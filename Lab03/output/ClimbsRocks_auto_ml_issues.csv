idtitlecreatedAtclosedAtclosed
MDU6SXNzdWUxNjk4MjQyOTM=allow the user to pass in their own arbitrary code to run first in the pipeline2016-08-08T00:13:04Z2016-08-08T05:02:28ZTrue
MDU6SXNzdWUxNjk4MjQ0MTA=implement gridsearchcv2016-08-08T00:16:01Z2016-08-09T04:26:41ZTrue
MDU6SXNzdWUxNjk4MjQ0Mjg=FUTURE: train more models2016-08-08T00:16:17Z2016-08-09T04:27:11ZTrue
MDU6SXNzdWUxNjk4MjQ0Mzk=FUTURE: train regressors or classifiers2016-08-08T00:16:30Z2016-08-12T06:12:57ZTrue
MDU6SXNzdWUxNjk4MjQ0NTU=FUTURE: run hyperparameter optimization on all the models2016-08-08T00:16:50Z2016-08-09T04:27:59ZTrue
MDU6SXNzdWUxNzAwODE2ODY=Fix which dataset we train/test on2016-08-09T04:53:29Z2016-08-24T22:53:41ZTrue
MDU6SXNzdWUxNzAwODE3MjY=Make RMSE our default scoring metric2016-08-09T04:53:57Z2016-08-16T02:30:34ZTrue
MDU6SXNzdWUxNzAwODE5MzU=implement more models2016-08-09T04:56:07Z2016-09-17T00:43:16ZTrue
MDU6SXNzdWUxNzAwODE5NDc=support NLP2016-08-09T04:56:14Z2016-10-08T19:20:53ZTrue
MDU6SXNzdWUxNzAwODI0NTU=make ensembling an option2016-08-09T05:02:04Z2016-08-24T22:52:09ZTrue
MDU6SXNzdWUxNzAwODI1MTc=support print_analytics_output!2016-08-09T05:02:45Z2016-08-11T06:58:45ZTrue
MDU6SXNzdWUxNzAwODM4MDk=add feature selection2016-08-09T05:17:21Z2016-08-17T02:30:59ZTrue
MDU6SXNzdWUxNzAwODM4MzE=add all kinds of stats transforms on our features2016-08-09T05:17:34Z2016-11-02T20:36:31ZTrue
MDU6SXNzdWUxNzAwODQxNzE=print_training_summary2016-08-09T05:21:21Z2016-08-18T03:00:45ZTrue
MDU6SXNzdWUxNzAyMjA3Njk=Super Future: let the user pass in a under_sample_to_balance_classes flag2016-08-09T17:11:53ZFalse
MDU6SXNzdWUxNzAyMjE0NDk=assemble pipeline based on flags passed in2016-08-09T17:15:07Z2016-08-10T01:25:44ZTrue
MDU6SXNzdWUxNzA1NzY4MzM=only turn values into floats if that column is not categorical2016-08-11T06:13:17Z2016-08-13T05:46:14ZTrue
MDU6SXNzdWUxNzA1NzY4NTY=turn categorical column into strings2016-08-11T06:13:28Z2016-08-13T05:46:04ZTrue
MDU6SXNzdWUxNzA1NzY5NDk=consider having .train() and .customized_train()2016-08-11T06:14:37ZFalse
MDU6SXNzdWUxNzA1ODA1MjA=optimize getting feature_ranges inside .fit in FinalModelATC2016-08-11T06:48:44Z2016-08-13T05:15:21ZTrue
MDU6SXNzdWUxNzA5NzEyNDY=add RandomizedSearchCV params for regressors2016-08-12T22:31:07Z2016-08-18T02:59:15ZTrue
MDU6SXNzdWUxNzA5NzQyOTg=Make sure we calibrate our models properly2016-08-12T22:57:43Z2017-03-12T00:25:27ZTrue
MDU6SXNzdWUxNzA5OTQ2OTg=add 'date' as an input column type2016-08-13T05:47:42Z2016-08-18T02:58:42ZTrue
MDU6SXNzdWUxNzA5OTcxNDM=look into using XGBoost2016-08-13T07:09:34Z2016-08-14T08:28:05ZTrue
MDU6SXNzdWUxNzA5OTcxNjE=update docs2016-08-13T07:10:25Z2016-08-28T21:07:02ZTrue
MDU6SXNzdWUxNzA5OTcxNzE=write tests2016-08-13T07:10:35Z2017-03-12T00:26:32ZTrue
MDU6SXNzdWUxNzEwNDg0MTE=allow user to pass in a value for scoring=2016-08-14T08:30:20ZFalse
MDU6SXNzdWUxNzEwNDg1MDM=see if we still need to turn class strings into ints2016-08-14T08:31:48Z2017-03-12T00:38:02ZTrue
MDU6SXNzdWUxNzEzMTI1MTQ=write the results of all the pipeline grid search combos to file2016-08-16T02:56:20Z2016-08-17T02:29:57ZTrue
MDU6SXNzdWUxNzE1NjA5NTk=Optimize feature selection2016-08-17T02:32:59Z2017-03-12T00:27:47ZTrue
MDU6SXNzdWUxNzE1NjU0MDE=impute missing values as one of the steps for gridsearchcv to tune2016-08-17T03:18:31Z2017-03-12T00:40:19ZTrue
MDU6SXNzdWUxNzIyNTY1NjQ=add in natural log y variable feature transform2016-08-20T06:20:41Z2016-08-20T20:25:13ZTrue
MDU6SXNzdWUxNzIyNTczMDM=i bet we can center and scale even sparse data manually. 2016-08-20T06:43:56Z2016-08-20T22:48:25ZTrue
MDU6SXNzdWUxNzIyNTczOTk=remove outlier values2016-08-20T06:47:02Z2016-08-21T02:09:23ZTrue
MDU6SXNzdWUxNzIyNTc2ODc=run a clustering algorithm over our data to first cluster it2016-08-20T06:56:10Z2016-08-28T21:06:37ZTrue
MDU6SXNzdWUxNzIyNTc3MDk=when doing nlp, use EmPythy to get sentiment predictions2016-08-20T06:57:10ZFalse
MDU6SXNzdWUxNzIyNTgzOTg=have a sensible set of default values2016-08-20T07:17:06Z2016-08-20T21:04:58ZTrue
MDU6SXNzdWUxNzIyNTg5MDI=automated training and ensembling of subpredictors2016-08-20T07:31:16Z2016-08-24T22:50:48ZTrue
MDU6SXNzdWUxNzIyODU2Njc=allow the user to do some fuzzy matching on type_of_model2016-08-20T19:05:11Z2016-08-20T19:58:57ZTrue
MDU6SXNzdWUxNzIyODg5OTc=shorten all attribute names in our dictionaries if there is no user defined func2016-08-20T20:23:03Z2017-03-12T00:40:37ZTrue
MDU6SXNzdWUxNzIyODkwMzU=far future: take in dataframes or other sparse data structures directly2016-08-20T20:23:42Z2017-03-12T00:41:41ZTrue
MDU6SXNzdWUxNzIyODkxMjQ=make taking the natural log of y values grid searchable. 2016-08-20T20:25:29Z2016-08-21T03:07:26ZTrue
MDU6SXNzdWUxNzIyOTY0NzQ=print better analytics results from xgb2016-08-20T23:40:13Z2016-08-21T01:05:06ZTrue
MDU6SXNzdWUxNzIyOTg5NDc=get better grid search params for XGBRegressor2016-08-21T01:05:39Z2016-08-22T16:40:57ZTrue
MDU6SXNzdWUxNzI0ODk4ODU=run PCA only in cases where the user passes in False for ml_for_analytics. 2016-08-22T15:58:47Z2017-03-12T00:42:24ZTrue
MDU6SXNzdWUxNzI0OTA0NjA=cluster input before feeding in to anything else2016-08-22T16:01:24Z2016-08-28T21:05:49ZTrue
MDU6SXNzdWUxNzI0OTg1NTg=add_ convention for all Pipeline Transformers that add a feature2016-08-22T16:38:31Z2016-08-24T22:48:17ZTrue
MDU6SXNzdWUxNzI0OTg5Nzg=When we implement ensembling, allow the user to pass in either a dict or a list2016-08-22T16:40:37Z2016-08-24T22:47:08ZTrue
MDU6SXNzdWUxNzI1MDA5NTY=inside FeatureUnion for ensembled predictors, add in FeatureSelection2016-08-22T16:50:27Z2016-08-24T22:49:03ZTrue
MDU6SXNzdWUxNzI1MDE3OTA=minor optimization: delete model_map after we create the model we need. 2016-08-22T16:54:18Z2016-08-24T22:45:34ZTrue
MDU6SXNzdWUxNzI3NzkzNTQ=make sure we're not deleting data we don't want to inside FeatureUnion2016-08-23T18:59:20Z2016-08-23T23:20:22ZTrue
MDU6SXNzdWUxNzI3Nzk0NTI=see if featureunion might be faster with n_jobs=12016-08-23T18:59:46Z2016-08-23T19:15:10ZTrue
MDU6SXNzdWUxNzI3Nzk1NTA=install previous version of xgboost, to avoid weird scipy.sparse issues2016-08-23T19:00:13Z2016-09-17T00:42:26ZTrue
MDU6SXNzdWUxNzI3ODA1MTg=within AddSubpredictorPrediction, only train on rows where we actually have the right value to predict2016-08-23T19:04:44Z2016-08-24T06:21:24ZTrue
MDU6SXNzdWUxNzI3ODY0MTY=Use sklearn's Gradient Boosting instead of XGBoost2016-08-23T19:33:05Z2016-08-23T22:23:50ZTrue
MDU6SXNzdWUxNzM0ODI0MjA=cannot train multiple instances of xgboost without it hanging2016-08-26T15:38:57Z2016-09-24T04:56:27ZTrue
MDU6SXNzdWUxNzM0OTk5ODk=more options for ml_for_analytics2016-08-26T17:10:18Z2017-03-12T00:50:06ZTrue
MDU6SXNzdWUxNzM2NjgwOTE=Add in deep learning with either scikit-learn's MLP, or TF Learn2016-08-28T21:13:03Z2017-03-12T00:49:44ZTrue
MDU6SXNzdWUxNzM2Njg1Nzc=make it importable for both python 2 and python 32016-08-28T21:22:32Z2016-09-17T00:36:58ZTrue
MDU6SXNzdWUxNzQxMzgyMjc=validation to run on input2016-08-30T22:07:55ZFalse
MDU6SXNzdWUxNzQyMjU5NDA='RidgeClassifier' object has no attribute 'predict_proba'2016-08-31T09:27:44Z2016-09-29T18:10:15ZTrue
MDU6SXNzdWUxNzQyMjY4MzI=User-defined config2016-08-31T09:32:05ZFalse
MDU6SXNzdWUxNzQ0MjI5NTM=make data dense to work around XGB's sparse bug only when an error is thrown.  2016-09-01T02:34:18Z2016-09-17T00:34:19ZTrue
MDU6SXNzdWUxNzQ0MjI5OTQ=verify nested subpredictors are actually running2016-09-01T02:34:47Z2016-09-17T00:34:52ZTrue
MDU6SXNzdWUxNzQ0MjMzNTQ=make sure that our outer subpredictors are not getting their own nested_subpredictor2016-09-01T02:38:20Z2017-06-07T16:14:21ZTrue
MDU6SXNzdWUxNzc1NTI1MzU=remove all references to optimize_final_model2016-09-17T03:15:32Z2016-09-17T04:57:56ZTrue
MDU6SXNzdWUxNzc1NTI1NDg=have some logic for whether we optimize hyperparameters or not2016-09-17T03:16:02Z2016-09-17T04:57:44ZTrue
MDU6SXNzdWUxNzc1NTI1NTg=future: build in more granular support for number of hyperparameter optimizations to consider in gscv2016-09-17T03:16:39Z2017-06-07T16:14:21ZTrue
MDU6SXNzdWUxNzc1NTI1ODg=really focus down on only gradient boosting as it's consistently a top performer2016-09-17T03:17:29Z2016-11-02T20:35:19ZTrue
MDU6SXNzdWUxNzc1NTU5Mzg=fix bug in user_defined_model_names in _construct_pipeline_search_params2016-09-17T04:57:26Z2016-09-24T04:54:21ZTrue
MDU6SXNzdWUxNzc1NTY4MjU=future: consider finding the ideal hyperparameters with an exhaustive search over only 10% of the data2016-09-17T05:24:28Z2017-03-12T00:47:43ZTrue
MDU6SXNzdWUxNzc1NTcxNjE=feature selection optimization2016-09-17T05:30:19Z2017-03-12T00:46:36ZTrue
MDU6SXNzdWUxNzc1ODkyNzU=take in a single string as user_defined_models, in addition to an array2016-09-17T16:34:57Z2017-06-07T16:14:21ZTrue
MDU6SXNzdWUxNzc2MTg1MDA=for deep learning, change how we save models2016-09-17T23:51:30Z2017-03-12T00:53:13ZTrue
MDU6SXNzdWUxNzc2MTk1Njg=deep learning: dynamically assemble models2016-09-18T00:18:39Z2017-03-12T00:55:43ZTrue
MDU6SXNzdWUxNzc2MTk2MzQ=deep learning: dynamically set n_classes2016-09-18T00:20:30ZFalse
MDU6SXNzdWUxNzc2MTk3MjU=deep learning: figure out workaround to .todense()2016-09-18T00:23:17Z2017-03-12T00:57:07ZTrue
MDU6SXNzdWUxNzc2MjEzNjU=deep learning: create a wrapper class to enable this to work with gridsearchcv2016-09-18T01:10:31Z2017-03-12T00:57:34ZTrue
MDU6SXNzdWUxNzc2MjMyNDE=deep learning gridsearchcv network shape strings2016-09-18T02:00:26Z2017-03-12T00:57:52ZTrue
MDU6SXNzdWUxNzc4Nzg2MDM=Modify subpredictor algorithms based on system info2016-09-19T19:46:54Z2017-06-07T16:14:22ZTrue
MDU6SXNzdWUxNzc4ODA4MzA=if we are not doing any grid search, just run straight through, don't use grid search2016-09-19T19:56:22Z2016-09-24T04:48:10ZTrue
MDU6SXNzdWUxNzc4ODM1NDU=definitely look back into FeatureUnion for subpredictors2016-09-19T20:06:50Z2016-09-24T04:47:45ZTrue
MDU6SXNzdWUxNzc5MjcxNTU=PR to scikit learn to support .001*max in SelectFromModel2016-09-19T23:45:38Z2017-03-12T00:58:32ZTrue
MDU6SXNzdWUxNzgxMjQzNjk=Allow the user to pass in a list of categorical variables as the value for a column2016-09-20T17:30:47ZFalse
MDU6SXNzdWUxNzgyMDYyODk=make sure we support both datetimes and dates for the 'date' column2016-09-20T23:24:23Z2017-03-12T00:59:04ZTrue
MDU6SXNzdWUxNzg0ODMxNzM=add in input validation on model name2016-09-21T23:00:54ZFalse
MDU6SXNzdWUxNzkwMDU2MTQ=consolidate pipeline for efficiency's sake2016-09-24T02:24:33Z2016-09-24T04:45:45ZTrue
MDU6SXNzdWUxNzkwMTA1Mjc=eventually, delete the feature names from all the DictVectorizers, and just keep one master list of all features expected for predictions2016-09-24T04:43:37Z2017-03-12T00:59:48ZTrue
MDU6SXNzdWUxNzk1NjY4Njg=Ridge classifier fails when tested on iris dataset.2016-09-27T17:57:17Z2016-09-29T18:01:12ZTrue
MDU6SXNzdWUxNzk1OTgyOTE=if given a list to run predictions on, run them in parallel2016-09-27T20:04:30Z2016-10-12T03:02:50ZTrue
MDU6SXNzdWUxODAwOTg0OTU=Error: list index out of range in predictor.py2016-09-29T16:27:34Z2016-09-29T17:59:47ZTrue
MDU6SXNzdWUxODAxMjgwMDE=fail gracefully if we end up with an empty vector to run predictions on2016-09-29T18:36:11Z2017-06-07T16:14:32ZTrue
MDU6SXNzdWUxODAzODUwNjA=interpretation of predictor score2016-09-30T19:35:06Z2017-06-07T16:15:15ZTrue
MDU6SXNzdWUxODA0MzQwNTA=Documentation: Addition of scoring metric details in description of ml_predictor.score2016-10-01T02:52:38Z2017-03-12T01:07:08ZTrue
MDU6SXNzdWUxODEwNTQxNjc=add in advanced logging2016-10-05T02:57:43Z2016-11-02T20:33:56ZTrue
MDU6SXNzdWUxODE3OTM1Mjk=figure out if we can take in a single sparse dictionary, and convert it to the same structure dataframe as we used for training2016-10-08T00:43:55Z2016-10-11T03:03:15ZTrue
MDU6SXNzdWUxODE4MzgxOTM=Make auto_ml available in JavaScript!2016-10-08T17:27:13ZFalse
MDU6SXNzdWUxODE4Mzg0OTI=Write our own dfVectorizer, mimicking DictVectorizer, but for DataFrames2016-10-08T17:32:21Z2016-10-11T03:02:36ZTrue
MDU6SXNzdWUxODE4Mzk0MTQ=df support2016-10-08T17:49:49Z2016-10-11T03:00:18ZTrue
MDU6SXNzdWUxODE4NDM2MDI=df FUTURE: keep transforms super flexible, to take in either a df, or a single dictionary2016-10-08T19:15:51Z2016-11-02T20:34:14ZTrue
MDU6SXNzdWUxODE4NDM4NTA=FUTURE: support multiple NLP columns2016-10-08T19:21:09Z2016-11-02T20:34:20ZTrue
MDU6SXNzdWUxODE4NjUyNDA=remove duplicate columns at the start, before pipelines2016-10-09T04:31:13Z2016-10-11T03:01:53ZTrue
MDU6SXNzdWUxODE4NjUyNzc=train up subpredictors in parallel using parallel map2016-10-09T04:32:13Z2016-10-11T03:00:37ZTrue
MDU6SXNzdWUxODIwNjgwNzI=remove duplicate pre-processing in subpredictors2016-10-10T17:15:52Z2017-03-12T01:07:29ZTrue
MDU6SXNzdWUxODIwNjgxNDk=run CustomSparseScaler on the subpredictor_predictions2016-10-10T17:16:15Z2017-03-12T01:07:39ZTrue
MDU6SXNzdWUxODIwNjgzNjQ=now that we're using much more memory-efficient DataFrames, look into parallelizing getting subpredictor predictions again2016-10-10T17:17:20Z2017-03-12T01:07:51ZTrue
MDU6SXNzdWUxODIxNjI1MTc=make sure we can still take in a single dictionary for .predict and .predict_proba2016-10-11T03:03:31Z2016-11-02T20:32:58ZTrue
MDU6SXNzdWUxODMzMzEzODk=make xgboost optional2016-10-17T05:56:28Z2016-11-02T20:33:22ZTrue
MDU6SXNzdWUxODMzMzI3MTk=eventually dynamically figure out ncpus based on available memory2016-10-17T06:09:10Z2017-06-07T16:14:22ZTrue
MDU6SXNzdWUxODM1NjY4OTY=optimize DataFrameVectorizer for memory2016-10-18T01:14:54ZFalse
MDU6SXNzdWUxODM1NjcxMzc=look into parallelizing CustomSparseScaler2016-10-18T01:17:09ZFalse
MDU6SXNzdWUxODM1NzU2OTc=look into getting predictions in parallel2016-10-18T02:34:51Z2017-03-12T01:09:26ZTrue
MDU6SXNzdWUxODM3Mzg2NzQ=run DataFrameVectorizer before parallelization2016-10-18T16:32:10Z2017-03-12T01:08:21ZTrue
MDU6SXNzdWUxODM3Mzg4NzM=weak estimators- get probabilities from classifiers2016-10-18T16:32:58Z2017-03-12T01:10:32ZTrue
MDU6SXNzdWUxODM3MzkxMjE=weak estimators- average together predictions (or grab the median prediction)2016-10-18T16:34:03Z2017-03-12T01:10:52ZTrue
MDU6SXNzdWUxODM4NzY3NjE=look into optimizing with numba2016-10-19T06:32:34ZFalse
MDU6SXNzdWUxODM5OTExODM=look into getting predictions in parallel2016-10-19T15:13:43Z2017-03-12T01:10:13ZTrue
MDU6SXNzdWUxODQwMDc1Nzc=Lack of milestones and tags for bugs relevancy/importance/difficultiness2016-10-19T16:12:26Z2017-06-07T16:14:22ZTrue
MDU6SXNzdWUxODU4MjkyNTA='FinalModelATC' object has no attribute 'feature_ranges'2016-10-28T03:13:27Z2016-10-28T04:06:59ZTrue
MDU6SXNzdWUxODYwNDAxMDU=print accuracy and advanced logging by default when calling .score2016-10-28T23:02:15Z2016-11-01T03:23:15ZTrue
MDU6SXNzdWUxODYwNTI5MTk=ValueError: Attempted relative import beyond toplevel package2016-10-29T01:53:54Z2016-11-01T03:22:36ZTrue
MDU6SXNzdWUxODYwNTMwMDI=UnboundLocalError: local variable 'prediction_data' referenced before assignment2016-10-29T01:56:18Z2016-11-01T03:22:07ZTrue
MDU6SXNzdWUxODY0NTcwNjk=rip out subpredictors2016-11-01T04:31:19Z2016-11-02T20:31:29ZTrue
MDU6SXNzdWUxODY0NTg2ODE=ensemble together many predictors2016-11-01T04:50:02Z2017-03-12T01:11:48ZTrue
MDU6SXNzdWUxODY0NTg4MTc=Comment out all the deep learning stuff for now2016-11-01T04:51:41Z2016-11-02T20:29:38ZTrue
MDU6SXNzdWUxODY1ODg1NzI=re-implement clustered prediction2016-11-01T17:04:19Z2017-03-12T01:12:40ZTrue
MDU6SXNzdWUxODY1OTk3NDU=look back into dropping columns in basicdatacleaning again2016-11-01T17:49:05Z2017-03-12T01:14:25ZTrue
MDU6SXNzdWUxODcxODQ2MzI=support multi-class classification in ensembling2016-11-03T20:42:37Z2017-03-12T01:12:52ZTrue
MDU6SXNzdWUxODc3OTU0MDM=ensembling methodologies to try2016-11-07T18:49:59ZFalse
MDU6SXNzdWUxODc3OTgzOTg=fix try/except block around import2016-11-07T19:02:43Z2017-03-12T01:13:09ZTrue
MDU6SXNzdWUxODgzNTc2MzQ=ideal features to have GSCV-able for ensembling2016-11-09T21:31:53ZFalse
MDU6SXNzdWUxODgzNzQ3NDU=for adding predicted features: add a flag for exists or not2016-11-09T22:58:28Z2017-03-12T01:13:50ZTrue
MDU6SXNzdWUxOTA4Njc0NDk=handle predict_proba for multiclass problems where the model doesn't support predict_proba2016-11-21T23:37:29ZFalse
MDU6SXNzdWUxOTE1OTEyNDc=run tests for python 2.7 and 3.x2016-11-24T21:08:49Z2016-11-30T02:37:31ZTrue
MDU6SXNzdWUxOTE1OTEyNjI=test pip installed version??2016-11-24T21:09:06Z2017-03-12T01:15:06ZTrue
MDU6SXNzdWUxOTI0NjAxMDc=bug: multiple model_names without GSCV breaks2016-11-30T02:38:09Z2016-12-09T20:40:59ZTrue
MDU6SXNzdWUxOTI2NjM0OTY=travis-ci: run tests against pip install and local2016-11-30T19:58:13Z2017-03-12T01:15:15ZTrue
MDU6SXNzdWUxOTQ2OTE3NzQ=check all columns to see if they're a time column, and warn the user if it is an undocumented time column2016-12-09T20:40:39Z2017-03-11T23:55:02ZTrue
MDU6SXNzdWUxOTQ3MjY5MTM=Logging & Validation: warn the user when they pass in a y column that only holds one distinct value2016-12-10T00:06:11ZFalse
MDU6SXNzdWUxOTQ3ODU1ODc=let the user pass in their own custom scoring metric2016-12-10T18:39:03ZFalse
MDU6SXNzdWUxOTUxMzEyNTY=ImportError: cannot import name Predictor2016-12-13T01:00:55Z2016-12-14T23:47:05ZTrue
MDU6SXNzdWUxOTUxNDkwNTk=Error on install - Windows 102016-12-13T03:16:21Z2017-03-12T01:16:33ZTrue
MDU6SXNzdWUxOTU1Nzc4MDM=Problem with scoring2016-12-14T16:26:01Z2016-12-14T19:34:54ZTrue
MDU6SXNzdWUxOTU2MTY1Mjc=make nlp work for individual dictionaries2016-12-14T19:02:18Z2017-03-12T01:17:17ZTrue
MDU6SXNzdWUxOTU5NjE3MTI=rethink how we handle compute_power2016-12-16T01:42:52Z2017-03-12T01:19:32ZTrue
MDU6SXNzdWUxOTYyMDY4MDU=add feature checking as a verbose option to .predict and .predict_proba in FinalModelATC2016-12-17T06:50:36Z2017-03-12T01:23:53ZTrue
MDU6SXNzdWUyMDA1MjcxMDk=add model_params and gs_params to .train api2017-01-13T01:37:15Z2017-03-12T01:23:03ZTrue
MDU6SXNzdWUyMDA1MjgwOTU=Incorporate Microsoft's LightGBM!2017-01-13T01:45:22Z2017-03-12T01:22:41ZTrue
MDU6SXNzdWUyMDA3NjQ5NDM=handle strings passed in as output for binary classification2017-01-14T00:32:17ZFalse
MDU6SXNzdWUyMTAxNTcwNzM=update docs2017-02-24T21:01:57Z2017-04-04T19:41:03ZTrue
MDU6SXNzdWUyMTAxNTc5MzA=deep learning training speed up- only perform feature scaling once2017-02-24T21:05:59Z2017-03-12T01:24:41ZTrue
MDU6SXNzdWUyMTIyMzY5NDU=automated ensembling v42017-03-06T20:16:26Z2017-06-07T16:18:02ZTrue
MDU6SXNzdWUyMTI1MzkzOTE=immediate improvements2017-03-07T19:49:38Z2017-04-04T19:40:56ZTrue
MDU6SXNzdWUyMTI1Njg3MTg=Document new changes2017-03-07T21:45:50Z2017-04-04T19:40:33ZTrue
MDU6SXNzdWUyMTM0MzkxMTk=TypeError: cannot perform reduce with flexible type OR AttributeError: 'Predictor' object has no attribute 'grid_search_pipelines'2017-03-10T20:06:08Z2017-03-19T01:22:33ZTrue
MDU6SXNzdWUyMTM1NTEzODE=Accept strings as labels for classification problems2017-03-11T19:03:07ZFalse
MDU6SXNzdWUyMTM1NTEzOTU=Increase test coverage for different types of scoring2017-03-11T19:03:21ZFalse
MDU6SXNzdWUyMTM1NTE0MjM=Refactor to send categorical data into LightGBM as a single column2017-03-11T19:03:51ZFalse
MDU6SXNzdWUyMTM1NTMyMTQ=Simplify README example2017-03-11T19:32:06Z2017-06-07T16:18:02ZTrue
MDU6SXNzdWUyMTM1NTQ0ODU=Finish Keras integration2017-03-11T19:47:47Z2017-06-07T16:18:02ZTrue
MDU6SXNzdWUyMTM1NjkwMjI=do not perform feature scaling by default2017-03-11T23:54:42Z2017-06-07T16:16:48ZTrue
MDU6SXNzdWUyMTM1NzE0NDA=Add space to logging for missing values being removed from y values2017-03-12T00:45:50Z2017-04-04T19:38:21ZTrue
MDU6SXNzdWUyMTM4OTIzMTY=keras: add more hyperparameters to our build_fns2017-03-13T20:47:12ZFalse
MDU6SXNzdWUyMTM4OTIzNzA=keras: rename regressor build_fn2017-03-13T20:47:24Z2017-06-07T16:18:03ZTrue
MDU6SXNzdWUyMTM4OTI1OTQ=keras future: two step hyperparameter optimization2017-03-13T20:48:20Z2017-06-07T16:18:03ZTrue
MDU6SXNzdWUyMTM4OTI2Mzg=test for gs_params and training_params2017-03-13T20:48:31ZFalse
MDU6SXNzdWUyMTM4OTI5NDc=keras: merge into master2017-03-13T20:49:45Z2017-04-04T19:38:08ZTrue
MDU6SXNzdWUyMTM4OTMxMzQ=examples branch2017-03-13T20:50:29ZFalse
MDU6SXNzdWUyMTM5NzI3NzM=keras future: use nn for representational learning early in ensemble2017-03-14T05:31:57Z2017-06-07T16:17:01ZTrue
MDU6SXNzdWUyMTM5NzcxNTc=simplification2017-03-14T06:07:06Z2017-04-04T19:37:01ZTrue
MDU6SXNzdWUyMTQxNjMwMTk=Upgrade to keras 2.02017-03-14T18:19:57Z2017-03-14T18:39:52ZTrue
MDU6SXNzdWUyMTQyMDkwNDY=update setup.py2017-03-14T21:15:46Z2017-04-04T19:36:19ZTrue
MDU6SXNzdWUyMTc4NzkzMjA=xgboost in advanced_requirements.txt unreliable2017-03-29T13:40:37Z2017-04-04T23:50:05ZTrue
MDU6SXNzdWUyMTkyNDMzODE=Show confusion matrix2017-04-04T13:03:56Z2017-04-06T00:22:16ZTrue
MDU6SXNzdWUyMTkzNzU4ODI=Categorical Ensembling2017-04-04T20:39:42Z2017-06-07T16:17:08ZTrue
MDU6SXNzdWUyMTk0MjQwOTY=test suite automation2017-04-05T00:11:28Z2017-06-07T16:17:18ZTrue
MDU6SXNzdWUyMTk0Mzk4MzU=parallelize categorical ensemble training2017-04-05T01:47:06Z2017-06-07T16:17:25ZTrue
MDU6SXNzdWUyMTk2NDAwNTA=logging clean up: remove model from our gscv params that get logged by sklearn2017-04-05T16:22:20Z2017-06-07T16:17:35ZTrue
MDU6SXNzdWUyMTk2OTIwMTc=categorical ensembling: default category2017-04-05T19:36:52Z2017-06-07T16:17:44ZTrue
MDU6SXNzdWUyMTk2OTMxMjI=categorical ensembling: min_category_size2017-04-05T19:41:24Z2017-06-07T16:17:51ZTrue
MDU6SXNzdWUyMTk2OTUwNDU=switch from gridsearchcv to randomizedsearchcv2017-04-05T19:49:06ZFalse
MDU6SXNzdWUyMTk3MTc5MTc=add time logging for gscv training2017-04-05T21:17:15ZFalse
MDU6SXNzdWUyMTk3MjQzMzE=categorical ensemble: eventually, get weighted average of feature_importances_2017-04-05T21:43:12ZFalse
MDU6SXNzdWUyMjAxMDEzODM=figure out how to save our new feature_learning models2017-04-07T03:45:47Z2017-06-07T16:18:38ZTrue
MDU6SXNzdWUyMjAyOTA3MzE=test suite improvement- test keras uninstalled, xgb installed2017-04-07T18:20:33ZFalse
MDU6SXNzdWUyMjExMDUxNjk=todos test suite2017-04-11T23:03:04Z2017-06-18T01:09:38ZTrue
MDU6SXNzdWUyMjE2NzA1NjY=Pure ML Idea2017-04-13T20:17:22ZFalse
MDU6SXNzdWUyMjE3MTk0MzY=training speed categorical ensemble- split and transform data before parallelization2017-04-14T01:08:24ZFalse
MDU6SXNzdWUyMjI3NzAwNzM=User validation on fl_data2017-04-19T15:06:27Z2017-04-20T21:36:16ZTrue
MDU6SXNzdWUyMjM5NTE0NjI=user validation: make sure there are at least two classes for classification problems2017-04-24T21:07:30ZFalse
MDU6SXNzdWUyMjQyNDY4NTc=pure ML idea: interaction of all terms2017-04-25T19:28:35ZFalse
MDU6SXNzdWUyMjQyNzI2Nzk=improved user logging2017-04-25T21:08:09ZFalse
MDU6SXNzdWUyMjUyNzM2MTc=Charting ideas2017-04-29T17:49:30ZFalse
MDU6SXNzdWUyMjYxNjYyNjA=Issue with minor change to sample code gave error2017-05-04T02:54:12Z2017-05-04T23:50:33ZTrue
MDU6SXNzdWUyMjc0NTI3NTE=add a __model_version__ attribute to the final trained pipeline2017-05-09T18:14:34ZFalse
MDU6SXNzdWUyMjc3NzMyMTY=refactor dataframevectorizer to be faster2017-05-10T18:39:55ZFalse
MDU6SXNzdWUyMjgwNDIyMjg=Training ate my dataframe2017-05-11T16:00:10Z2017-05-11T23:16:58ZTrue
MDU6SXNzdWUyMjgxNjg1MDQ=Uncertainty predictions2017-05-12T02:03:48ZFalse
MDU6SXNzdWUyMjkxODcyNzg=Use ELI5 for model analytics2017-05-16T22:29:19ZFalse
MDU6SXNzdWUyMjkzNTM1Mzk=Multi-label classification with feature learning throws an error2017-05-17T13:31:53ZFalse
MDU6SXNzdWUyMjkzNjEwOTE=Analytics idea: alter all values at prediction time by one std up and down2017-05-17T13:56:09ZFalse
MDU6SXNzdWUyMjk1MTM1MzE=consider bucketing differently for advanced_scoring_classifiers2017-05-17T23:18:13ZFalse
MDU6SXNzdWUyMjk1NTg0MDU=Fix formatting of pypi page2017-05-18T05:24:15Z2017-06-03T01:05:11ZTrue
MDU6SXNzdWUyMjk4MzQzOTE=print analytics on our is_uncertain_prediction set2017-05-18T23:48:18Z2017-06-03T01:05:00ZTrue
MDU6SXNzdWUyMzAxMzg3NzI=ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape2017-05-20T08:16:21Z2017-09-12T03:03:10ZTrue
MDU6SXNzdWUyMzExMjM2MDY=Project Organization and Next Steps2017-05-24T18:00:49ZFalse
MDU6SXNzdWUyMzExNTk3MzM=Deep Learning optimization2017-05-24T20:21:23ZFalse
MDU6SXNzdWUyMzE0MDY0MjI=AttributeError: 'XGBRegressor' object has no attribute 'get_fscore'2017-05-25T17:34:45Z2017-05-25T23:45:47ZTrue
MDU6SXNzdWUyMzE0MTEyNTM=AttributeError: grid_search_pipelines2017-05-25T17:54:09Z2017-05-25T23:45:22ZTrue
MDU6SXNzdWUyMzE2MTM1MjA=Google stole the project name2017-05-26T12:29:45ZFalse
MDU6SXNzdWUyMzIzNDEzNjU=Save trained models to their own folders2017-05-30T18:29:55ZFalse
MDU6SXNzdWUyMzIzNjU3NDU=Comparison with other automatic ML libraries?2017-05-30T20:04:26Z2017-05-30T20:37:21ZTrue
MDU6SXNzdWUyMzMzMTU3ODQ=make all feature names ascii appropriate2017-06-02T22:15:40Z2017-06-03T01:04:44ZTrue
MDU6SXNzdWUyMzMzNjA0Njk=model_names - some remarks2017-06-03T10:15:32ZFalse
MDU6SXNzdWUyMzMzOTg4NjM=feature_learning - separate data set2017-06-03T22:25:21ZFalse
MDU6SXNzdWUyMzQxNjg3NjM=Another Visualization idea2017-06-07T10:50:13ZFalse
MDU6SXNzdWUyMzQyNjM5NDQ=Better feature selection2017-06-07T16:12:35ZFalse
MDU6SXNzdWUyMzUzNTU3MTI=feature importances selects top 100 incorrectly2017-06-12T20:28:45Z2017-06-13T03:20:22ZTrue
MDU6SXNzdWUyMzUzNTU4MDI=train_categorical_ensemble should be able to use an ignored column as the category column2017-06-12T20:29:08Z2017-06-13T03:20:33ZTrue
MDU6SXNzdWUyMzUzNTYzNTI=categorical ensemble should fail gracefully when no category fits min_category_size2017-06-12T20:31:24Z2017-06-13T03:20:13ZTrue
MDU6SXNzdWUyMzU0MDc4MjU=modify feature responses with feature_learning2017-06-13T01:05:12ZFalse
MDU6SXNzdWUyMzU3MzA4MTA=follow up on numpy deprecations2017-06-14T00:37:37Z2017-06-15T21:46:07ZTrue
MDU6SXNzdWUyMzU3MzE0NDE=better hyperparameter optimization using evolutionary algorithms through sklearn-deap2017-06-14T00:42:20ZFalse
MDU6SXNzdWUyMzYwMTc5ODU=progress bar for feature transformation pipeline2017-06-14T21:41:20Z2017-10-12T04:08:37ZTrue
MDU6SXNzdWUyMzYzMTMzNDA=add learning rate schedules for DL2017-06-15T21:01:57Z2017-06-17T16:39:11ZTrue
MDU6SXNzdWUyMzYzMTQzMzU=for deep learning, sort feature_responses by magnitude of effect2017-06-15T21:05:47ZFalse
MDU6SXNzdWUyMzY1NjM3NDY=Analytics improvements2017-06-16T18:47:56ZFalse
MDU6SXNzdWUyMzY1NzUyNTM=use RMSE instead of MSE for keras reporting2017-06-16T19:39:19ZFalse
MDU6SXNzdWUyMzY2NDEwNjk=create feature_responses only for the top 100 features2017-06-17T05:44:50Z2017-06-25T20:55:55ZTrue
MDU6SXNzdWUyMzY2ODgzMDg=separate param for optimize_feature_learning_model2017-06-17T22:45:08Z2017-06-18T01:07:02ZTrue
MDU6SXNzdWUyMzY2ODk2NTE=don't report feature_responses for feature_learning2017-06-17T23:18:34Z2017-06-18T00:50:08ZTrue
MDU6SXNzdWUyMzY2OTQ3OTE=Ensembling 3.02017-06-18T01:55:35ZFalse
MDU6SXNzdWUyMzY3MDM4Njg=Keras callbacks to add2017-06-18T06:31:59ZFalse
MDU6SXNzdWUyMzY3MDU2NTQ=search printing: remove `model__` prefix from logging2017-06-18T07:23:46Z2017-06-25T20:54:51ZTrue
MDU6SXNzdWUyMzY5OTM3NzU=deep learning optimizations to make2017-06-19T19:18:02ZFalse
MDU6SXNzdWUyMzczMjU2MTE=Have a `timeit` param?2017-06-20T19:52:17ZFalse
MDU6SXNzdWUyMzczOTA5Mjk=force deep learning to always do feature scaling2017-06-21T01:34:25Z2017-06-25T20:54:36ZTrue
MDU6SXNzdWUyMzc2MTYxMTQ=do post-hoc feature selection, to tell the user which features they can cut2017-06-21T17:56:16ZFalse
MDU6SXNzdWUyMzc5Mjc1NTc=print out params as their own columns in the df2017-06-22T18:06:11Z2017-06-25T20:53:48ZTrue
MDU6SXNzdWUyMzgzOTExNzk=sort printed params by score2017-06-25T16:36:10Z2017-06-25T20:53:39ZTrue
MDU6SXNzdWUyMzg1ODYyNjQ=Load checkpointed model2017-06-26T15:46:32ZFalse
MDU6SXNzdWUyMzg3MTk2MDg=SGD seems to be throwing an error?2017-06-27T02:19:14ZFalse
MDU6SXNzdWUyMzk4MDE2OTg=Build gradient boosting trees sequentially, with a smaller learning rate2017-06-30T14:49:24Z2017-07-04T06:50:39ZTrue
MDU6SXNzdWUyMzk4MDIyNTY=New ML Idea: learning rate schedules for gradient boosting trees2017-06-30T14:51:10ZFalse
MDU6SXNzdWUyMzk4MDY4NzM=New ML Idea: use many basic model types for gradient boosting, not just decision trees2017-06-30T15:05:33ZFalse
MDU6SXNzdWUyNDAyMjc0ODE=tf takes forever to import- let the user specify which backend they want through an environmental variable2017-07-03T17:10:22ZFalse
MDU6SXNzdWUyNDAyMjc1ODg=automatically pick theano as the backend for windows, and remove tf from requirements.txt??2017-07-03T17:10:58ZFalse
MDU6SXNzdWUyNDAzMjgyODM=warm start for lightgbm2017-07-04T06:56:05ZFalse
MDU6SXNzdWUyNDAzMjgzMDY=warm start for xgb2017-07-04T06:56:12ZFalse
MDU6SXNzdWUyNDA0ODIxOTM=allow keyboard interrupt for any warm-started model2017-07-04T18:47:57ZFalse
MDU6SXNzdWUyNDA3MDYwMDY=eventually, train on the entire dataset even when warm_starting, or early_stopping2017-07-05T16:26:36ZFalse
MDU6SXNzdWUyNDA3MDgwODY=lightgbm seems prone to overfitting with warm_start2017-07-05T16:34:20ZFalse
MDU6SXNzdWUyNDA3OTM3MzM=create advanced scoring logging for multi-class classification2017-07-05T22:26:48ZFalse
MDU6SXNzdWUyNDA4NDE2MjE=add a .transform_only option2017-07-06T04:29:21ZFalse
MDU6SXNzdWUyNDA4NDE2ODU=add an option to take in an already transformed matrix2017-07-06T04:29:57ZFalse
MDU6SXNzdWUyNDA4NTUxODQ=oversampling- use only original data2017-07-06T06:19:23ZFalse
MDU6SXNzdWUyNDEwMTA5Njk=give the user the option of passing in a function that's called after transform, and right before predict?2017-07-06T16:17:19ZFalse
MDU6SXNzdWUyNDExMTUxMDE=only use the original training data as validation data when using oversampling2017-07-06T23:28:41ZFalse
MDU6SXNzdWUyNDExMjQ4MzY=create an oversampling module2017-07-07T00:35:13ZFalse
MDU6SXNzdWUyNDExNTM3Mzc=oversampling- consider a true holdout set2017-07-07T04:21:58ZFalse
MDU6SXNzdWUyNDExNjIxOTI=oversampling- overfitting2017-07-07T05:35:26ZFalse
MDU6SXNzdWUyNDExNjU0NzM=oversampling- move feature_learning to after oversampling2017-07-07T06:00:37ZFalse
MDU6SXNzdWUyNDE0MjY0MTM="have something like ""is_hyperparameter_search"" for eascv finalmodelatc issues"2017-07-08T05:12:51ZFalse
MDU6SXNzdWUyNDE4MDM2Mzg=naming considerations2017-07-10T18:27:52ZFalse
MDU6SXNzdWUyNDIyNzIyMjY=adjust verbosity of sequential training during grid searching2017-07-12T06:24:57ZFalse
MDU6SXNzdWUyNDI1MjE5Njc=let the user pass in their own eval data set2017-07-12T21:31:07ZFalse
MDU6SXNzdWUyNDI1MjYxNjc=only pass in training_params for final model, not for feature_learning2017-07-12T21:49:47ZFalse
MDU6SXNzdWUyNDI1MzE5MTM=do model training differently inside gscv2017-07-12T22:15:41ZFalse
MDU6SXNzdWUyNDI4NDQ3NjI=use quantile with a 0.5 alpha to get a prediction of the median2017-07-13T22:09:12ZFalse
MDU6SXNzdWUyNDI4NzQ1Njk=add some regularization to gradientboosting warm starting2017-07-14T01:41:31ZFalse
MDU6SXNzdWUyNDI4NzYxMDc=API for predict_intervals2017-07-14T01:54:14ZFalse
MDU6SXNzdWUyNDI4NzYyOTU=write tests for predict_intervals!2017-07-14T01:55:53ZFalse
MDU6SXNzdWUyNDI4NzY2Mjc=predict intervals master list2017-07-14T01:58:30ZFalse
MDU6SXNzdWUyNDI4NzcwNjk=add docs for training_params2017-07-14T02:02:08ZFalse
MDU6SXNzdWUyNDI4ODU5MDg=FUTURE: prediction_intervals- use xgboost or lightgbm instead of sklearn2017-07-14T03:13:29ZFalse
MDU6SXNzdWUyNDI4ODU5NDY=FUTURE: parallelize training up our three different prediction_interval models2017-07-14T03:13:46ZFalse
MDU6SXNzdWUyNDI5MDMxOTY=feature responses- make the column all noise2017-07-14T05:46:48ZFalse
MDU6SXNzdWUyNDMwMzMzMDM=Single feature column and Multiple label columns for prediction2017-07-14T15:37:03ZFalse
MDU6SXNzdWUyNDMwNjE1NDI=add n_jobs as a training param2017-07-14T17:34:03ZFalse
MDU6SXNzdWUyNDMxOTQ1NDQ=look into deleting FRD_MAP2017-07-15T19:17:37ZFalse
MDU6SXNzdWUyNDM0NzMzMzE=todos before merging in evolving2017-07-17T17:45:56ZFalse
MDU6SXNzdWUyNDM4NDAwMzA=add in CatBoost!2017-07-18T20:24:04ZFalse
MDU6SXNzdWUyNDM4OTYyMDg=use loss = 'MultiClass' for catboost multiclass2017-07-19T01:22:14ZFalse
MDU6SXNzdWUyNDQ0ODYwNTc=TODO: adjust test bounds for classifiers after passing in new categorical variable for titanic2017-07-20T20:23:41ZFalse
MDU6SXNzdWUyNDQ3NzQxMjM=allow the user to pass in False for prediction_intervals2017-07-21T20:23:31ZFalse
MDU6SXNzdWUyNDU1NTYxODQ=shuffle input data for training by default2017-07-25T22:40:53ZFalse
MDU6SXNzdWUyNDU1NTc1NjY=use Xavier or He for weight initializations2017-07-25T22:49:05ZFalse
MDU6SXNzdWUyNDY4MzcxMjg=speed up test suite2017-07-31T18:07:45ZFalse
MDU6SXNzdWUyNDcyNDc0NTA=make sure compare_all_algos lives up to the name2017-08-02T01:29:12ZFalse
MDU6SXNzdWUyNDcyNTE0OTI=let the user pass in their own model training code?2017-08-02T01:59:52ZFalse
MDU6SXNzdWUyNDcyNjQ1MDI=deep learning- don't get stuck predicting averages2017-08-02T03:40:44ZFalse
MDU6SXNzdWUyNDc5OTY0MzM=Problem with import2017-08-04T12:49:51Z2017-09-09T02:05:38ZTrue
MDU6SXNzdWUyNTA0MDcxNjY=ImportError: cannot import name frombuffer_empty2017-08-15T19:04:50Z2017-09-09T02:04:31ZTrue
MDU6SXNzdWUyNTA1NDEwNzA=ValueError: Iteration of zero-sized operands is not enabled2017-08-16T07:54:49Z2017-09-09T02:12:52ZTrue
MDU6SXNzdWUyNTA2OTY2MTQ=categorical column with float and np.nan throws error when being converted to strings only with lgbm2017-08-16T17:07:44ZFalse
MDU6SXNzdWUyNTE5ODg5OTg=Scikit learn  __version__ = '0.19.0' error2017-08-22T15:04:00Z2017-09-09T02:02:07ZTrue
MDU6SXNzdWUyNTIwMTExODM=How can I pass train/test splits to auto ml for classification?2017-08-22T16:11:05ZFalse
MDU6SXNzdWUyNTMwNTk2Nzc=Choosing best model from multiple models2017-08-26T03:56:37Z2017-09-09T02:10:43ZTrue
MDU6SXNzdWUyNTM0NjEzODQ=get_boston_dataset data while using  'DeepLearningRegressor', 'XGBRegressor'2017-08-28T21:24:03Z2017-09-09T02:19:57ZTrue
MDU6SXNzdWUyNTQ2NDc4MTA=Repeated KFold Cross Validation?2017-09-01T13:53:37ZFalse
MDU6SXNzdWUyNTY4MTA0NTc=ensembling2017-09-11T19:09:10ZFalse
MDU6SXNzdWUyNTcwMjA4OTQ=TypeError: 'int' object is not subscriptable2017-09-12T12:12:08Z2017-09-13T16:20:30ZTrue
MDU6SXNzdWUyNTc0NDE1NTQ=make column names strings, not ints2017-09-13T16:22:07ZFalse
MDU6SXNzdWUyNTgyMTcwNzM=more logging of versions in trained models2017-09-16T08:10:28ZFalse
MDU6SXNzdWUyNTgyMzIyMzg=Custom eval metrics2017-09-16T13:40:42Z2018-03-16T14:59:52ZTrue
MDU6SXNzdWUyNTg3Njc1Mjc=Classification evaluation: Adjust confusion matrix and derivative metrics?2017-09-19T10:12:39ZFalse
MDU6SXNzdWUyNTk0MDAzNTg=Got an unexpected keyword argument 'max_iter' in SGDClassifier2017-09-21T07:25:36Z2017-09-25T03:13:32ZTrue
MDU6SXNzdWUyNTk1MTQ3NTg=Update estimator default config2017-09-21T14:24:39Z2017-09-26T17:56:28ZTrue
MDU6SXNzdWUyNjAwNjM1OTE=increase iteration speed- take in transformed_X, and transformation_pipeline2017-09-24T06:55:23ZFalse
MDU6SXNzdWUyNjA2NTc2NDE=Error when using categorical ensemble2017-09-26T14:59:38Z2017-09-26T15:23:14ZTrue
MDU6SXNzdWUyNjExMjc3OTE=deep learning learning rate consistency across optimizers2017-09-27T21:44:08ZFalse
MDU6SXNzdWUyNjE4MjI4MDE=figure out what's going on with the latest version of lightgbm2017-09-30T06:34:42ZFalse
MDU6SXNzdWUyNjMwNzUyOTg=Argument 'X' has incorrect type (expected numpy.ndarray, got csr_matrix)2017-10-05T10:28:21Z2017-10-06T20:30:47ZTrue
MDU6SXNzdWUyNjQzMjQ3NjE=error during LGBM predict_proba2017-10-10T18:10:12Z2017-10-12T03:57:16ZTrue
MDU6SXNzdWUyNjQ2NjgxNTE=investigate ExtendedLabelEncoder more2017-10-11T17:18:10ZFalse
MDU6SXNzdWUyNjU1NDY0Mzc=Questions2017-10-15T05:07:02Z2017-10-24T21:11:57ZTrue
MDU6SXNzdWUyNjgwMjYyMDM=ImportError: cannot import name 'Bunch'2017-10-24T13:11:21Z2017-10-24T21:01:23ZTrue
MDU6SXNzdWUyNjgxODc3ODk=training- let the user override num_trees for iterative models2017-10-24T21:12:32ZFalse
MDU6SXNzdWUyNjgxODc5NDk=implement lightgbm's ranking predictors for confidence intervals, rather than sklearn's gradientboosting2017-10-24T21:13:08ZFalse
MDU6SXNzdWUyNjgxODgwMDc=docs- document X_test and y_test2017-10-24T21:13:21ZFalse
MDU6SXNzdWUyNjgxODgxNDY=speed up dataframevectorizer- can we parallelize it?2017-10-24T21:13:51ZFalse
MDU6SXNzdWUyNjgyMTczOTk=current projects2017-10-24T23:15:33ZFalse
MDU6SXNzdWUyNjg3NTk4Njg=LSTM2017-10-26T13:28:30Z2017-10-27T17:35:34ZTrue
MDU6SXNzdWUyNjk0ODQxNTA=A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.2017-10-30T05:16:10Z2017-11-02T21:05:24ZTrue
MDU6SXNzdWUyNzA2MDA3MTU=compare_all_models=True2017-11-02T10:22:21Z2017-11-10T20:05:55ZTrue
MDU6SXNzdWUyNzE1ODIxNzU=Improvements week of nov 62017-11-06T18:55:12ZFalse
MDU6SXNzdWUyNzE5ODA3NTM=dfv- pass through np.nans for lgbm2017-11-07T20:57:45ZFalse
MDU6SXNzdWUyNzIxMjI1MTQ=Exporting auto_ml models to use in other programming languages.2017-11-08T09:03:23ZFalse
MDU6SXNzdWUyNzMwNDcxNzU=feature_responses2017-11-10T20:17:49ZFalse
MDU6SXNzdWUyNzM2MDAxOTA=boston prices example2017-11-13T22:25:30Z2017-11-15T16:08:53ZTrue
MDU6SXNzdWUyNzQ5MDEzNzA=optimize_final_model and XGBoost vs GradientBoosting2017-11-17T15:30:39ZFalse
MDU6SXNzdWUyNzUzOTExNzA=optimize_final_model does not work with a classification pipeline2017-11-20T15:18:11ZFalse
MDU6SXNzdWUyNzcxODQzNjE=today's improvements2017-11-27T21:59:53ZFalse
MDU6SXNzdWUyNzgzMzU5OTI=memory improvements2017-12-01T02:17:09ZFalse
MDU6SXNzdWUyNzk2Mzg2NDk=investigate feature scaling more2017-12-06T06:09:27ZFalse
MDU6SXNzdWUyODExMjY1NDI=Issue with NLP data.2017-12-11T18:46:20Z2018-02-09T18:24:02ZTrue
MDU6SXNzdWUyODIyNDcyNjA=gs issues2017-12-14T21:38:49ZFalse
MDU6SXNzdWUyODIyODAzODQ=lgbm max_bin parameter will be deprecated2017-12-15T00:10:26Z2018-02-09T00:49:00ZTrue
MDU6SXNzdWUyODU0ODM1MTc=FutureWarning + KeyError2018-01-02T17:06:06ZFalse
MDU6SXNzdWUyODU0ODcyMTc=TypeError: Cannot cast ufunc add output ...2018-01-02T17:21:21Z2018-02-09T18:23:15ZTrue
MDU6SXNzdWUyODU3MTIxMzI=Make most of requirements optional and load them lazily2018-01-03T15:03:56Z2018-02-09T01:23:53ZTrue
MDU6SXNzdWUyODYwMzk5MDc=Error running tutorial example2018-01-04T16:27:28Z2018-02-09T01:33:37ZTrue
MDU6SXNzdWUyODY1NTY3MDI=Adding new pipeline steps2018-01-07T09:31:29Z2018-01-10T17:39:20ZTrue
MDU6SXNzdWUyODcxMjU5MjE=Question: Training fails with AttributeError  'DataFrame' object has no attribute 'FR_Incrementing'2018-01-09T15:22:56Z2018-02-09T18:21:07ZTrue
MDU6SXNzdWUyODczNDA3MTI=Error on multiclass classifying dataset when compare_all_model = True2018-01-10T07:38:27ZFalse
MDU6SXNzdWUyODc1MjE3MTU=Calibrate_final_model doesnt accept y_test dataset2018-01-10T17:47:38Z2018-03-05T07:46:33ZTrue
MDU6SXNzdWUyODgzMTI3OTk=Use of custom scoring function2018-01-13T08:34:01ZFalse
MDU6SXNzdWUyODk0NzAwMDQ=Error when training with optimize_final_model = True2018-01-18T01:11:40Z2018-01-19T01:54:31ZTrue
MDU6SXNzdWUyOTA1NzYxMTM=Train gives errors with DeepLearningClassifier, DeepLearningRegressor, LinearRegression and Ridge2018-01-22T18:54:37ZFalse
MDU6SXNzdWUyOTE4MzM1ODc=can auto_ml Regressor support multi label2018-01-26T08:47:33Z2018-02-09T02:05:05ZTrue
MDU6SXNzdWUyOTM2NDk0OTE=grid search bug- need to add copy_reg back in most likely2018-02-01T19:12:34ZFalse
MDU6SXNzdWUyOTU2ODUyMjE=we overwrite model__n_estimators after grid searching for lgbm2018-02-08T22:16:11Z2018-02-09T02:05:25ZTrue
MDU6SXNzdWUyOTU2OTYwMTE=Error training dataset2018-02-08T22:58:48Z2018-02-09T18:20:08ZTrue
MDU6SXNzdWUyOTU3NjUwMjA=Sometimes for hyperparams optimization sklearn-deap does poorly.2018-02-09T06:10:08ZFalse
MDU6SXNzdWUyOTY1OTQ3NDg=edge case: let the user pass in a .csv file as X_test_already_transformed2018-02-13T02:37:49ZFalse
MDU6SXNzdWUyOTY5NDAwNjk=create a score_intervals function2018-02-14T00:54:10ZFalse
MDU6SXNzdWUzMDMwNDY5NDA=Feature Request: Give option to limit the training time or number of iterations2018-03-07T10:39:06ZFalse
MDU6SXNzdWUzMDMzMDEzNTI=Idea: more thoughts on feature_learning (embeddings, representations, etc.)2018-03-07T23:39:32ZFalse
MDU6SXNzdWUzMDMzMDIwMTU=documentation goals2018-03-07T23:42:18ZFalse
MDU6SXNzdWUzMDQ3MzAzMzA=Error Running Multiple Classifiers2018-03-13T11:42:24ZFalse
MDU6SXNzdWUzMDUwMDk4ODc=Question about RNN,CNN2018-03-14T03:22:52ZFalse
MDU6SXNzdWUzMTQ4MzQ1MDE=Serving predictions through AWS Lambda?2018-04-16T22:03:18ZFalse
MDU6SXNzdWUzMTg2MTI3MDk=Can  I  change the model_params and see  parameters of the saved model?Advise to provide options.2018-04-28T08:12:37ZFalse
MDU6SXNzdWUzMTg4NDgzMTk=Using different Regression models is not working properly2018-04-30T10:37:59ZFalse
MDU6SXNzdWUzMjYyMTE4NjI=Logistic Regression does not work2018-05-24T17:07:05ZFalse
MDU6SXNzdWUzMzU4NjE5NjI=Interpretation of Brier Score2018-06-26T14:59:48ZFalse
MDU6SXNzdWUzMzkyNzE1MDA=sounds great, but may you share what are you doing? how it works ?2018-07-09T00:22:10ZFalse
MDU6SXNzdWUzNDE5Mjc0MjA=README.md typo2018-07-17T13:48:14ZFalse
MDU6SXNzdWUzNDY0NzY5MTM=DeepLearningClassifier does not work while default classifier works  for digits dataset 2018-08-01T07:17:24ZFalse
MDU6SXNzdWUzNDc3MjM0NjM=Dropout2018-08-05T19:15:34ZFalse
MDU6SXNzdWUzNTM2MDQ2NTQ=The sorting of model analytics output is incorrect in predictor.py2018-08-24T00:50:20ZFalse
MDU6SXNzdWUzNTM2Mjg3Mjk= Loading deep learning model has an error2018-08-24T03:15:49ZFalse
MDU6SXNzdWUzNTM5ODgyODU=How can I use this toolkit to do multi-output regression?2018-08-25T06:27:28ZFalse
MDU6SXNzdWUzNTQ2ODE3NzA='DeepLearningClassifier' using GPU2018-08-28T11:08:28ZFalse
MDU6SXNzdWUzNTk3ODUzNTM=Can I get the same results for the same dataset2018-09-13T08:03:23ZFalse
MDU6SXNzdWUzNjIyNzA0MTY=error for test case from front page2018-09-20T16:38:32ZFalse
MDU6SXNzdWUzNzU1MDc1NDg=Error when training with optimize_final_model = True2018-10-30T14:06:35ZFalse
MDU6SXNzdWUzNzk0ODExMDM=I want update scikit-learn Vesion to 0.19.0 from 0.18.2.　But not going well... Please Help me.2018-11-11T02:00:35Z2018-11-14T02:20:45ZTrue
MDU6SXNzdWUzOTUxNjU4OTA=Can someone please explain the concept of 'categorical ensembling' intuitively? Is it the same as categorical embedding?2019-01-02T07:17:18Z2019-01-03T06:28:49ZTrue
MDU6SXNzdWUzOTUxNjg2Mzk="""optimize_final_model=True"" fails !!"2019-01-02T07:35:59ZFalse
MDU6SXNzdWU0MDExMTgzODU=ValueError: fill value must be in categories2019-01-20T17:15:40ZFalse
MDU6SXNzdWU0MjI0MzI4MDE=Problem with utils_scoring score function when using 'roc_auc'2019-03-18T21:01:05ZFalse
MDU6SXNzdWU0MjI0ODg5NjE=Active?2019-03-19T00:16:51ZFalse
MDU6SXNzdWU0MzkwNjM1ODQ=transform_categorical_col cannot handle col_names that are a substring of another col_name2019-05-01T04:14:06ZFalse
MDU6SXNzdWU0NTAxNTI2MzA=Error n_jobs >12019-05-30T06:29:50ZFalse
MDU6SXNzdWU0NTAxODA0Mzk=the model_names don't show when the ensemble_config is setted2019-05-30T07:57:39ZFalse
MDU6SXNzdWU0NTAxODA4MzU=can I get the all models from training2019-05-30T07:58:47ZFalse
MDU6SXNzdWU0NjI3MDA1MTk=Multiclass with DeepLearningClassifier2019-07-01T12:58:55ZFalse
MDU6SXNzdWU0ODIwMjQ4NjE=Explanation of algorithm?2019-08-18T18:47:42ZFalse
MDU6SXNzdWU1NDUyNjAyMTM=Imblearn incompatibility.2020-01-04T08:49:52Z2020-01-08T01:18:05ZTrue
