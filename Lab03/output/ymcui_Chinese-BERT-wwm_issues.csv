idtitlecreatedAtclosedAtclosed
MDU6SXNzdWU0NTgzNzEzMzA=XNLI的测试集只有2.5k，少于自己下的2019-06-20T06:26:05Z2019-06-20T11:09:06ZTrue
MDU6SXNzdWU0NTg0MDIwOTk=只能在百度的Paddle 平台上玩儿？2019-06-20T07:38:32Z2019-06-20T11:05:15ZTrue
MDU6SXNzdWU0NTg2MDc1NDg=MSRA-NER数据集是否有下载地址2019-06-20T11:43:25Z2019-06-20T11:47:34ZTrue
MDU6SXNzdWU0NTg2MTYwNjY=我想问下全词mask的一个小细节2019-06-20T12:02:10Z2019-06-21T02:20:42ZTrue
MDU6SXNzdWU0NTkwMzgzMTY=Sina Weibo数据的具体划分方式是怎样的2019-06-21T06:46:12Z2019-06-21T07:29:48ZTrue
MDU6SXNzdWU0NTk1NDc2NjI=请问这个训练模型有什么用？2019-06-23T07:57:30Z2019-06-23T08:04:04ZTrue
MDU6SXNzdWU0NTk1NTE4NTA=ner评估是用的那个值2019-06-23T08:48:16Z2019-06-28T03:41:28ZTrue
MDU6SXNzdWU0NTk3MDg3OTQ=请问一下，我用bert-as-service去启动整个模型有一些问题2019-06-24T06:19:26Z2019-06-24T06:35:24ZTrue
MDU6SXNzdWU0NjAzMDM1MzA=cmrc 2108数据集中的问题2019-06-25T09:10:29Z2019-06-25T09:23:24ZTrue
MDU6SXNzdWU0NjAzMDcxNjE=是否有计划将代码开源？2019-06-25T09:17:49Z2019-06-25T09:29:44ZTrue
MDU6SXNzdWU0NjAzNjIyNTA=没能复现CMRC2018的结果2019-06-25T11:15:32Z2019-06-26T04:59:55ZTrue
MDU6SXNzdWU0NjA5NzIxNTQ=ner预测问题2019-06-26T13:30:15Z2019-06-28T03:41:38ZTrue
MDU6SXNzdWU0NjEyNjY2OTk=Chinese-BERT-wwm对于Masked LM 任务（完形填空，ERNIE中提到的那种），表现怎么样？有测试过么？2019-06-27T02:05:00Z2019-06-28T03:41:46ZTrue
MDU6SXNzdWU0NjEyODU5OTA=阅读理解在实现上是不是有问题2019-06-27T03:25:18Z2019-06-29T10:07:52ZTrue
MDU6SXNzdWU0NjE4Mzg3NTg=新闻分类的数据集里面有大于512长度的数据吗，你们是如何处理的2019-06-28T03:31:55Z2019-06-28T03:41:13ZTrue
MDU6SXNzdWU0NjE4NzI2NzI=tensorflow版本和hugging face torch版本的weights是否一致？2019-06-28T06:08:04Z2019-07-03T04:21:15ZTrue
MDU6SXNzdWU0NjM1MzAyMDA=Chinese-BERT-wwm基础上做预训练的方式2019-07-03T03:49:10Z2019-07-05T00:25:37ZTrue
MDU6SXNzdWU0NjM1ODUzMjg=Chinese-BERT-wwm fine-tuning2019-07-03T07:16:23Z2019-07-03T07:28:51ZTrue
MDU6SXNzdWU0NjM3MDU3OTk=要怎么样下载bqcorpus数据集呢？2019-07-03T11:46:38Z2019-07-04T01:30:59ZTrue
MDU6SXNzdWU0NjU2Nzg2NTA=基于分词预训练中文Bert2019-07-09T09:40:38Z2019-07-09T10:47:00ZTrue
MDU6SXNzdWU0Njc5NjMyMjY=云盘的tensorflow版本的预训练模型链接已经打不开了2019-07-15T06:38:45Z2019-07-15T06:45:00ZTrue
MDU6SXNzdWU0Njc5ODcxNzQ=question of bert model size2019-07-15T07:53:52Z2019-07-16T03:03:28ZTrue
MDU6SXNzdWU0NzA3MzQ0MTM=请问你们预训练了多少轮，最后如何判断模型收敛呢？2019-07-21T02:30:12Z2019-07-22T03:10:58ZTrue
MDU6SXNzdWU0NzQ5MTgxMDU=关于阅读理解的问题2019-07-31T03:33:55Z2019-07-31T03:44:35ZTrue
MDU6SXNzdWU0NzU0NTAzNDc=模型转换失效，请求提供pytorch版本2019-08-01T03:22:11Z2019-08-01T03:50:07ZTrue
MDU6SXNzdWU0NzYxMTc5NzM=「THUCNews：篇章级文本分类」任务的评测结果2019-08-02T10:44:32Z2019-08-02T10:51:26ZTrue
MDU6SXNzdWU0NzY2MjMzMzI=文本分类问题2019-08-05T01:57:58Z2019-08-06T06:32:08ZTrue
MDU6SXNzdWU0NzgzNzI1ODI=请问你们大概训了多少轮2019-08-08T10:05:09Z2019-08-08T12:59:49ZTrue
MDU6SXNzdWU0Nzg3NzMyODY=求预训练代码2019-08-09T03:05:43Z2019-08-20T03:20:32ZTrue
MDU6SXNzdWU0ODE1MDAxOTk=如何移除训练用的变量2019-08-16T08:24:52Z2019-08-16T10:09:15ZTrue
MDU6SXNzdWU0ODI4Mjk0MDE=关于模型选择的疑问2019-08-20T12:26:05Z2019-08-22T03:50:24ZTrue
MDU6SXNzdWU0ODMxNTk3ODI=DRCD數據集，在前處理時卡住2019-08-21T01:56:08Z2019-08-21T03:48:59ZTrue
MDU6SXNzdWU0ODQ0NDA5NjM=请问mask策略2019-08-23T09:53:41Z2019-08-23T11:37:04ZTrue
MDU6SXNzdWU0ODQ4MDMzNTc=关于优化器的选择2019-08-24T10:31:59Z2019-08-24T23:08:16ZTrue
MDU6SXNzdWU0ODYyOTY2NTI=关于词典的问题2019-08-28T10:36:37Z2019-09-05T08:20:55ZTrue
MDU6SXNzdWU0ODcyMDExMDU=Some question about training with LCQMC dataset2019-08-29T22:20:05Z2019-09-05T08:21:06ZTrue
MDU6SXNzdWU0ODgwMTEwNTE=same corpus2019-09-02T05:58:15Z2019-09-05T08:22:41ZTrue
MDU6SXNzdWU0OTA1ODA1ODM=NER-MSRA的结果无法复现2019-09-07T02:21:57Z2019-10-21T11:01:10ZTrue
MDU6SXNzdWU0OTA5MjQ4NjE=MRC任务loss降不下去2019-09-09T07:28:52Z2019-10-21T10:59:37ZTrue
MDU6SXNzdWU0OTA5NDM4NjM=关于模型的tokenizer2019-09-09T08:09:41Z2019-09-12T03:26:21ZTrue
MDU6SXNzdWU0OTI1Mzc5NzA=显存不够问题2019-09-12T01:25:25Z2019-10-21T10:59:48ZTrue
MDU6SXNzdWU0OTI1ODgxMzQ=关于模型input embedding2019-09-12T05:07:48Z2019-09-12T09:22:58ZTrue
MDU6SXNzdWU0OTI3Mzk4Mjk=thucnews验证集的准确率很低2019-09-12T11:12:21Z2019-09-18T03:40:02ZTrue
MDU6SXNzdWU0OTM2MzU5ODk=请问有fine tune代码提供吗2019-09-14T15:40:54Z2019-10-21T11:01:02ZTrue
MDU6SXNzdWU0OTM2ODM0MjU=请问bert-wwm-ext有对下游任务的结果汇报吗2019-09-15T01:24:23Z2019-10-16T00:03:22ZTrue
MDU6SXNzdWU0OTQzODA4NTk=RoBERTa-wwm-ext, 这个模型的问题。2019-09-17T03:29:38Z2019-09-26T02:46:09ZTrue
MDU6SXNzdWU0OTUwNzg5MzQ=RoBERTa这个模型，取消了NSP loss以后，[CLS] 或者说 <S> 这个初始token是如何得到的呢？2019-09-18T08:46:31Z2019-09-20T09:02:58ZTrue
MDU6SXNzdWU0OTYxMDM4MDM=ext预训练数据集大小2019-09-20T02:00:28Z2019-09-25T01:26:30ZTrue
MDU6SXNzdWU0OTY2MDI0NjA=关于BPE tokenizer没有在项目里提及2019-09-21T02:17:37Z2019-09-21T02:27:33ZTrue
MDU6SXNzdWU0OTgxMDIzMzc=Roberta-large 计划2019-09-25T07:30:36Z2019-09-26T02:36:43ZTrue
MDU6SXNzdWU0OTg2MjY2NzY=ValueError: Couldn't find 'checkpoint' file or checkpoints in given directory chinese_roberta_wwm_ext_L-12_H-768_A-122019-09-26T03:00:02Z2019-10-21T11:01:25ZTrue
MDU6SXNzdWU1MDAwMjc3MTU=roberta模型加载错误2019-09-30T03:16:33Z2019-09-30T03:21:17ZTrue
MDU6SXNzdWU1MDYyNjMyMzE=预训练数据清洗问题2019-10-13T02:15:48Z2019-10-25T05:35:47ZTrue
MDU6SXNzdWU1MDY1MzkyNzg=有roberta large版本的下载地址吗2019-10-14T09:27:47Z2019-10-15T00:26:08ZTrue
MDU6SXNzdWU1MDY5ODE3NjI=微调roberta large需要什么样的配置2019-10-15T03:26:28Z2019-10-16T00:00:39ZTrue
MDU6SXNzdWU1MDcwNTMwMzk=如果目标任务的数据和预训练模型的领域相差较大，请在自己的数据集上进一步做预训练。2019-10-15T07:13:58Z2019-10-16T00:00:20ZTrue
MDU6SXNzdWU1MDk4MjQxMTg=请教长文本分类问题 ,关于Thunews结果.2019-10-21T08:54:41Z2019-10-23T06:28:51ZTrue
MDU6SXNzdWU1MDk4MzgxNDg=请问如何获得训练数据?2019-10-21T09:20:49Z2019-10-21T09:38:09ZTrue
MDU6SXNzdWU1MDk4NTgyODM=你好，请问为什么这个新的24层的模型做一个文本情感分类的fine tune效果这么差 acc只有0.54 相反12层的可以达到0.94  用的是google-bert里面的run_classifier.py2019-10-21T09:58:36Z2019-10-21T10:06:07ZTrue
MDU6SXNzdWU1MDk4Njk3MzU=请问有遇到过这个错的吗2019-10-21T10:20:43Z2019-11-01T14:24:11ZTrue
MDU6SXNzdWU1MTA1MzA4MDg=做下游分类任务的时候，1.需要分词么，我看vocab.txt仍然是字不是词； 2.如果分词，可以用jieba等非lpa的工具吗2019-10-22T09:21:58Z2019-10-25T05:35:26ZTrue
MDU6SXNzdWU1MTA3MzQ5MDk=请教一下输入token如果是词内部的字，使用的token是'字'还是'##字'?2019-10-22T15:26:44Z2019-10-25T05:35:20ZTrue
MDU6SXNzdWU1MTE2MDA1ODQ=转换预训练参数在paddlepaddle下使用2019-10-23T22:17:20Z2019-10-25T05:35:14ZTrue
MDU6SXNzdWU1MTE3Nzk5MjQ=pytorch加载模型遇到错误2019-10-24T08:09:53Z2019-10-30T12:08:29ZTrue
MDU6SXNzdWU1MTI2MjE3MzU=如何使用google bert 训练好的checkpoint在自己的语料上继续训练2019-10-25T17:02:07Z2019-11-05T04:30:31ZTrue
MDU6SXNzdWU1MTMxOTY0MjI=关于在您发布的预训练模型之上进一步预训练2019-10-28T09:43:13Z2019-11-06T02:57:39ZTrue
MDU6SXNzdWU1MTMzNDUxNzM=THUNews中的文章过长2019-10-28T14:36:45Z2019-11-01T14:27:08ZTrue
MDU6SXNzdWU1MTY3OTA4OTA=请问下：论文中分类的评价指标用的什么？     3.4 Sentiment Classification: ChnSentiCorp, Sina Weibo    3.6 Document Classification: THUCNews2019-11-03T07:14:24Z2019-11-03T07:44:38ZTrue
MDU6SXNzdWU1MTY3OTc3NTc=THUCNews，acc很低（0.027177358580844267）大概怎么回事 。我的参数如下2019-11-03T09:42:39Z2019-11-05T04:31:11ZTrue
MDU6SXNzdWU1MTkxNzE0NjE=在预训练Roberta的时候需要像原来训练Bert一样加上CLS SEP SEP, 还是直接CLS SEP2019-11-07T10:18:28Z2019-11-08T04:03:21ZTrue
MDU6SXNzdWU1MTkyMjg2NDM=通用数据哪里可以获取2019-11-07T12:11:40Z2019-11-08T04:04:00ZTrue
MDU6SXNzdWU1MTk4Mjg0MTY=Roberta预训练时，学习率是多少2019-11-08T06:03:38Z2019-11-08T06:50:08ZTrue
MDU6SXNzdWU1MjA4MjUwNjE=关于训练语料生成时候的分句2019-11-11T09:07:49Z2019-11-12T04:59:24ZTrue
MDU6SXNzdWU1MjIxMTYwMTY=对于对话文本的阅读理解的效果怎样2019-11-13T10:39:27Z2019-11-18T12:34:39ZTrue
MDU6SXNzdWU1MjQ3MzgwODQ=About the learning rate of RoBerta in the finetuning stage?2019-11-19T02:43:59Z2019-11-19T02:55:27ZTrue
MDU6SXNzdWU1MjQ4Mzk1ODU=对RoBERTa-wwm-ext-large模型的疑问2019-11-19T08:03:26Z2019-11-19T09:14:35ZTrue
MDU6SXNzdWU1MjQ4NDYwODc=Do you have plans to release Chinese ALBERT model?2019-11-19T08:18:32Z2019-11-21T01:40:09ZTrue
MDU6SXNzdWU1MzE2NjMyMTg=你在google tpu v3-8上训练roberta large的时候， batch size大小是多少2019-12-03T02:11:04Z2019-12-03T05:24:03ZTrue
MDU6SXNzdWU1MzI1NDA4NTY=Some questions about the RoBERTa-wwm-ext-large2019-12-04T09:02:12Z2019-12-13T06:37:17ZTrue
MDU6SXNzdWU1NDQxMjA0MjQ=能否获得其他维数的向量?2019-12-31T08:01:10Z2019-12-31T09:04:57ZTrue
MDU6SXNzdWU1NDQzMjQ1ODQ=BERT-wwm-ext, Chinese 讯飞云下载地址失效2020-01-01T07:32:55Z2020-01-01T07:55:26ZTrue
MDU6SXNzdWU1NDQ0MDU3MTE=Chinese-BERT-wwm与Chinese-PreTrained-XLNet的模型下载地址有错误2020-01-01T22:29:18Z2020-01-02T00:41:30ZTrue
MDU6SXNzdWU1NDU1NjcxNzU=外链失效2020-01-06T06:40:15Z2020-01-06T07:17:57ZTrue
MDU6SXNzdWU1NDc0MDIyMzM=couldn't  load the model RoBERTa-wwm-ext-large2020-01-09T10:52:37Z2020-01-13T05:02:56ZTrue
MDU6SXNzdWU1NDc0NTc4MTU=BERT-wwm-ext, Chinese 和BERT-wwm, Chinese下载pytorch版本，model.bin参数是一样的大小?2020-01-09T12:48:14Z2020-01-09T13:12:54ZTrue
MDU6SXNzdWU1NDc5NDY2Mjk=现在预训练模型的url都无法打开，请问可以在哪里下载2020-01-10T08:53:54Z2020-01-13T04:58:08ZTrue
MDU6SXNzdWU1NDgzODQ3MzA=请问一下有如下的权重可以分享吗?2020-01-11T05:32:23Z2020-01-11T06:49:49ZTrue
MDU6SXNzdWU1NDg2NjE5ODE=相似度2020-01-13T01:29:14Z2020-01-13T05:13:21ZTrue
MDU6SXNzdWU1NTY4NDQ3MTk=tokenize后的tokens需要自己加[CLS]和[SEP]吗？2020-01-29T12:56:23Z2020-02-07T06:00:19ZTrue
MDU6SXNzdWU1NzA1NjMyMjU=MaskedLM模型？2020-02-25T13:17:41Z2020-02-25T15:13:12ZTrue
MDU6SXNzdWU1Nzc1MTgxMjU=关于pipeline2020-03-08T15:27:10Z2020-03-11T04:50:48ZTrue
MDU6SXNzdWU1ODIxMDgxMjk=想请问怎么把这个模型放到TFBertModel中，可否提供模型的h5文件？2020-03-16T08:44:17Z2020-03-17T01:46:22ZTrue
MDU6SXNzdWU1ODI3MjgxNTE=请问英文的roberta预训练模型哪里可以找得到？？？2020-03-17T03:25:41Z2020-03-17T04:15:25ZTrue
MDU6SXNzdWU1ODI5MjcyMTU=RBT3、RBTL3相关介绍2020-03-17T10:56:40Z2020-03-20T13:57:48ZTrue
MDU6SXNzdWU1ODM4MDM4Mzk=Bert 训练未标记的中文数据相关2020-03-18T15:18:03Z2020-03-22T10:00:24ZTrue
MDU6SXNzdWU1ODYxNDY0NzA=请问词表文件中为什么汉字既有加双##的，也有不加的？2020-03-23T11:43:45Z2020-03-23T13:39:21ZTrue
MDU6SXNzdWU1OTA5ODkyODc=关于chinese-roberta-wwm-ext-large模型的问题2020-03-31T10:34:24Z2020-04-01T03:05:43ZTrue
MDU6SXNzdWU1OTM3OTMxMzY=为什么讯飞云下载要一天2020-04-04T10:31:59Z2020-04-04T10:51:38ZTrue
MDU6SXNzdWU1OTM3OTMzNjM=下载好慢2020-04-04T10:33:24Z2020-04-08T02:36:21ZTrue
MDU6SXNzdWU1OTYyNjQ1ODc=RBTL3预测结果随机性2020-04-08T02:28:32Z2020-04-17T07:08:52ZTrue
MDU6SXNzdWU1OTcyODM4NTU=下载2020-04-09T13:30:13Z2020-04-17T07:09:10ZTrue
MDU6SXNzdWU1OTcyODY5NDM=使用Transformers加载模型2020-04-09T13:34:55Z2020-04-17T07:11:05ZTrue
MDU6SXNzdWU1OTg4MDgyMTQ=无法加载chinese-roberta-wwm-ext模型2020-04-13T10:24:44Z2020-04-30T03:48:57ZTrue
MDU6SXNzdWU1OTkyNTU2NzU=无法使用transformers快速加载模型2020-04-14T02:42:58Z2020-04-17T07:13:13ZTrue
MDU6SXNzdWU2MDA3MTEyMzY=请教下两阶段预训练的schedule设置的细节2020-04-16T02:59:54Z2020-05-04T11:31:27ZTrue
MDU6SXNzdWU2MDA3ODU3NTM=readme 存在一个死链2020-04-16T06:38:52Z2020-04-17T07:10:20ZTrue
MDU6SXNzdWU2MDI0MDMwNzM=请教roberta的segment id2020-04-18T07:53:30Z2020-04-30T03:49:20ZTrue
MDU6SXNzdWU2MDMwNDQ2Nzk=关于Squad方案bert+AoA+DAE2020-04-20T08:28:53Z2020-04-20T08:45:28ZTrue
MDU6SXNzdWU2MDM2ODI1MjI=Pytorch版能直接在transformers里面用吗？2020-04-21T03:43:31Z2020-04-21T07:28:51ZTrue
MDU6SXNzdWU2MDcxNTc5Mzk=MaskedLM的head能开源吗？2020-04-27T00:45:34Z2020-04-28T16:46:09ZTrue
MDU6SXNzdWU2MDg3NTkzMzE=使用chinese_roberta_wwm_ext_L-12_H-768_A-12预训练模型时出现以下错误？请问是什么原因呢？2020-04-29T03:55:04Z2020-05-07T06:09:31ZTrue
MDU6SXNzdWU2MTMyNzQ1MTA=中文文本里面混有韩文的时候tokenize会出错2020-05-06T12:16:59Z2020-05-07T06:03:48ZTrue
MDU6SXNzdWU2MTM5MDQ2NTY=请问同一个模型（如RoBERTa-wwm-ext, Chinese），tensorflow版和pytorch版，模型输出是一样的吗2020-05-07T09:21:13Z2020-05-12T05:09:18ZTrue
MDU6SXNzdWU2MTUwOTE3MTY=请问一下roberta-wwm的输入的ids最大size是不是512 ?2020-05-09T04:50:09Z2020-05-09T05:36:04ZTrue
MDU6SXNzdWU2MTUyOTg1MTM=请问预训练过程中的标点符号是用的中文还是英文？2020-05-10T02:09:55Z2020-05-11T01:55:13ZTrue
MDU6SXNzdWU2MTczMjAyNDQ=看表格感觉是 中文是字级别的mask，英文是全词mask？2020-05-13T10:09:01Z2020-05-13T12:00:06ZTrue
