idtitlecreatedAtclosedAtclosed
MDU6SXNzdWUzNzc1OTI2MzE=run_squad questions2018-11-05T21:35:51Z2018-11-07T22:37:09ZTrue
MDU6SXNzdWUzNzc2OTgzNzg=MRPC hyperparameters question2018-11-06T05:30:36Z2018-11-07T23:42:51ZTrue
MDU6SXNzdWUzNzc3MzY4NDQ=Failure during pytest (and solution for python3)2018-11-06T08:23:29Z2018-11-07T23:43:42ZTrue
MDU6SXNzdWUzNzg5MzU1OTU=Crash at the end of training2018-11-08T22:01:57Z2018-11-09T08:17:26ZTrue
MDU6SXNzdWUzNzg5OTY4MzE=Is there a plan to have a FP16 for GPU so to have larger batch size or longer text documents support ?2018-11-09T02:23:34Z2018-11-12T16:06:47ZTrue
MDU6SXNzdWUzNzkwMzYzOTQ=Swapped to_seq_len/from_seq_len in comment2018-11-09T06:13:08Z2018-11-09T08:31:25ZTrue
MDU6SXNzdWUzNzk0MjIwOTA=py2 code2018-11-10T13:23:31Z2018-11-10T15:06:35ZTrue
MDU6SXNzdWUzNzk0NDA3NTk=Bug in run_classifier.py2018-11-10T17:16:01Z2018-11-10T17:45:28ZTrue
MDU6SXNzdWUzODAyNzExMzQ=activation function in BERTIntermediate2018-11-13T15:09:33Z2018-11-13T15:17:39ZTrue
MDU6SXNzdWUzODA1NTUxMzI=will you push the pytorch code for the pre-training process?2018-11-14T06:30:59Z2018-11-17T21:55:41ZTrue
MDU6SXNzdWUzODA1ODE0OTU=model loading the checkpoint error2018-11-14T08:13:34Z2018-11-15T21:02:04ZTrue
MDU6SXNzdWUzODEyNTA5MjE=ValueError while using --optimize_on_cpu2018-11-15T16:53:12Z2018-11-17T21:56:46ZTrue
MDU6SXNzdWUzODEzODc3MTc=[Feature request] Port SQuAD 2.0 support2018-11-15T23:47:04Z2018-11-17T21:57:07ZTrue
MDU6SXNzdWUzODE0OTA1ODQ=can you push the run-pretraining and create_pretraining_data codes?2018-11-16T08:15:33Z2018-11-17T21:57:19ZTrue
MDU6SXNzdWUzODE3MTg0MjQ=Checkpoints not saved2018-11-16T18:50:27Z2018-11-17T22:02:08ZTrue
MDU6SXNzdWUzODE4MzM2OTQ=how to load checkpoint?2018-11-17T06:23:28Z2018-11-17T06:50:57ZTrue
MDU6SXNzdWUzODE4MzU0MzY=speed is very slow2018-11-17T06:51:54Z2018-11-17T22:02:38ZTrue
MDU6SXNzdWUzODE4NzIwNzE=[Feature request] Add example of finetuning the pretrained models on custom corpus2018-11-17T15:19:58Z2018-11-17T22:03:43ZTrue
MDU6SXNzdWUzODE5MjA1MjI=BERT model for Machine Translation2018-11-18T02:10:15Z2018-11-18T08:48:33ZTrue
MDU6SXNzdWUzODE5Mzk3OTI=[Bug report] Ineffective no_decay when using BERTAdam2018-11-18T08:28:52Z2018-11-20T09:07:58ZTrue
MDU6SXNzdWUzODE5NjU4MzM=Can not find vocabulary file for Chinese model2018-11-18T14:33:58Z2018-11-19T03:17:31ZTrue
MDU6SXNzdWUzODE5OTgwNDA=issues with accents on convert_ids_to_tokens()2018-11-18T20:41:24Z2018-11-19T08:39:56ZTrue
MDU6SXNzdWUzODIwNTQ2MjY=How to detokenize a BertTokenizer output?2018-11-19T04:39:04Z2018-11-20T09:07:39ZTrue
MDU6SXNzdWUzODIyNjUxNzQ=using BERT as a language Model2018-11-19T15:26:20Z2018-11-20T09:06:07ZTrue
MDU6SXNzdWUzODIyOTc0NDQ=truncated normal initializer2018-11-19T16:35:08Z2018-11-26T09:42:42ZTrue
MDU6SXNzdWUzODIzMDA4Njk=Command-line interface Document Bug2018-11-19T16:42:56Z2018-11-20T09:03:06ZTrue
MDU6SXNzdWUzODI0ODk3NTE=Typo in README2018-11-20T03:52:35Z2018-11-20T09:02:15ZTrue
MDU6SXNzdWUzODI1NTM1ODk=grad is None in squad example2018-11-20T08:38:03Z2018-11-20T23:04:28ZTrue
MDU6SXNzdWUzODI1NzY1NTk=Race condition when prepare pretrained model in distributed training 2018-11-20T09:40:25Z2018-11-26T09:23:03ZTrue
MDU6SXNzdWUzODI1Nzk3MTc=Issue of `bert_model` arg in `run_classify.py`2018-11-20T09:48:09Z2018-11-20T13:07:14ZTrue
MDU6SXNzdWUzODI2NDkxMDM=Assertion `srcIndex < srcSelectDimSize` failed.2018-11-20T12:50:41Z2018-11-21T09:02:51ZTrue
MDU6SXNzdWUzODI3NjE3NzE=Fine-Tuned BERT-base on Squad v1. 2018-11-20T17:04:09Z2018-11-21T09:02:04ZTrue
MDU6SXNzdWUzODI5Mzc3MTg=example for is next sentence2018-11-21T03:16:00Z2018-11-21T09:40:15ZTrue
MDU6SXNzdWUzODMwMjg4NDQ=Multilingual Issue2018-11-21T09:32:32Z2018-11-21T09:39:41ZTrue
MDU6SXNzdWUzODMwNTUyMzU=pytorch_pretrained_bert/convert_tf_checkpoint_to_pytorch.py  error2018-11-21T10:36:49Z2018-11-21T11:10:58ZTrue
MDU6SXNzdWUzODMxNjIzMTk=Missing options/arguments in run_squad.py for BERT Large2018-11-21T15:10:45Z2018-11-26T08:57:23ZTrue
MDU6SXNzdWUzODM1ODYxNTY=UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 3920: character maps to <undefined>2018-11-22T15:42:08Z2018-11-23T11:21:56ZTrue
MDU6SXNzdWUzODM5NDY3MzY=Multi-GPU training vs Distributed training2018-11-24T00:49:45Z2018-11-26T09:03:23ZTrue
MDU6SXNzdWUzODM5NjcxMDY=example in BertForSequenceClassification() conflicts with the api 2018-11-24T07:27:50Z2018-11-26T08:54:47ZTrue
MDU6SXNzdWUzODQwNDQ2NjY=Loss calculation error2018-11-25T03:48:17Z2018-11-26T08:52:00ZTrue
MDU6SXNzdWUzODQyNzYwNTk=[Feature request ] Add support for the new cased version of the multilingual model2018-11-26T10:56:18Z2018-11-30T22:28:32ZTrue
MDU6SXNzdWUzODQ1MjUzMzk=Missing function convert_to_unicode in tokenization.py2018-11-26T21:50:15Z2018-11-26T22:33:47ZTrue
MDU6SXNzdWUzODUxNTg1OTU=not good when I use BERT for seq2seq model in keyphrase generation2018-11-28T08:44:24Z2018-11-29T07:47:06ZTrue
MDU6SXNzdWUzODUzMDQ2NzU=BERTConfigs in example usages in `modeling.py` are not OK (?)2018-11-28T14:53:01Z2018-11-30T22:29:24ZTrue
MDU6SXNzdWUzODUzNjgyODY=Specify a model from a specific directory for extract_features.py2018-11-28T17:04:39Z2018-11-30T22:30:12ZTrue
MDU6SXNzdWUzODU0ODczNjU=Unseen Vocab2018-11-28T22:38:57Z2018-11-30T22:31:36ZTrue
MDU6SXNzdWUzODU1NTUwOTU=Feature extraction for sequential labelling2018-11-29T03:33:09Z2020-01-19T00:12:47ZTrue
MDU6SXNzdWUzODU2Mzg1OTU=3 sentences as input for BertForSequenceClassification?2018-11-29T09:18:21Z2018-11-30T22:58:16ZTrue
MDU6SXNzdWUzODYwNDcxNzM=`TypeError: object of type 'NoneType' has no len()` when tuning on squad  2018-11-30T05:48:04Z2018-11-30T13:24:02ZTrue
MDU6SXNzdWUzODYwNTU5ODc=Accuracy on classification task is lower than the official tensorflow version2018-11-30T06:30:56Z2018-11-30T22:56:45ZTrue
MDU6SXNzdWUzODYxOTc4MzY=cannot access to pretrained vocab file on S32018-11-30T13:57:03Z2018-11-30T14:44:24ZTrue
MDU6SXNzdWUzODYzMDM1NjU=run_squad script gets stuck2018-11-30T18:39:54Z2018-11-30T19:47:07ZTrue
MDU6SXNzdWUzODY0ODk0MzY=Wrong signature in model call in run_classifier.py example (?)2018-12-01T19:34:40Z2018-12-02T12:02:34ZTrue
MDU6SXNzdWUzODY1NTMyNjU=TypeError: object of type 'WindowsPath' has no len()2018-12-02T12:03:51Z2018-12-02T15:30:43ZTrue
MDU6SXNzdWUzODY2OTg1MTE=numpy.core._internal.AxisError: axis 1 is out of bounds for array of dimension 12018-12-03T07:56:56Z2018-12-03T08:37:11ZTrue
MDU6SXNzdWUzODY3NjM5MDY=How can I apply BERT to a cloze task?2018-12-03T10:58:43Z2018-12-09T20:57:24ZTrue
MDU6SXNzdWUzODY3ODYwNzk=There is some problem in supporting continuously training2018-12-03T12:00:09Z2018-12-09T21:01:02ZTrue
MDU6SXNzdWUzODY4ODc5NjU=AttributeError: 'tuple' object has no attribute 'backward'2018-12-03T16:06:20Z2018-12-04T07:27:06ZTrue
MDU6SXNzdWUzODY5ODg4Nzg=Error while runing example2018-12-03T20:21:12Z2018-12-05T00:12:48ZTrue
MDU6SXNzdWUzODcxMDA4NDQ=How to use pre-trained SQUAD model? 2018-12-04T03:13:30Z2018-12-14T14:42:04ZTrue
MDU6SXNzdWUzODcyMzM3MTQ=code in run_squad.py line 2632018-12-04T11:08:09Z2018-12-06T01:30:36ZTrue
MDU6SXNzdWUzODcyODY2NTM=Error when calculating loss and running backward2018-12-04T13:30:58Z2018-12-05T03:41:38ZTrue
MDU6SXNzdWUzODc2ODMwNTQ=bert-base-multilingual-cased - Text bigger than 5122018-12-05T10:11:21Z2018-12-09T21:04:53ZTrue
MDU6SXNzdWUzODc3NzA0MjE=Fine tuned to Multi-choice dataset?2018-12-05T14:01:41Z2018-12-10T10:10:16ZTrue
MDU6SXNzdWUzODc5MDM3MjE=Bert uncased and Bert large giving much lower results than Bert cased base2018-12-05T19:13:24Z2018-12-09T21:07:49ZTrue
MDU6SXNzdWUzODgyNDI5MDE=Not updating the BERT embeddings during the fine tuning process2018-12-06T14:40:33Z2018-12-09T21:13:11ZTrue
MDU6SXNzdWUzODg0NzAyOTA=RuntimeError: cuda runtime error (59) : device-side assert triggered2018-12-07T01:39:03Z2018-12-07T07:25:30ZTrue
MDU6SXNzdWUzODg2NjAxMzI=Problem about convert TF model and pretraining2018-12-07T13:42:59Z2018-12-14T14:42:40ZTrue
MDU6SXNzdWUzODg2NjA1NDI=run_squad.py stuck on batch size greater than 12018-12-07T13:44:09Z2018-12-14T14:43:02ZTrue
MDU6SXNzdWUzODg3MTM5NTE=Squad dataset has multiple answers to a question.2018-12-07T16:02:00Z2018-12-08T11:57:22ZTrue
MDU6SXNzdWUzODg5MDEzNjU=How to modify the model config?2018-12-08T08:38:37Z2018-12-09T21:19:31ZTrue
MDU6SXNzdWUzODg5MTU0MDc=Words after tokenization replaced with #2018-12-08T11:56:57Z2018-12-11T10:33:23ZTrue
MDU6SXNzdWUzODg5MzA1Nzk=BERT for classification example training files2018-12-08T15:16:50Z2018-12-08T15:19:17ZTrue
MDU6SXNzdWUzODg5OTQ1ODY=weights initialized two times2018-12-09T07:06:52Z2018-12-09T21:17:51ZTrue
MDU6SXNzdWUzODkyMDE4NzY=Picking max_sequence_length in run_classifier.py CoLA task2018-12-10T09:04:47Z2018-12-10T15:14:47ZTrue
MDU6SXNzdWUzODkzNDY2NTI=Does max_seq_length specify the maxium number of words2018-12-10T15:14:22Z2018-12-11T12:11:10ZTrue
MDU6SXNzdWUzODk1NDA2MTE=UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte2018-12-11T00:04:09Z2018-12-11T01:17:00ZTrue
MDU6SXNzdWUzODk1NDk4Njg=Pretrained Tokenizer Loading Fails: 'PosixPath' object has no attribute 'rfind'2018-12-11T00:48:11Z2018-12-11T10:28:47ZTrue
MDU6SXNzdWUzODk4NDY4OTc=What is the best dataset structure for BERT?2018-12-11T16:28:00Z2018-12-11T20:57:45ZTrue
MDU6SXNzdWUzODk5NTA4ODg=How to run a saved model?2018-12-11T20:58:38Z2018-12-14T14:43:43ZTrue
MDU6SXNzdWUzOTA3OTMxODM=logging.basicConfig overrides user logging2018-12-13T17:58:02Z2018-12-14T13:46:51ZTrue
MDU6SXNzdWUzOTA5NTA4MjE=Segmentation fault (core dumped)2018-12-14T03:24:58Z2018-12-22T14:26:56ZTrue
MDU6SXNzdWUzOTE0MDIwMTM=RuntimeError: Expected object of type torch.LongTensor but found type torch.cuda.LongTensor for argument #3 'index'2018-12-15T18:43:53Z2018-12-15T20:45:37ZTrue
MDU6SXNzdWUzOTE0NTg5OTc=High accuracy for CoLA task2018-12-16T11:39:56Z2018-12-17T06:41:06ZTrue
MDU6SXNzdWUzOTE1NjQ2NTM=_load_from_state_dict() takes 7 positional arguments but 8 were given2018-12-17T05:38:40Z2019-01-07T11:46:27ZTrue
MDU6SXNzdWUzOTE5NzkwNzU=big memory occupied2018-12-18T03:13:11Z2018-12-18T08:04:38ZTrue
MDU6SXNzdWUzOTIwOTMzODM=Warning/Assert when embedding sequences longer than positional embedding size2018-12-18T10:36:23Z2019-01-07T11:46:41ZTrue
MDU6SXNzdWUzOTIxNTQxOTU=Benchmarking Prediction Speed2018-12-18T13:21:51Z2019-05-12T13:18:41ZTrue
MDU6SXNzdWUzOTI0MDkzNzU=BERT + CNN classifier doesn't work after migrating from 0.1.2 to 0.4.02018-12-19T01:57:22Z2018-12-20T00:20:48ZTrue
MDU6SXNzdWUzOTI1ODM3Mjc=bert-base-multilingual-cased, do lower case problem2018-12-19T12:40:38Z2019-01-07T12:08:47ZTrue
MDU6SXNzdWUzOTI4OTgzMTE=NONE2018-12-20T05:42:29Z2018-12-28T13:56:36ZTrue
MDU6SXNzdWUzOTI5MjIzMjI=lower accuracy on OMD(Obama-McCain Debate twitter sentiment dataset)2018-12-20T07:27:11Z2019-01-07T12:11:22ZTrue
MDU6SXNzdWUzOTMwNTU2NjA=Problem loading a finetuned model.2018-12-20T13:52:44Z2019-01-07T11:20:43ZTrue
MDU6SXNzdWUzOTMwNTg0NjM=It's possible to avoid download the pretrained model?2018-12-20T14:00:03Z2018-12-20T14:08:10ZTrue
MDU6SXNzdWUzOTMwNzk5MjQ=run_squad.py without GPU.. Without CUPY2018-12-20T14:53:46Z2018-12-21T09:33:02ZTrue
MDU6SXNzdWUzOTMxNDIxNDQ=Problem loading finetuned model for squad2018-12-20T17:27:40Z2019-01-07T12:17:58ZTrue
MDU6SXNzdWUzOTMxNjc3ODQ=Not able to use FP16 in pytorch-pretrained-BERT2018-12-20T18:46:14Z2018-12-28T09:23:34ZTrue
MDU6SXNzdWUzOTMxNjc4NzA=Not able to use FP16 in pytorch-pretrained-BERT. Getting error **Runtime error: Expected scalar type object Half but got scalar type Float for argument #2 target**2018-12-20T18:46:30Z2019-01-07T12:18:36ZTrue
MDU6SXNzdWUzOTMzNjU2MzM=bug in init_bert_weights2018-12-21T08:29:40Z2019-01-07T12:18:49ZTrue
MDU6SXNzdWUzOTM2NjkyMDA=Some questions in Loss Function for MaskedLM2018-12-22T12:24:24Z2019-01-07T12:19:19ZTrue
MDU6SXNzdWUzOTM4NzYzMjA=BertForQuestionAnswering: Predicting span on the question?2018-12-24T12:51:49Z2018-12-28T09:20:49ZTrue
MDU6SXNzdWUzOTQwNjQ0OTk=Does the final hidden state contains the <CLS> for Squad2.02018-12-26T02:05:34Z2018-12-26T02:48:04ZTrue
MDU6SXNzdWUzOTQzMTA2ODI=Embeddings from BERT for original tokens2018-12-27T06:48:23Z2018-12-28T09:17:16ZTrue
MDU6SXNzdWUzOTQ1MDc5Njc=Speedup using NVIDIA Apex 2018-12-27T23:17:42Z2018-12-29T10:42:51ZTrue
MDU6SXNzdWUzOTQ1OTY4OTg=BertLayerNorm not loaded in CPU mode2018-12-28T09:55:05Z2019-06-21T10:20:02ZTrue
MDU6SXNzdWUzOTQ2NzMzNTE=Using large model with fp16 enable causes the server down2018-12-28T16:32:05Z2019-01-07T12:24:34ZTrue
MDU6SXNzdWUzOTQ4NjQ2MjI=Did you suport squad2.02018-12-30T11:25:55Z2019-01-14T09:03:50ZTrue
MDU6SXNzdWUzOTQ4NjUwMzA="the run_squad report ""for training,each question should exactly have 1 answer"" when I tried to fintune bert on squad2.0"2018-12-30T11:33:29Z2018-12-30T11:48:50ZTrue
MDU6SXNzdWUzOTQ4NzA4OTE=Why not the mlm use the information of adjacent sentences?2018-12-30T13:08:53Z2019-01-07T12:25:24ZTrue
MDU6SXNzdWUzOTUyNTUxMzI=Is it feasible to set num_workers>=1 in DataLoader to quickly load data?2019-01-02T13:54:25Z2019-01-07T12:25:56ZTrue
MDU6SXNzdWUzOTU1MTcwMTI=AttributeError: 'BertForPreTraining' object has no attribute 'global_step'2019-01-03T10:10:51Z2019-01-04T09:59:42ZTrue
MDU6SXNzdWUzOTU1NTUwNjQ=Weights of BertForQuestionAnswering not initialized from pretrained model2019-01-03T12:24:32Z2019-01-03T12:38:58ZTrue
MDU6SXNzdWUzOTU1ODEzNjc=Predict Mode: Weights of BertForQuestionAnswering not initialized from pretrained model2019-01-03T13:56:02Z2019-01-07T12:27:12ZTrue
MDU6SXNzdWUzOTU4OTMwMzA=TypeError: Class advice impossible in Python32019-01-04T11:23:43Z2019-01-07T05:48:58ZTrue
MDU6SXNzdWUzOTU5NDE2NDU=pretrained model 2019-01-04T14:20:49Z2019-01-07T12:28:07ZTrue
MDU6SXNzdWUzOTYxNDExODE=Question about hidden layers from pretained model2019-01-05T07:09:20Z2019-01-07T12:28:19ZTrue
MDU6SXNzdWUzOTYyMzI3NzY=Cannot reproduce the result of run_squad 1.12019-01-06T06:34:47Z2019-01-07T12:30:56ZTrue
MDU6SXNzdWUzOTYzNzU3Njg=How to pretrain my own data with this pytorch code?2019-01-07T07:22:53Z2019-01-07T12:29:44ZTrue
MDU6SXNzdWUzOTY3NzYyNTQ=What 's the mlm accuracy of pretrained model? 2019-01-08T07:08:35Z2019-01-08T10:07:23ZTrue
MDU6SXNzdWUzOTcyNDM2MzU=RuntimeError: Dimension out of range (expected to be in range of [-1, 0], but got 1)2019-01-09T07:26:46Z2019-01-14T09:15:11ZTrue
MDU6SXNzdWUzOTcyODY2MDQ=Add [CLS] and [SEP] tokens in Usage2019-01-09T09:41:58Z2019-01-10T00:35:07ZTrue
MDU6SXNzdWUzOTc2NzMzMDg=run_lm_finetuning.py does not define a do_lower_case argument2019-01-10T05:01:17Z2019-01-14T09:04:46ZTrue
MDU6SXNzdWUzOTc3MDMxMDc=Can we use BERT for Punctuation Prediction?2019-01-10T07:25:30Z2019-01-14T09:05:22ZTrue
MDU6SXNzdWUzOTgxNDM4Nzg=Weights not initialized from pretrained model2019-01-11T06:03:47Z2019-01-14T09:05:33ZTrue
MDU6SXNzdWUzOTgxNDg1ODk=All about the training speed in classification job 2019-01-11T06:27:39Z2019-01-14T09:09:04ZTrue
MDU6SXNzdWUzOTgyMDg2MDY=Python 3.5 + Torch 1.0 does not work2019-01-11T09:43:43Z2019-01-14T09:10:02ZTrue
MDU6SXNzdWUzOTgyMTg3NDE=got an unexpected keyword argument 'cache_dir'2019-01-11T10:08:56Z2019-01-14T09:11:06ZTrue
MDU6SXNzdWUzOTgyMjk3Mjc=BertOnlyMLMHead is a duplicate of BertLMPredictionHead2019-01-11T10:35:36Z2019-01-14T09:14:56ZTrue
MDU6SXNzdWUzOTgyNTIwNjY=issue is, that ##string will repeats at intermediate, it collapses all index for mask words2019-01-11T11:35:06Z2019-01-14T09:16:36ZTrue
MDU6SXNzdWUzOTg1ODg2Mzg=Weight Decay Fix Original Paper2019-01-12T20:22:45Z2019-01-14T01:08:36ZTrue
MDU6SXNzdWUzOTg3NzEzMzk=run_classifier.py doesn't save any configurations and I can't load the trained model. 2019-01-14T07:16:07Z2019-01-14T09:19:59ZTrue
MDU6SXNzdWUzOTg3OTk4NzM=Potentially redundant learning rate scheduling2019-01-14T09:10:06Z2019-02-05T16:07:58ZTrue
MDU6SXNzdWUzOTkxNTU1NjY=TODO statement on Question/Answering Model2019-01-15T01:56:48Z2019-01-16T12:23:14ZTrue
MDU6SXNzdWUzOTk2Mjc5Mzc=seems meet the GPU memory leak problem2019-01-16T03:05:33Z2019-01-23T16:12:53ZTrue
MDU6SXNzdWUzOTk2NzE2NzI=HTTPSConnectionPool(host='s3.amazonaws.com', port=443): Max retries exceeded with url: /models.huggingface.co/bert/bert-base-uncased.tar.gz (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000002456AF21710>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond',))2019-01-16T06:55:31Z2019-01-16T08:34:45ZTrue
MDU6SXNzdWU0MDA1MjE5NDE=training new BERT seems not working2019-01-18T00:30:24Z2019-03-06T12:16:55ZTrue
MDU6SXNzdWU0MDA1NDQyNTQ=Add some new layers from BertModel and then 'grad' error occurs2019-01-18T02:19:58Z2019-01-23T16:34:28ZTrue
MDU6SXNzdWU0MDA1ODIxNzA=Two to Three mask word prediction at the same sentence is very complex2019-01-18T05:52:40Z2019-01-22T16:50:03ZTrue
MDU6SXNzdWU0MDA3MzgwMzE=What is the meaning of Attention Mask2019-01-18T14:04:11Z2019-01-18T22:26:00ZTrue
MDU6SXNzdWU0MDA3NzU0Njc=Classifier example not training on CoLa data2019-01-18T15:36:20Z2019-02-05T16:08:59ZTrue
MDU6SXNzdWU0MDA4ODU2OTc=AttributeError: 'NoneType' object has no attribute 'start_logit'2019-01-18T20:55:47Z2019-02-05T16:09:16ZTrue
MDU6SXNzdWU0MDA5Njg2MTM=Missing softmax in BertForQuestionAnswering after linear layer?2019-01-19T06:55:30Z2019-01-19T08:26:35ZTrue
MDU6SXNzdWU0MDEwMDYzNjA=error: the following arguments are required: --bert_model, --output_dir2019-01-19T15:32:43Z2019-01-20T04:28:03ZTrue
MDU6SXNzdWU0MDEwMDg4NTg=How convert pytorch to tf checkpoint?2019-01-19T16:02:47Z2019-05-21T14:38:19ZTrue
MDU6SXNzdWU0MDEwODA1MzA=Pytorch-Bert: Why this command: pip install pytorch-pretrained-bert doesn't work for me2019-01-20T09:44:52Z2019-02-05T16:10:10ZTrue
MDU6SXNzdWU0MDEyMTkwMjI=will examples update the parameters of bert model?2019-01-21T07:04:08Z2019-02-05T16:10:45ZTrue
MDU6SXNzdWU0MDEyNjQ5NTk=SQuAD output layer and the computation loss2019-01-21T09:34:44Z2019-01-28T10:31:02ZTrue
MDU6SXNzdWU0MDE0NDQ5ODQ=Loading fine tuned BertForMaskedLM2019-01-21T17:13:54Z2019-01-23T22:12:30ZTrue
MDU6SXNzdWU0MDE4OTA1Nzk=Training classifier does not work for more than two classes2019-01-22T18:14:52Z2019-01-23T13:38:42ZTrue
MDU6SXNzdWU0MDE5NzEzOTI=Loading fine_tuned BertModel fails due to prefix error2019-01-22T21:55:45Z2019-01-24T09:42:14ZTrue
MDU6SXNzdWU0MDIxMDM1Njc=How can I get the confidence score for the classification task2019-01-23T07:21:51Z2019-01-23T07:35:25ZTrue
MDU6SXNzdWU0MDIxMjAyMjM=Questions Answering Example2019-01-23T08:19:56Z2019-01-23T08:32:15ZTrue
MDU6SXNzdWU0MDIxNjk2NTM=Using BERT with custom QA dataset2019-01-23T10:26:54Z2019-01-28T10:30:41ZTrue
MDU6SXNzdWU0MDI1MDkyODc=ConnectionError returned if Internet network is not stable2019-01-24T02:01:16Z2019-01-28T10:29:08ZTrue
MDU6SXNzdWU0MDI1MTc1MzQ=how to add new vocabulary?2019-01-24T02:42:38Z2019-01-24T05:13:10ZTrue
MDU6SXNzdWU0MDI1MjQyMzI=max sentence length2019-01-24T03:16:17Z2019-01-24T05:11:14ZTrue
MDU6SXNzdWU0MDMxMjU3ODQ=Logical error in the run_lm_finetuning?2019-01-25T11:51:02Z2019-01-25T14:35:21ZTrue
MDU6SXNzdWU0MDMxODYxMDg=RuntimeError: Expected object of backend CUDA but got backend CPU for argument #3 'index'2019-01-25T14:45:34Z2019-01-25T15:42:59ZTrue
MDU6SXNzdWU0MDM0MjMwMDQ=Freezing base transformer weights2019-01-26T09:09:36Z2019-01-26T09:45:04ZTrue
MDU6SXNzdWU0MDM0MzA3MTk=Is BERT suitable for seq2seq tasks, such as machine translation? 2019-01-26T11:01:42Z2019-01-28T10:28:41ZTrue
MDU6SXNzdWU0MDM0OTQ0ODc=Cleaning `~/.pytorch_pretrained_bert`2019-01-26T23:18:42Z2019-01-28T10:27:04ZTrue
MDU6SXNzdWU0MDM1NzQxMjM=Why is the output bias computed separately?2019-01-27T17:22:32Z2019-01-28T10:27:25ZTrue
MDU6SXNzdWU0MDM4MTAwNzk=What is get_lr() meaning in the optimizer.py2019-01-28T13:19:06Z2019-02-05T16:12:33ZTrue
MDU6SXNzdWU0MDQyOTQ0ODE=Fine tuning for evaluation2019-01-29T13:36:53Z2019-03-06T12:18:20ZTrue
MDU6SXNzdWU0MDQyOTg4NDU=Training BERT behind a proxy server2019-01-29T13:47:29Z2019-02-05T16:13:25ZTrue
MDU6SXNzdWU0MDQzNjAwODc=Preprocessing necessary for lengthier text2019-01-29T15:56:30Z2019-01-29T16:03:27ZTrue
MDU6SXNzdWU0MDQ2MDQ2MTM=How can I change vocab size for pretrained model?2019-01-30T05:10:37Z2019-02-05T16:14:19ZTrue
MDU6SXNzdWU0MDQ2MjQ5NjI=padded positions are ignored when embedding position ids2019-01-30T06:43:13Z2019-05-12T13:18:44ZTrue
MDU6SXNzdWU0MDQ4NTAzMjk=cannot load BERTAdam when restoring from BioBert2019-01-30T16:21:09Z2019-03-06T08:54:27ZTrue
MDU6SXNzdWU0MDQ5MDU4NDI=Tokenization doesn't seem to match BERT paper2019-01-30T18:33:15Z2019-01-30T23:56:06ZTrue
MDU6SXNzdWU0MDUxNTY2NTg=seems there is a bug in fine tuning language model2019-01-31T09:37:11Z2019-01-31T10:37:32ZTrue
MDU6SXNzdWU0MDUzOTY2MTk=can you do a new release + pypi2019-01-31T19:15:10Z2019-02-11T15:13:17ZTrue
MDU6SXNzdWU0MDU3NTc2NTQ=Multilabel classification and diverging loss2019-02-01T15:48:37Z2019-02-11T17:03:15ZTrue
MDU6SXNzdWU0MDYwNTcxNTg=Fine tuning Bert for Question answering 2019-02-03T06:08:52Z2019-02-06T08:07:50ZTrue
MDU6SXNzdWU0MDY5MTk5Mzk=BERT tuning all parameters? 2019-02-05T18:39:37Z2019-02-06T08:07:13ZTrue
MDU6SXNzdWU0MDcwMjQ5Mjg=Error while using Apex2019-02-05T23:49:01Z2019-02-06T08:07:21ZTrue
MDU6SXNzdWU0MDcwNTE5NzI=does run_lm_finetuning.py actually use --eval_batch_size?2019-02-06T01:57:28Z2019-03-06T08:55:00ZTrue
MDU6SXNzdWU0MDcyMTgxMTA=Minor redundancy in model defintion?2019-02-06T12:44:46Z2019-03-06T08:56:01ZTrue
MDU6SXNzdWU0MDc0NzUxOTU=please add option to load fine-tuned file to CPU if trained on GPU2019-02-06T23:16:04Z2019-02-08T09:37:56ZTrue
MDU6SXNzdWU0MDc0OTkxODk=pretrained model(s) in onnx format2019-02-07T00:55:12Z2019-07-29T03:38:47ZTrue
MDU6SXNzdWU0MDc4NDk2Mjg=speed becomes slow2019-02-07T19:02:12Z2019-05-12T13:18:42ZTrue
MDU6SXNzdWU0MDgzNDM3MzA=potential bug in extract_features.py2019-02-08T22:11:49Z2019-02-11T15:45:45ZTrue
MDU6SXNzdWU0MDg3Mjk5MTY=RuntimeError: cuda runtime error while running run_classifier.py with 'bert-large-uncased' bert model2019-02-11T11:05:22Z2019-03-06T08:57:51ZTrue
MDU6SXNzdWU0MDg3NzEwODc=Variance Sources2019-02-11T13:01:38Z2019-02-12T10:06:10ZTrue
MDU6SXNzdWU0MDkxNDE0NTM=Tokenization Incorrect2019-02-12T06:30:57Z2019-02-13T09:27:37ZTrue
MDU6SXNzdWU0MDkxOTQxODk=Missing files for Transformer-XL examples2019-02-12T09:15:46Z2019-02-12T09:25:24ZTrue
MDU6SXNzdWU0MDkzODU2MjY=Get hidden states from all layers of Transformer-XL?2019-02-12T16:25:18Z2019-02-13T09:33:48ZTrue
MDU6SXNzdWU0MDk1MTY1MzA=Transformer-XL: hidden states are nan2019-02-12T21:50:32Z2019-02-13T09:27:14ZTrue
MDU6SXNzdWU0MDk1ODU5NzQ=Transformer-XL: wrong encoding in the vocab2019-02-13T01:52:38Z2019-05-12T13:18:43ZTrue
MDU6SXNzdWU0MDk1OTg4NjU=Facing issue in Run Fine tune LM2019-02-13T02:45:55Z2019-03-06T09:00:20ZTrue
MDU6SXNzdWU0MDk3MTU5NTA=Help: how to get index/symbol from last_hidden, on text8?2019-02-13T09:50:51Z2019-03-06T09:00:37ZTrue
MDU6SXNzdWU0MDk4NjExMjI=Argument do_lower_case is repeated in run_lm_finetuning.py2019-02-13T15:29:35Z2019-02-13T15:33:05ZTrue
MDU6SXNzdWU0MDk4NzA1NDM=80min training time to fine-tune BERT-base on the SQuAD dataset instead of 24min?2019-02-13T15:48:43Z2019-03-06T09:00:50ZTrue
MDU6SXNzdWU0MTAwNzQ5Nzc=PAD symbols change the output2019-02-14T00:57:02Z2019-02-14T07:32:29ZTrue
MDU6SXNzdWU0MTAxNDMwNjY=DataParallel imbalanced memory usage2019-02-14T06:06:38Z2019-03-06T09:01:27ZTrue
MDU6SXNzdWU0MTA1OTEzMTA=Have you eval the inference speed of transformer-xl?2019-02-15T03:39:14Z2019-02-27T03:42:59ZTrue
MDU6SXNzdWU0MTA2NDYxMDg=Conversion of gpt-2 small model2019-02-15T07:52:25Z2019-02-18T10:43:00ZTrue
MDU6SXNzdWU0MTA3MjM0Mzk=unicode2019-02-15T11:21:08Z2019-02-16T13:49:30ZTrue
MDU6SXNzdWU0MTA3ODI1OTg=Error in Apex's FusedLayerNorm2019-02-15T14:01:48Z2019-02-20T15:46:50ZTrue
MDU6SXNzdWU0MTEwNzQxNzk=Anyone tried this model to write a next sentence?2019-02-16T13:45:00Z2019-05-12T13:18:40ZTrue
MDU6SXNzdWU0MTE0MzAyNDU=HugginFace or HuggingFace?2019-02-18T11:27:20Z2019-03-06T09:02:34ZTrue
MDU6SXNzdWU0MTE1NTg4OTE=Too much info @ stdout2019-02-18T16:30:54Z2019-03-06T09:05:27ZTrue
MDU6SXNzdWU0MTE4NTU0NTk=Extract Features for GPT2 and Transformer-XL2019-02-19T10:36:26Z2019-02-20T07:59:58ZTrue
MDU6SXNzdWU0MTIwNjMxMDI=How to change config parameters when loading the model with `from_pretrained`2019-02-19T18:27:01Z2019-02-20T02:43:02ZTrue
MDU6SXNzdWU0MTIxNDc4NjE=Sudden catastrophic classification output during NER training2019-02-19T22:09:33Z2019-02-21T14:48:27ZTrue
MDU6SXNzdWU0MTIxNjE0NDA=Transformer-XL: Convert lm1b model to PyTorch2019-02-19T22:49:57Z2019-05-12T13:18:45ZTrue
MDU6SXNzdWU0MTIxOTc4NTk=Tests failure2019-02-20T01:11:52Z2019-03-06T09:11:51ZTrue
MDU6SXNzdWU0MTIyMjA0Njg=bert.pooler.dense initialization 2019-02-20T02:56:09Z2019-02-20T07:56:09ZTrue
MDU6SXNzdWU0MTIyMjIxNTA=`train_dataset` and `eval_dataset` in run_openai_gpt.py2019-02-20T03:03:52Z2019-02-20T07:57:14ZTrue
MDU6SXNzdWU0MTI0Njg5NTM=Example Code in README fails.2019-02-20T14:57:26Z2019-02-20T15:43:19ZTrue
MDU6SXNzdWU0MTI1NjUxMzk=Can I do a code reference in implementing my code?2019-02-20T18:24:41Z2019-02-21T08:45:41ZTrue
MDU6SXNzdWU0MTI3MjAzNTg=Issue happens while using convert_tf_checkpoint_to_pytorch  2019-02-21T02:33:50Z2019-07-22T17:14:13ZTrue
MDU6SXNzdWU0MTI3NDI0MzU=It seems the eval speed of transformer-xl is not faster than bert-base-uncased.2019-02-21T04:22:02Z2019-02-27T03:31:13ZTrue
MDU6SXNzdWU0MTI4MDc5OTc=Tests error: Issue with python3 compatibility, on zope interface implementation2019-02-21T08:41:35Z2019-03-07T03:07:16ZTrue
MDU6SXNzdWU0MTI4NzAyMDg=Shouldn't GPT2 use Linear instead of Conv1D?2019-02-21T11:09:22Z2019-03-06T09:16:59ZTrue
MDU6SXNzdWU0MTMyMDQ0ODc=Problems converting TF BioBERT model to PyTorch2019-02-22T01:47:02Z2019-02-26T00:24:17ZTrue
MDU6SXNzdWU0MTMyNDEyNjQ=run_lm_finetuning2019-02-22T04:42:39Z2019-05-12T13:18:46ZTrue
MDU6SXNzdWU0MTMyNzI5MTY=Issue with apex import on MAC 2019-02-22T07:13:33Z2019-02-22T17:18:09ZTrue
MDU6SXNzdWU0MTM1OTAwODM=run_classifier.py :  TypeError: join() argument must be str or bytes, not 'PosixPath'2019-02-22T21:40:50Z2019-03-06T09:20:02ZTrue
MDU6SXNzdWU0MTM3MTkyMzA=anyone notice large difference of using fp16 ?2019-02-23T17:49:23Z2019-02-23T22:56:11ZTrue
MDU6SXNzdWU0MTM3ODkyNTI=TransfoXLLMHeadModel output interpretation2019-02-24T06:52:50Z2019-03-06T09:25:23ZTrue
MDU6SXNzdWU0MTQzNjYyMTc=run_classifier.py: TypeError: __init__() got an unexpected keyword argument 'cache_dir'2019-02-26T00:02:34Z2019-02-26T20:52:30ZTrue
MDU6SXNzdWU0MTQ0OTc5MjQ=what is the batch size we can use for SQUAD task?2019-02-26T08:56:20Z2019-03-03T00:21:19ZTrue
MDU6SXNzdWU0MTQ1ODMxMjk=how to load classification model and predict?2019-02-26T12:18:20Z2019-03-06T09:26:00ZTrue
MDU6SXNzdWU0MTQ1OTY2NTQ=Single sentence corpus in run_lm_finetuning?2019-02-26T12:53:33Z2019-03-06T09:26:53ZTrue
MDU6SXNzdWU0MTQ2OTAxNzk=What should be the label of sub-word units in Token Classification with Bert2019-02-26T16:06:34Z2019-03-06T09:28:10ZTrue
MDU6SXNzdWU0MTQ2OTQ0OTc=warmup_linear for BertAdam and OpenAIAdam2019-02-26T16:14:45Z2019-03-06T09:28:38ZTrue
MDU6SXNzdWU0MTQ5Mzg4ODU=run_classifier with evaluation job only2019-02-27T04:24:42Z2019-03-06T09:29:50ZTrue
MDU6SXNzdWU0MTUzMjMzNTA=PyTorch Huggingface BERT-NLP for Named Entity Recognition2019-02-27T20:57:13Z2019-07-16T09:51:24ZTrue
MDU6SXNzdWU0MTU0NDkzNjE=run_lm_finetuning - ZeroDivisionError2019-02-28T05:05:55Z2019-05-12T14:18:40ZTrue
MDU6SXNzdWU0MTU0NzE1NjQ=Can we fine tune our model on Chinese corpus2019-02-28T06:43:35Z2019-03-06T09:40:43ZTrue
MDU6SXNzdWU0MTU1MDUxMzM=Can BERT do the next-word-predict task? As it is bidirectional.2019-02-28T08:36:02Z2019-03-01T02:05:43ZTrue
MDU6SXNzdWU0MTU1MDc1MDA=Train with custom data on bert question answering2019-02-28T08:42:09Z2019-12-13T13:06:56ZTrue
MDU6SXNzdWU0MTU5OTQ4MjA=Add lm and next sentence accuracy for run_lm_finetuning example2019-03-01T08:34:15Z2019-03-06T09:41:27ZTrue
MDU6SXNzdWU0MTU5OTg0ODI=pip install [--editable] . ---> Error2019-03-01T08:45:48Z2019-03-06T09:42:17ZTrue
MDU6SXNzdWU0MTYxOTU2MjE=Feature Request: GPT2 fine tuning2019-03-01T17:05:14Z2019-03-06T09:43:41ZTrue
MDU6SXNzdWU0MTY0NTAxNzY=F1 and EM scores output for run_squad.py2019-03-02T22:42:27Z2019-03-09T20:57:26ZTrue
MDU6SXNzdWU0MTY0ODA4MTI=Why the weights are not intialized ?2019-03-03T06:14:33Z2019-03-06T09:46:24ZTrue
MDU6SXNzdWU0MTY1ODI0ODQ=optimizer.zero_grad() in run_openai_gpt.py?2019-03-03T23:51:47Z2019-03-06T10:44:01ZTrue
MDU6SXNzdWU0MTcwNTAyMDU=Usage example needs [CLS] and [SEP] added post-tokenization2019-03-05T00:00:37Z2019-03-05T19:05:47ZTrue
MDU6SXNzdWU0MTcxMDc5MDQ=Tokenizer defaults lowercase even when bert_model is cased2019-03-05T04:11:14Z2019-05-12T13:18:47ZTrue
MDU6SXNzdWU0MTcxMzczMjE=BertEmbedding not initialized with `padding_idx=0`2019-03-05T06:23:48Z2019-03-11T08:07:41ZTrue
MDU6SXNzdWU0MTcxOTY5MzE="Not able to import RandomSampler, Getting error ""ImportError: cannot import name 'RandomSampler'""?"2019-03-05T09:24:19Z2019-03-06T06:26:18ZTrue
MDU6SXNzdWU0MTc0NDEzNDY=MRPC Score Lower than Expected2019-03-05T18:25:44Z2019-03-05T19:21:07ZTrue
MDU6SXNzdWU0MTc1OTYxNjc=Unable to train (fine-tuning) BERT with small training set2019-03-06T02:44:27Z2019-05-12T13:18:48ZTrue
MDU6SXNzdWU0MTc3MDM4Njg=Bert Uncased Large giving very low results with SQUAD v1.1 dataset2019-03-06T09:30:23Z2019-03-19T04:28:35ZTrue
MDU6SXNzdWU0MTc3MjE2ODQ=Little training has no impact2019-03-06T10:09:43Z2019-05-17T12:11:31ZTrue
MDU6SXNzdWU0MTc3NzI4NTY=How to incrementally do fine tune train 2019-03-06T12:11:20Z2019-05-22T08:43:48ZTrue
MDU6SXNzdWU0MTc4MjkxMDk=can't load the model2019-03-06T14:24:23Z2019-04-17T13:27:03ZTrue
MDU6SXNzdWU0MTc4Nzg3OTQ=Dropout Layer in OpenAIGPTMultipleChoiceHead not used2019-03-06T15:56:16Z2019-03-11T08:06:28ZTrue
MDU6SXNzdWU0MTc5ODEyNzU=[Question] Best choice for Sentence Compression model? 2019-03-06T19:54:37Z2019-05-13T08:16:41ZTrue
MDU6SXNzdWU0MTgwMjIzMzc=How to add input mask to GPT?2019-03-06T21:41:43Z2019-03-07T07:49:18ZTrue
MDU6SXNzdWU0MTg4ODIzNDU=Ranking predictions with BertForQuestionAnswering2019-03-08T17:26:03Z2019-05-18T09:44:38ZTrue
MDU6SXNzdWU0MTkxMzk3ODc=Separator token for custom QA input (multi paragraph, longer than 512)2019-03-10T02:56:29Z2019-05-17T09:11:31ZTrue
MDU6SXNzdWU0MTkyOTIzMTA=Potential redundancy in run_classifier.py example script2019-03-11T04:44:38Z2019-05-18T14:44:36ZTrue
MDU6SXNzdWU0MTk0NzMxMTY=BERT accuracy reduced after providing custom training..The answer is also not correct2019-03-11T13:36:58Z2019-05-18T14:44:34ZTrue
MDU6SXNzdWU0MTk2ODkzNDA=Vocabularly file not available for Squad predictions2019-03-11T21:21:06Z2019-05-18T14:44:35ZTrue
MDU6SXNzdWU0MTk4NDE1NDU=how does the run_squad.py deal with non-answerable questions 2019-03-12T07:38:40Z2019-03-14T02:22:20ZTrue
MDU6SXNzdWU0MTk4Nzk5MzA=When i fine tune the BERT on my serve, it always says Segmentation fault? 2019-03-12T09:24:10Z2019-07-17T10:07:46ZTrue
MDU6SXNzdWU0MjAxNDk0MDI=BertForQuestionAnswering: How to split  output between query hidden state and context hidden state2019-03-12T18:46:25Z2019-06-14T09:31:10ZTrue
MDU6SXNzdWU0MjAxOTU0NzI=What is Synthetic Self-Training?2019-03-12T20:40:50Z2019-06-05T08:50:40ZTrue
MDU6SXNzdWU0MjAyNzk4Mjk=a single sentence classification task, should the max length of sentence limited to half of 512, that is to say 2562019-03-13T01:47:10Z2019-07-03T17:21:53ZTrue
MDU6SXNzdWU0MjAzNjc2MTU=performance degraded when using paddings between queries and contexts.2019-03-13T08:14:02Z2019-04-03T02:12:03ZTrue
MDU6SXNzdWU0MjA1NTc2NjM=How to input the fine-tuned model?2019-03-13T15:16:41Z2019-06-12T20:12:02ZTrue
MDU6SXNzdWU0MjA1ODU0MjY=run_lm_finetuning generates short training cases2019-03-13T16:05:30Z2019-03-27T12:01:26ZTrue
MDU6SXNzdWU0MjA3MjI4NDA=Empty nbest_predictions.json for run_squad.py2019-03-13T21:15:05Z2019-03-14T09:00:48ZTrue
MDU6SXNzdWU0MjE2NDY1Mjg=fp16 overflow in GPT-22019-03-15T18:16:07Z2019-04-17T09:11:10ZTrue
MDU6SXNzdWU0MjE3OTQ4MzU=Incrementally Train BERT with minimum QnA records - to get improved results2019-03-16T10:54:15Z2019-05-25T10:39:14ZTrue
MDU6SXNzdWU0MjE4NjgzNzQ=pre-training a BERT from scratch2019-03-17T00:45:26Z2019-09-28T22:00:08ZTrue
MDU6SXNzdWU0MjE4OTkwMDM=run_squad.py cannot predict only2019-03-17T09:01:40Z2019-05-25T10:39:15ZTrue
MDU6SXNzdWU0MjI3MjU4Mjc='NoneType' object with constructor2019-03-19T13:16:16Z2019-04-27T07:24:25ZTrue
MDU6SXNzdWU0MjMwNTk5MTU=Reproduce the results on CoLA 2019-03-20T04:22:10Z2019-06-11T03:40:19ZTrue
MDU6SXNzdWU0MjM1MjA5MDY=AttributeError: 'BertForPreTraining' object has no attribute 'shape'2019-03-20T23:48:16Z2019-10-15T03:11:53ZTrue
MDU6SXNzdWU0MjM1ODE3NjQ=AttributeError: 'BertOnlyMLMHead' object has no attribute 'seq_relationship'2019-03-21T05:57:02Z2019-06-02T12:49:43ZTrue
MDU6SXNzdWU0MjM3NzM1OTc=Allow do_lower_case regardless of do_basic_tokenize2019-03-21T14:56:09ZFalse
MDU6SXNzdWU0MjQzOTI5NTA=Is the GPT-2 pretrained model language agnostic?2019-03-22T20:45:26Z2019-03-25T15:36:55ZTrue
MDU6SXNzdWU0MjQ1MDMxOTY=how to freeze bert model and just train a classifier?2019-03-23T13:56:18Z2019-03-27T11:37:10ZTrue
MDU6SXNzdWU0MjQ1MTczMzM=How can I generate new text after having fine-tuned BERT on a custom dataset ? 2019-03-23T16:20:21Z2019-06-14T09:31:09ZTrue
MDU6SXNzdWU0MjQ1ODU5NTM=gpt2 tokenizer issue with ValueError: chr() arg not in range(256) in Python 2.X2019-03-24T07:57:09Z2019-06-02T12:49:46ZTrue
MDU6SXNzdWU0MjQ2MzAyNDk=[Question]Embedding Generate Problem2019-03-24T16:13:03Z2019-07-28T15:05:06ZTrue
MDU6SXNzdWU0MjUwMzQ4MDk=embeddings after fine tuning2019-03-25T17:46:58Z2019-07-14T07:22:00ZTrue
MDU6SXNzdWU0MjUwNDU2Njg=error when trying to get embeddings after fine tuning2019-03-25T18:11:36Z2019-03-27T09:15:49ZTrue
MDU6SXNzdWU0MjUxNjEzNDI=AllenNLP TransformerXL2019-03-25T23:33:58Z2019-06-02T12:49:45ZTrue
MDU6SXNzdWU0MjUyOTgwNzE=slow training speed even 20 steps2019-03-26T09:05:07Z2019-06-02T12:49:48ZTrue
MDU6SXNzdWU0MjU0MTEwMjM=something wrong in example2019-03-26T13:15:19Z2019-06-03T08:37:46ZTrue
MDU6SXNzdWU0MjU0MTUyODI=Why average the loss when training on multi-GPUs2019-03-26T13:23:18Z2019-03-27T11:48:20ZTrue
MDU6SXNzdWU0MjU2NjMzNjE="Possible error in ""pytorch-pretrained-BERT/examples/run_gpt2.py"" unconditional"2019-03-26T21:45:31Z2019-04-16T06:45:31ZTrue
MDU6SXNzdWU0MjU2NjUzNDI=Bert Pretrained model has no modules nor parameters2019-03-26T21:51:14Z2019-03-27T00:33:41ZTrue
MDU6SXNzdWU0MjU3ODgxMDI=Help with implementing strides into features for multi-label classifier2019-03-27T06:36:34Z2019-06-02T12:49:47ZTrue
MDU6SXNzdWU0MjYxNDYxOTk=For sequence classification, is this model using the wrong token?2019-03-27T19:32:56Z2019-03-28T08:10:32ZTrue
MDU6SXNzdWU0MjYyNDI3NDY=Distributed Training Gets Stuck2019-03-28T00:40:50Z2019-06-09T08:40:38ZTrue
MDU6SXNzdWU0MjYzMjc4NDU=Is there any pre-training example code?2019-03-28T06:54:15Z2019-03-28T07:59:04ZTrue
MDU6SXNzdWU0MjYzNDkwNzU=can I fine-tuning pretrained gpt2 model on my corpus?2019-03-28T07:58:42Z2019-03-30T06:09:13ZTrue
MDU6SXNzdWU0MjYzNzYzNDc=bug in examples/run_squad.py line 88 & 902019-03-28T09:08:20Z2019-04-03T07:25:41ZTrue
MDU6SXNzdWU0MjY1NDQwMTc=Advantage of BertAdam over Adam?2019-03-28T15:03:16Z2019-04-03T10:44:50ZTrue
MDU6SXNzdWU0MjY1NDk5Mzc=pytorch model to tensorflow checkpoint2019-03-28T15:13:52Z2019-06-09T09:47:44ZTrue
MDU6SXNzdWU0MjY2MTE1MjM=BertForTokenClassification for NER, mask labels 2019-03-28T17:11:21Z2019-04-03T07:38:31ZTrue
MDU6SXNzdWU0MjY2NTEwODM=Difference between base and large tokenizer?2019-03-28T18:41:19Z2019-06-14T09:31:09ZTrue
MDU6SXNzdWU0MjcyNzE4MjY=Cannot find Synthetic self-training in this repository.2019-03-30T11:12:04Z2019-04-03T07:42:52ZTrue
MDU6SXNzdWU0MjcyOTA3NDA=GPT2Tokenizer <|endoftext|>2019-03-30T14:56:28Z2019-04-03T17:55:52ZTrue
MDU6SXNzdWU0Mjc2NDU4NjU=How to fine tune Transformer-XL on own dataset?2019-04-01T11:11:52Z2019-07-14T20:42:27ZTrue
MDU6SXNzdWU0Mjc2NTc4MzM=Predictions from BertForSequenceClassification model keep changing across runs2019-04-01T11:40:58Z2019-06-13T13:31:03ZTrue
MDU6SXNzdWU0Mjc3MjA3OTk=how to do the pre training the model form scratch?2019-04-01T13:57:23Z2019-04-03T07:59:14ZTrue
MDU6SXNzdWU0Mjc3NDM0OTU=Model not training at all in Google Colab2019-04-01T14:39:11Z2019-06-09T09:47:43ZTrue
MDU6SXNzdWU0Mjc5NDQ4NDU=BertTokenizer.from_pretrained('bert-base-multilingual-cased') does not recognize Korean2019-04-01T22:47:06Z2019-04-03T09:01:12ZTrue
MDU6SXNzdWU0MjgxOTk3Mjc=convert_tf_checkpoint_to_pytorch 'BertPreTrainingHeads' object has no attribute 'squad'2019-04-02T12:31:25Z2019-04-03T09:01:12ZTrue
MDU6SXNzdWU0MjgzMjE3NzY=DistributedDataParallel Not Working2019-04-02T16:18:27Z2019-06-09T10:47:43ZTrue
MDU6SXNzdWU0MjgzMjE4Mjg=How can i use bert for finding word embeddings2019-04-02T16:18:34Z2019-06-22T14:07:43ZTrue
MDU6SXNzdWU0Mjg0MTg1ODk=Unable to incrementally train BERT with custom training2019-04-02T20:07:32Z2019-06-09T10:47:42ZTrue
MDU6SXNzdWU0Mjg1NzIyMjM=How do you train custom corpus with bert?2019-04-03T05:24:05Z2019-06-09T13:47:42ZTrue
MDU6SXNzdWU0Mjg2NDA3MjQ=if crf needed when do ner?  2019-04-03T08:49:24Z2019-06-09T10:47:44ZTrue
MDU6SXNzdWU0Mjg5NzE1NzA=How to select a certain layer as token's representation?2019-04-03T20:57:32Z2019-04-11T13:43:34ZTrue
MDU6SXNzdWU0MjkwMTI1MjU=Dynamic max_seq_length implementation?2019-04-03T23:07:41Z2019-04-11T13:45:07ZTrue
MDU6SXNzdWU0MjkxNDU3NDU=pretrain for chinese dataset2019-04-04T08:26:30Z2019-04-11T13:47:07ZTrue
MDU6SXNzdWU0MjkxOTE1Mjg=Convert_tf_checkpoint_to_pytorch for bert-joint-baseline2019-04-04T10:05:52Z2019-06-18T06:54:29ZTrue
MDU6SXNzdWU0MjkyOTM4Njc=Understanding pre-training and fine-tuning2019-04-04T13:55:47Z2019-06-17T14:54:30ZTrue
MDU6SXNzdWU0Mjk0Mzg3Mzc=Help: cannot load pretrain models from .pytorch_pretrained_bert folder2019-04-04T19:11:46Z2019-07-08T14:23:21ZTrue
MDU6SXNzdWU0Mjk2MzQ1NTE=Pregenerating data requires multiple documents2019-04-05T08:14:02Z2019-06-18T15:21:05ZTrue
MDU6SXNzdWU0Mjk2NTQ4NjA=What‘s op-for-op meaning?2019-04-05T09:07:31Z2019-04-11T14:26:12ZTrue
MDU6SXNzdWU0Mjk3NTU1OTA=getting sequence embeddings for pair of sentences2019-04-05T13:28:40Z2019-04-11T14:26:46ZTrue
MDU6SXNzdWU0MzAxMTY0MzI=LM fine tuning on top of a custom model2019-04-07T07:58:04Z2019-04-11T14:58:08ZTrue
MDU6SXNzdWU0MzAyNzA1NDg=max_seq_length for squad2019-04-08T06:08:01Z2019-04-11T14:30:33ZTrue
MDU6SXNzdWU0MzAyODkxMDU=Load Biobert pre-trained weights into Bert model with Pytorch bert hugging face run_classifier.py code2019-04-08T07:08:40Z2019-06-17T14:54:29ZTrue
MDU6SXNzdWU0MzA0MDA1MjM=Suggestion: add warning when using BertForSequenceClassification without special [CLS] token2019-04-08T11:35:06Z2019-04-16T11:07:02ZTrue
MDU6SXNzdWU0MzA1MjU5MzI=Question about BertForQuestionAnswering model2019-04-08T15:47:53Z2019-04-09T02:48:50ZTrue
MDU6SXNzdWU0MzA1ODQwMzc=run_classifier on CoLA fails with illegal memory access2019-04-08T18:01:30Z2019-06-28T18:57:48ZTrue
MDU6SXNzdWU0MzA2ODY1MDM=Pooler weights not being updated for Multiple Choice models? 2019-04-08T22:29:35Z2019-06-12T17:40:47ZTrue
MDU6SXNzdWU0MzA3MTYyNjE=Vocab changes in lm_finetuning in BERT2019-04-09T00:41:19Z2019-10-03T04:01:35ZTrue
MDU6SXNzdWU0MzA4Nzk2NDc=How to get vocab.txt and bert_config.json as output of fine tuning?2019-04-09T10:03:22Z2019-04-11T14:44:24ZTrue
MDU6SXNzdWU0MzEwMjYyMjM=Errors when using Apex2019-04-09T15:17:26Z2019-06-17T15:54:29ZTrue
MDU6SXNzdWU0MzExNzIwODU=Mismatch in pre-processed wikitext-103 corpus and using pre-trained tokenizer for TransfoXLLMHeadModel2019-04-09T20:20:15Z2019-04-16T06:49:58ZTrue
MDU6SXNzdWU0MzEzNTg5Njc=GPT-2 fine tunning2019-04-10T08:01:01Z2019-06-29T17:11:34ZTrue
MDU6SXNzdWU0MzE2MTU5MDE=Why can`t we just use cached pytorch-model without internet2019-04-10T17:08:57Z2019-06-23T16:14:14ZTrue
MDU6SXNzdWU0MzE2Mzk5MDE=how to correctly do classifying?2019-04-10T18:08:05Z2019-06-17T15:54:30ZTrue
MDU6SXNzdWU0MzE4ODE2NDA=modeling_openai.py bug report2019-04-11T07:57:17Z2019-04-11T09:43:20ZTrue
MDU6SXNzdWU0MzE5MzUzMjc=Compilation terminated2019-04-11T09:58:42Z2019-04-11T10:03:03ZTrue
MDU6SXNzdWU0MzIxNjI5MzI=GPT as a Language Model2019-04-11T18:02:25Z2019-07-13T19:22:00ZTrue
MDU6SXNzdWU0MzIzNDE4NTM=Non-Determinism Behavior that cannot reproduce result when evaluate on each epoch2019-04-12T00:59:40Z2019-04-23T08:51:16ZTrue
MDU6SXNzdWU0MzIzNzI5OTk=cannot run squad script 2019-04-12T03:37:33Z2019-09-01T11:02:24ZTrue
MDU6SXNzdWU0MzI0MzU3OTc=Getting Sentence level log probabilities using this model2019-04-12T07:56:56Z2019-06-23T10:14:14ZTrue
MDU6SXNzdWU0MzI2ODg4NTc=Using GPT2 to implement GLTR2019-04-12T18:23:43Z2019-06-23T15:14:15ZTrue
MDU6SXNzdWU0MzI3MDAzMTA=BERT does mask-answering or sequence prediction or both???2019-04-12T18:54:42Z2019-06-23T10:14:14ZTrue
MDU6SXNzdWU0MzI3NDMyOTM=Suggestion: exception handling for out-of-vocab in pretrained model2019-04-12T20:58:40Z2019-04-17T11:33:10ZTrue
MDU6SXNzdWU0MzI3NDcxMTc=Perplexity number of wikitext-103 on gpt-2 don't match the paper2019-04-12T21:10:39Z2019-08-31T15:02:23ZTrue
MDU6SXNzdWU0MzI4MjY0MDc=KeyError: in convert_tokens_to_ids()2019-04-13T09:04:53Z2019-04-18T20:19:48ZTrue
MDU6SXNzdWU0MzI4MzA1MzM=UnboundLocalError: local variable 'i' referenced before assignment when using fine_tuning code2019-04-13T09:58:13Z2019-04-17T07:58:35ZTrue
MDU6SXNzdWU0MzI4ODQ5Mjg=Difference between this repo and bert-as-service2019-04-13T18:44:59Z2019-06-23T09:14:14ZTrue
MDU6SXNzdWU0MzI5NjM3OTI=BERT multilingual for zero-shot classification2019-04-14T11:39:34Z2019-06-23T09:14:14ZTrue
MDU6SXNzdWU0MzM1NTAyMjE=pretrained GPT-2 checkpoint gets only 31% accuracy on Lambada2019-04-16T02:04:24Z2019-05-29T23:39:38ZTrue
MDU6SXNzdWU0MzM1OTc2MDQ=no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']2019-04-16T06:03:22Z2019-04-17T08:16:25ZTrue
MDU6SXNzdWU0MzM3Nzg1OTc=how to use extracted features in extract_features.py?2019-04-16T13:25:02Z2019-07-12T15:50:30ZTrue
MDU6SXNzdWU0MzQwMjg2NTQ=UnboundLocalError: local variable 'special_tokens_file' referenced before assignment2019-04-16T23:33:31Z2019-04-17T09:06:58ZTrue
MDU6SXNzdWU0MzQxODI2MDM=error when do python3 run_squad.py2019-04-17T09:29:28Z2019-04-23T09:21:24ZTrue
MDU6SXNzdWU0MzQyMDA4MjM=Test a fine-tuned BERT-QA model2019-04-17T10:10:27Z2019-04-18T20:04:27ZTrue
MDU6SXNzdWU0MzQyMTc2ODE=How to obtain attention values for each layer 2019-04-17T10:51:15Z2019-06-23T13:14:13ZTrue
MDU6SXNzdWU0MzQ0Njk2MTY=Init BertForTokenClassification from from_pretrained2019-04-17T20:23:25Z2019-04-24T18:59:21ZTrue
MDU6SXNzdWU0MzQ0ODkxMTM=Generating text with Transformer XL2019-04-17T21:13:58Z2019-04-17T21:42:51ZTrue
MDU6SXNzdWU0MzQ5OTQ1Njg=GPT-2 FineTuning on Cloze/ ROC2019-04-18T23:16:47Z2019-05-03T21:22:29ZTrue
MDU6SXNzdWU0MzU0MDc4ODc=How to read a checkpoint and continue training?2019-04-20T14:54:14Z2019-10-21T19:47:29ZTrue
MDU6SXNzdWU0MzU0NTQzMjQ=Adam optimiser not following Pytorch conventions2019-04-20T23:33:42Z2019-06-28T16:00:15ZTrue
MDU6SXNzdWU0MzU1MDk5OTE=error when trying to use multilingual model for fine tuning2019-04-21T13:29:39Z2019-09-14T02:54:19ZTrue
MDU6SXNzdWU0MzU2MjAzNjE=How many epochs are necessary for finetuning BERT?2019-04-22T06:47:37Z2019-06-29T09:11:33ZTrue
MDU6SXNzdWU0MzU2NzI5NzI=ADD ERNIE2019-04-22T09:57:29Z2019-05-13T06:51:38ZTrue
MDU6SXNzdWU0MzU4MDY3MTM=Same loss values but different eval result2019-04-22T17:19:40Z2019-06-29T09:11:32ZTrue
MDU6SXNzdWU0MzU5ODYyMjE=More SEPs2019-04-23T03:51:06Z2019-06-29T09:11:34ZTrue
MDU6SXNzdWU0MzYxMDkzODE=No GPT2 model2019-04-23T10:17:05Z2019-04-23T11:19:12ZTrue
MDU6SXNzdWU0MzYxMTc3MTg="unable to load finetuned LM ""No file bert_config.json"""2019-04-23T10:37:42Z2019-04-25T19:51:50ZTrue
MDU6SXNzdWU0MzYxMzcwNzE=extending of Transformer-XL for new tasks 2019-04-23T11:28:26Z2019-06-30T13:02:54ZTrue
MDU6SXNzdWU0MzYxNzcxNDI=ImportError: cannot import name 'WEIGHTS_NAME' from 'pytorch_pretrained_bert.file_utils'2019-04-23T13:05:37Z2019-04-25T19:50:58ZTrue
MDU6SXNzdWU0MzYzMDg1ODg=Mixed up isNextSentence label in simple_lm_finetuning.py script? 2019-04-23T17:38:44Z2019-04-24T20:32:18ZTrue
MDU6SXNzdWU0MzY1MTMyNDI=Should I use weight_decay or weight_decay_rate?2019-04-24T06:11:06Z2019-06-30T08:02:54ZTrue
MDU6SXNzdWU0MzY1NjEyNjc=Will BERT weights for SQuAD be released?2019-04-24T08:23:43Z2019-04-24T08:36:11ZTrue
MDU6SXNzdWU0MzY2ODA0MTU=__init__() got an unexpected keyword argument 'do_basic_tokenize'2019-04-24T12:54:48Z2019-06-30T16:02:54ZTrue
MDU6SXNzdWU0MzY2OTE3MjM=Why classifier fine-tuning don't save best model based on the evaluation on dev dataset2019-04-24T13:17:15Z2019-06-24T01:51:14ZTrue
MDU6SXNzdWU0MzY5NjI3NjY=GPT2 training and generating on text longer than 10242019-04-25T00:40:51Z2019-07-01T02:02:54ZTrue
MDU6SXNzdWU0MzcyMTk2MTQ=[Feature request] Support configurable BertLayerNorm epsilon2019-04-25T14:06:52Z2019-04-25T19:12:49ZTrue
MDU6SXNzdWU0MzcyODUyMzU=How many datasets does Bert use in pretraining process?2019-04-25T16:15:58Z2019-07-08T12:23:22ZTrue
MDU6SXNzdWU0MzczMzQwODg=gpt2 fine tuning sources2019-04-25T18:21:04Z2019-10-18T03:11:06ZTrue
MDU6SXNzdWU0Mzc1MDM4MjI=New GPT2 tokenizer no longer encodes Unicode characters properly in Python 32019-04-26T05:24:02Z2019-10-18T15:11:06ZTrue
MDU6SXNzdWU0Mzc1MjY2NTE=key error in BertQuestionAsnwering predict?2019-04-26T06:58:11Z2019-04-26T07:06:41ZTrue
MDU6SXNzdWU0Mzc1MzIxODU=Can we use 'bert-base-uncased' to question_answer just for start, rather rather than run_squad pretraining?2019-04-26T07:15:29Z2019-04-27T08:03:55ZTrue
MDU6SXNzdWU0Mzc1NDk4MjQ=no to_json_file(file) in BERT2019-04-26T08:05:27Z2019-05-02T03:00:02ZTrue
MDU6SXNzdWU0Mzc1NTUwMjY=Any way to reduce the model size to <250mb?2019-04-26T08:19:28Z2019-07-02T17:04:39ZTrue
MDU6SXNzdWU0Mzc3MDIxMjE=Clarifying attention mask2019-04-26T14:32:15Z2019-05-01T14:52:49ZTrue
MDU6SXNzdWU0Mzc3NDEyMDg=How to train our own domain-specific data instead of using pre-training models?2019-04-26T16:01:00Z2019-07-16T09:35:30ZTrue
MDU6SXNzdWU0Mzc3NzQwODY=TypeError: '<' not supported between instances of 'NoneType' and 'int'2019-04-26T17:33:37Z2019-07-05T08:18:16ZTrue
MDU6SXNzdWU0Mzc5ODY4NDg=Import Error2019-04-27T21:38:46Z2019-07-21T10:49:51ZTrue
MDU6SXNzdWU0Mzc5OTE4MzQ=How to get masked word prediction probabilities2019-04-27T22:54:10Z2019-10-09T16:29:28ZTrue
MDU6SXNzdWU0Mzc5OTMzNzI=how to ensemble different checkpoints?2019-04-27T23:19:03Z2019-07-04T00:21:53ZTrue
MDU6SXNzdWU0MzgwMDU1NTY=CUDA out of memory issue when training 2019-04-28T02:51:37Z2019-07-04T09:54:29ZTrue
MDU6SXNzdWU0MzgwMjk3OTk=Pad inputs to multiple of 82019-04-28T08:25:06Z2019-07-04T09:54:30ZTrue
MDU6SXNzdWU0MzgwMzUzNTY=should loss_scale be multiplied to the loss explicitly?2019-04-28T09:25:38Z2019-07-04T13:54:23ZTrue
MDU6SXNzdWU0MzgwOTQ1MDE=How to get back input and predictions as string2019-04-28T20:04:47Z2019-07-04T21:54:23ZTrue
MDU6SXNzdWU0MzgxMDIxMjM=ValueError: For training, each question should have exactly 1 answer.2019-04-28T21:28:03Z2019-07-22T13:11:04ZTrue
MDU6SXNzdWU0MzgyOTgwOTg=Transformer XL from Pytorch model2019-04-29T12:47:17Z2019-07-05T13:18:13ZTrue
MDU6SXNzdWU0Mzg0MzQzMDg=Training beyond specified 't_total' steps with schedule 'warmup_linear'. Learning rate set to 0.0. Please set 't_total' of BertAdam correctly.2019-04-29T17:53:52Z2019-07-27T11:44:29ZTrue
MDU6SXNzdWU0Mzg0NzIwMzU=Expanding vocab size for GTP2 pre-trained model.2019-04-29T19:32:02Z2019-07-06T18:04:23ZTrue
MDU6SXNzdWU0Mzg1MTE1OTk=can one run squad using gpt2?2019-04-29T21:15:43Z2019-07-05T22:18:14ZTrue
MDU6SXNzdWU0Mzg2MDQ1Njc=the size of words and the size of lables do not match2019-04-30T05:01:05Z2019-07-06T09:04:23ZTrue
MDU6SXNzdWU0Mzg5NjM3NTc=Training Transformer XL from scratch2019-04-30T20:30:27Z2019-07-07T10:37:33ZTrue
MDU6SXNzdWU0Mzg5OTk0MDg=performance does not change but loss decrease2019-04-30T22:11:46Z2019-07-07T00:04:23ZTrue
MDU6SXNzdWU0MzkwNTIzNTI=Results of Fine-tuned model changes in every run2019-05-01T02:52:00Z2019-07-07T05:04:23ZTrue
MDU6SXNzdWU0MzkwODU0MjE=Bug in run_classifier.py fp16 learning rate2019-05-01T07:01:53Z2019-05-10T11:48:13ZTrue
MDU6SXNzdWU0MzkxMTU4NTU=about pytorch 1.1.0 rerlease2019-05-01T09:48:27Z2019-07-08T12:23:21ZTrue
MDU6SXNzdWU0MzkyMjg5MDY=Fine-tuning Bert2019-05-01T16:34:17Z2019-08-09T03:58:01ZTrue
MDU6SXNzdWU0MzkzNjUyNjg=License of the pretrained models2019-05-01T23:14:21Z2019-05-02T18:39:25ZTrue
MDU6SXNzdWU0Mzk1NDY5MzE=BERT pre-training using only domain specific text2019-05-02T11:39:02Z2019-07-08T12:23:23ZTrue
MDU6SXNzdWU0Mzk2OTQyOTM=GPT2 doesn't accept inputs of varying tokens length (despite the padding at the end)2019-05-02T17:05:16Z2019-10-13T22:00:30ZTrue
MDU6SXNzdWU0Mzk3MDY3MzE=understanding of the output from TransfoXLModel 2019-05-02T17:37:39Z2019-07-08T18:23:21ZTrue
MDU6SXNzdWU0Mzk5NjM0MzI=Different BERT representations when text is with and without single quotes2019-05-03T09:30:37Z2019-05-03T19:41:22ZTrue
MDU6SXNzdWU0NDAwMDEzODM=key error when using run_classifier.py in predict mode, expecting label?2019-05-03T11:19:02Z2019-07-09T12:29:42ZTrue
MDU6SXNzdWU0NDAwMzY4OTQ=GPT2 lm_labels masking using (-1) throws an index out of range2019-05-03T13:05:39Z2019-08-20T22:44:43ZTrue
MDU6SXNzdWU0NDAwNDA4ODg="""Easy"" path for classifier training / pre-training"2019-05-03T13:16:00Z2019-07-21T14:11:08ZTrue
MDU6SXNzdWU0NDAxMzU4NTI=Resetting current_random_doc and current_doc2019-05-03T17:03:20Z2019-07-12T08:08:27ZTrue
MDU6SXNzdWU0NDAxNDI3OTQ=Bert for passage reranking2019-05-03T17:22:30Z2019-05-07T16:06:22ZTrue
MDU6SXNzdWU0NDAyMTg4MTM=BertAdam gradient clipping is not global2019-05-03T20:56:14Z2019-07-09T21:29:42ZTrue
MDU6SXNzdWU0NDAyNjIwMjc=Add GPT-2 Bigger Model2019-05-04T00:00:49Z2019-07-16T18:17:11ZTrue
MDU6SXNzdWU0NDAyODgxNjk=BERT + PyTorch + XLA2019-05-04T05:49:35Z2019-07-12T08:08:26ZTrue
MDU6SXNzdWU0NDAzNzgxNjI=The number of train examples in STS-B is only 57492019-05-04T22:47:35Z2019-07-10T23:46:51ZTrue
MDU6SXNzdWU0NDA1NjIwNTY=Padding Token in Transformer XL2019-05-06T06:52:29Z2019-07-12T09:08:25ZTrue
MDU6SXNzdWU0NDA1OTU4MjE=From which layer is fine tuning starting in BERT?2019-05-06T08:37:21Z2019-07-24T14:21:04ZTrue
MDU6SXNzdWU0NDA2NzcwMzM=installation error 2019-05-06T12:31:47Z2019-05-10T09:51:47ZTrue
MDU6SXNzdWU0NDA3MDI1NzA=Can't save converted checkpoint2019-05-06T13:34:01Z2019-07-12T14:50:30ZTrue
MDU6SXNzdWU0NDEwMTgwNDg=What is the use of [SEP]?2019-05-07T04:12:16Z2019-05-07T05:12:07ZTrue
MDU6SXNzdWU0NDEwMzA3MDQ=Can the use of [SEP] reduce the information extraction between the sentences?2019-05-07T05:13:00Z2019-05-20T00:06:08ZTrue
MDU6SXNzdWU0NDExMzI3OTE=Embedding' object has no attribute 'shape' 2019-05-07T09:29:43Z2019-08-03T07:35:30ZTrue
MDU6SXNzdWU0NDExNDk1NzA=size mismatch for lm_head.decoder.weight2019-05-07T10:05:22Z2019-07-13T11:22:01ZTrue
MDU6SXNzdWU0NDExOTgyOTA=Unclear error message when unable to cache the model2019-05-07T12:12:06Z2019-10-14T12:23:40ZTrue
MDU6SXNzdWU0NDE3MTUzOTg=[Question] Cross-lingual sentence representations2019-05-08T12:42:27Z2019-05-10T10:25:53ZTrue
MDU6SXNzdWU0NDI2MDM2NDM=BERT tokenizer - set special tokens 2019-05-10T08:38:43Z2019-07-28T12:05:05ZTrue
MDU6SXNzdWU0NDI2MzMzODE=Fine tuning time did not change much after freezing layers 2019-05-10T09:48:26Z2019-07-16T12:07:50ZTrue
MDU6SXNzdWU0NDI2Mzk3OTE=How to reduce embedding size from 768?2019-05-10T10:03:17Z2019-09-09T10:59:08ZTrue
MDU6SXNzdWU0NDI5MzU4Nzc=Different GPT-2 outputs with mixed precision vs single precision2019-05-11T00:38:21Z2019-08-30T19:56:02ZTrue
MDU6SXNzdWU0NDI5OTgwMTQ=Using BERT as feature extractor2019-05-11T14:18:43Z2019-09-12T02:33:40ZTrue
MDU6SXNzdWU0NDMxNTMxNDM=why use  self.apply(self.init_bert_weights) in inhiritance class？2019-05-12T22:16:25Z2019-07-18T23:42:26ZTrue
MDU6SXNzdWU0NDMxNTMyODY=How can we import cased bert model?2019-05-12T22:18:30Z2019-07-18T23:42:27ZTrue
MDU6SXNzdWU0NDMxNTMzOTA=How to check the vocab size of bert large and bert small?2019-05-12T22:20:02Z2019-07-18T23:42:28ZTrue
MDU6SXNzdWU0NDM5NjQ3MzA=when using multiple GPUs, `loss.mean()` may have subtle bias 2019-05-14T14:57:04Z2019-07-21T09:49:51ZTrue
MDU6SXNzdWU0NDQzMTM3NTY=t_total2019-05-15T08:51:35Z2019-05-15T08:52:39ZTrue
MDU6SXNzdWU0NDQzMTU5OTQ=t_total2019-05-15T08:56:33Z2019-05-15T12:32:33ZTrue
MDU6SXNzdWU0NDQ0MTMzOTk=extract_features2019-05-15T12:35:46Z2019-08-02T16:51:55ZTrue
MDU6SXNzdWU0NDQ0NjYwMjE=How to use the fine tuned model for classification (CoLa) task?2019-05-15T14:18:16Z2019-08-15T12:36:12ZTrue
MDU6SXNzdWU0NDQ1MDEyNjQ=Learning from scratch not working2019-05-15T15:22:40Z2019-07-21T16:11:04ZTrue
MDU6SXNzdWU0NDUzMjU3Nzk=Couldn't import '''BertPreTrainedModel'''2019-05-17T08:30:10Z2019-07-26T14:07:34ZTrue
MDU6SXNzdWU0NDUzNTQ3NDE=TransfoXLModel and TransforXLLMModel have the same example2019-05-17T09:40:14Z2019-07-23T12:14:12ZTrue
MDU6SXNzdWU0NDUzODMzMTM=How to get the softmax probabilities from the TransfoXLLMModel2019-05-17T10:51:10Z2019-07-23T12:14:13ZTrue
MDU6SXNzdWU0NDU3MDMyNjI=Loss function of run_classifier.py takes in 2 inputs of different dimensions. 2019-05-18T10:37:57Z2019-05-18T10:58:15ZTrue
MDU6SXNzdWU0NDU3NDc2NTE=Custom data, gradient explosion, accuracy is 02019-05-18T19:39:59Z2019-07-24T19:58:27ZTrue
MDU6SXNzdWU0NDU3ODQxNTk=Question on duplicated sentence2019-05-19T06:01:58Z2019-07-26T18:44:29ZTrue
MDU6SXNzdWU0NDU4ODQwNzY="In run_classifier.py, is ""warmup_proportion"" a fraction or percentage?"2019-05-20T00:43:26Z2019-08-02T08:51:57ZTrue
MDU6SXNzdWU0NDU5MTQzMDQ=Integration with a retriever Model2019-05-20T04:05:35Z2019-07-27T09:44:29ZTrue
MDU6SXNzdWU0NDYxMTI1ODI=tokenization_gpt2.py - on python 2 you can use backports.functools_lru_cache package from pypi2019-05-20T13:17:14Z2019-07-26T14:07:35ZTrue
MDU6SXNzdWU0NDYyMDM5NDE=Tried to visualize the CLS Token embeddings after fine-tuning on SST-2 using t-SNE, but no clear clustered visualizations of positive and negative sentences !2019-05-20T16:20:45Z2019-07-27T15:44:30ZTrue
MDU6SXNzdWU0NDY1Mjk0NDQ=How to use run_squad.py to produce multiple answers for a question?2019-05-21T10:03:32Z2019-09-27T17:29:41ZTrue
MDU6SXNzdWU0NDY1NTE2NTg=BERT QnA is not matching correct answer when document is in QnA format2019-05-21T10:54:34Z2019-08-24T12:25:40ZTrue
MDU6SXNzdWU0NDY3MjYwMzY=IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)2019-05-21T16:57:57Z2019-05-21T17:02:05ZTrue
MDU6SXNzdWU0NDY5NTI2OTU=Is loss.mean() needed?2019-05-22T06:22:41Z2019-07-30T07:52:01ZTrue
MDU6SXNzdWU0NDcwNzk1MzU=from_pretrained2019-05-22T11:23:23Z2019-07-28T15:05:05ZTrue
MDU6SXNzdWU0NDcxNTIxMzk=run_classifier.py:TypeError: forward() missing 1 required positional argument: 'input_ids'2019-05-22T13:55:40Z2019-09-01T08:02:24ZTrue
MDU6SXNzdWU0NDc0ODE0MjU=bert->onnx ->caffe2 weird error2019-05-23T06:59:07Z2019-07-29T07:38:47ZTrue
MDU6SXNzdWU0NDc1MjYxOTQ=convert_tf_checkpoint_to_pytorch get different result?2019-05-23T08:50:45Z2019-07-29T12:38:47ZTrue
MDU6SXNzdWU0NDc1NDAyOTA=GPT2 - support data type torch.DoubleTensor for Position embedding2019-05-23T09:19:24Z2019-08-15T13:30:31ZTrue
MDU6SXNzdWU0NDc4NTUyNzk=Training Dataset of GPT-22019-05-23T20:20:45Z2019-08-24T16:25:42ZTrue
MDU6SXNzdWU0NDc5ODY5Mjc=run_squad.py F1 and EM score are differ from tensorflow version 2019-05-24T05:34:50Z2019-07-30T10:52:02ZTrue
MDU6SXNzdWU0NDgwMjAxNTQ=GPT-2 Tokenizer error!2019-05-24T07:30:29Z2019-05-29T16:31:07ZTrue
MDU6SXNzdWU0NDgyMzY4OTE=Isn't it too few activations?2019-05-24T15:44:16Z2019-07-30T16:52:02ZTrue
MDU6SXNzdWU0NDkzNDk1NTc=The prediction accuracy for the masked token is ZERO when using the pretrained model. Does it make sense?2019-05-28T15:54:39Z2019-05-30T13:08:25ZTrue
MDU6SXNzdWU0NDkzNDk4NzE=Performing optimization on CPU2019-05-28T15:55:17Z2019-09-11T11:48:09ZTrue
MDU6SXNzdWU0NDk0MDE4MTA=FileNotFoundError: [Errno 2] No such file or directory: 'uncased_L-12_H-768_A-12\\pytorch_model.bin'2019-05-28T17:57:49Z2019-06-19T15:49:34ZTrue
MDU6SXNzdWU0NDk1NzI3MTI=RuntimeError: cublas runtime error : an internal operation failed at /pytorch/aten/src/THC/THCBlas.cu:2582019-05-29T02:51:41Z2019-08-09T01:00:59ZTrue
MDU6SXNzdWU0NDk2NzAwNTQ=BertAdam's get_lr() not return correct learning rate2019-05-29T08:34:48Z2019-08-04T09:18:22ZTrue
MDU6SXNzdWU0NTAyNTY3Mzc=No softmax activation in BertForTokenClassification2019-05-30T11:16:34Z2019-05-30T11:25:49ZTrue
MDU6SXNzdWU0NTAyOTU5NTA=[Dropout] why  there is no dropout for the dev and eval?2019-05-30T13:00:50Z2019-07-02T03:32:39ZTrue
MDU6SXNzdWU0NTAyOTg3MDU=fine-tuning BERT, next sentence prediction loss is not decreasing2019-05-30T13:07:23Z2019-08-05T13:57:57ZTrue
MDU6SXNzdWU0NTA2MjY5NDA=RuntimeError: CUDA error: device-side assert triggered2019-05-31T05:53:27Z2019-08-05T06:42:05ZTrue
MDU6SXNzdWU0NTA2OTcxNjE=Different Results from version 0.4.0 to version 0.5.02019-05-31T09:12:52Z2019-05-31T12:02:55ZTrue
MDU6SXNzdWU0NTA5MjQ5MDc=use of special tokens in gpt2?2019-05-31T18:23:42Z2019-08-07T00:44:32ZTrue
MDU6SXNzdWU0NTEzNTY0NjA=Use of GPT for multilingual LM2019-06-03T08:33:13Z2019-08-09T08:58:00ZTrue
MDU6SXNzdWU0NTE4Nzg2Njc=How to use different learning rates in the classifier example.2019-06-04T09:02:16Z2019-08-05T09:58:34ZTrue
MDU6SXNzdWU0NTIwMjA2MTc=SQuAD 1.1 very low evaluation score when using `--fp16`2019-06-04T14:10:49Z2019-08-12T08:20:31ZTrue
MDU6SXNzdWU0NTIwOTg1NzI=Whole Word Masking Models update2019-06-04T16:41:02Z2019-08-26T11:47:25ZTrue
MDU6SXNzdWU0NTI4MDgyMzk=Recommended batch size and epochs for finetuning on large data2019-06-06T03:00:42Z2019-08-12T04:20:31ZTrue
MDU6SXNzdWU0NTI4ODU4MTU=How to load a existing model2019-06-06T08:01:35Z2019-08-31T09:56:04ZTrue
MDU6SXNzdWU0NTI5NzQ0NTI="MRPC / SQuAD stuck in ""Running training"""2019-06-06T11:19:44Z2019-06-11T15:52:46ZTrue
MDU6SXNzdWU0NTMwODgyMTY=Accumulation2019-06-06T15:12:33Z2019-06-06T15:12:45ZTrue
MDU6SXNzdWU0NTMzMDk2MjM=Padding in GPT-2  2019-06-07T02:09:05Z2019-08-31T09:56:03ZTrue
MDU6SXNzdWU0NTM3NDQ4MDc=GPT-2 medium and large release?2019-06-08T02:04:14Z2019-06-08T20:34:31ZTrue
MDU6SXNzdWU0NTM3NzMyMTI=GPT2 generating repetitive text2019-06-08T09:01:22Z2019-09-15T14:13:22ZTrue
MDU6SXNzdWU0NTM5NzU3MzA=when I use bert-large-uncased to load bert,runtimeError occured,but base-uncase is ok2019-06-10T02:45:39Z2019-08-17T10:10:43ZTrue
MDU6SXNzdWU0NTQwNTAxMjk=`get_final_text` bug when dealing with chinese sentence2019-06-10T08:14:17Z2019-08-16T09:58:55ZTrue
MDU6SXNzdWU0NTQ0OTExNDQ=warmup for BertAdam2019-06-11T05:46:15Z2019-06-12T02:42:44ZTrue
MDU6SXNzdWU0NTQ1MTA1ODY=BERT  what's different with step and t_total2019-06-11T06:54:23Z2019-06-18T06:10:57ZTrue
MDU6SXNzdWU0NTQ4NTkyNTE=LM fine-tuning without NSP2019-06-11T19:16:23Z2019-08-23T14:46:34ZTrue
MDU6SXNzdWU0NTQ4NzAwNzg=Gradual unfreezing and discriminative fine-tuning for BERT2019-06-11T19:43:10Z2019-08-18T09:23:05ZTrue
MDU6SXNzdWU0NTUxMzUwMjY=Importing TF checkpoint as BertForTokenClassificiation2019-06-12T10:30:10Z2019-06-27T02:45:53ZTrue
MDU6SXNzdWU0NTUyOTYyNDM=Download the model without executing a Python script2019-06-12T15:57:14Z2019-06-15T00:03:10ZTrue
MDU6SXNzdWU0NTU0MjIxNDY=Transformer XL ProjectedAdaptiveLogSoftmax bug (maybe?)2019-06-12T20:59:35Z2019-06-16T03:34:02ZTrue
MDU6SXNzdWU0NTU2MTU0Njc=Why the output of models are random.2019-06-13T08:53:25Z2019-06-14T20:22:07ZTrue
MDU6SXNzdWU0NTU2MjcxODY=Limit on the input text length?2019-06-13T09:17:14Z2019-06-15T00:03:27ZTrue
MDU6SXNzdWU0NTU4MTY1ODM=Can BertForMaskedLM be used to predict out-of-vocabulary words?2019-06-13T15:43:47Z2019-08-16T16:23:23ZTrue
MDU6SXNzdWU0NTU4NTk2OTQ=Can't find gpt2 vocab file. 2019-06-13T17:19:41Z2019-06-13T18:08:45ZTrue
MDU6SXNzdWU0NTYwMTk5Mzg=Implementation of 15% words masking in pretraining2019-06-14T01:24:19Z2019-09-16T13:44:28ZTrue
MDU6SXNzdWU0NTYxODgxMDc=How to use GPT2 to predict and fit a word into an existing sentence?2019-06-14T10:59:11Z2019-08-15T13:30:35ZTrue
MDU6SXNzdWU0NTY0NDEwMTA=Failing to run pregenerate_training_data.py & finetune_on_pregenerated.py2019-06-14T21:09:57Z2019-09-17T13:45:53ZTrue
MDU6SXNzdWU0NTY2MTE1ODU=Include a reference on in-domain LM pre-training for BERT2019-06-16T07:24:09Z2019-08-28T21:00:01ZTrue
MDU6SXNzdWU0NTY3MjU1MzM=Have no GPU to train language modelling2019-06-17T03:28:51Z2019-06-18T12:57:48ZTrue
MDU6SXNzdWU0NTcxODc0MjE=BERT output not deterministic2019-06-17T23:07:59Z2019-08-24T07:46:35ZTrue
MDU6SXNzdWU0NTc2MDYwMDU=convert_gpt2_checkpoint_to_pytorch dimensions assertion error2019-06-18T17:27:40Z2019-06-19T15:14:32ZTrue
MDU6SXNzdWU0NTc4NDc4NDk=Fine tuning GPT-2 for LM objective function2019-06-19T07:21:08Z2019-10-13T22:00:31ZTrue
MDU6SXNzdWU0NTgwNjU4MjM=Low SQuADv2 F1 & EM Score2019-06-19T14:59:55Z2019-08-29T04:00:01ZTrue
MDU6SXNzdWU0NTgwNzU2Nzc="""Received 'killed' signal"" during the circleci python3 build after submitting PR"2019-06-19T15:18:33Z2019-06-25T08:06:17ZTrue
MDU6SXNzdWU0NTgzMzgzMDI=Implementing XLNet in pytorch2019-06-20T04:26:24Z2019-09-04T10:44:30ZTrue
MDU6SXNzdWU0NTg5MDQxODA=Future attention masking in GPT/GPT-2?2019-06-20T22:00:07Z2019-08-13T03:02:26ZTrue
MDU6SXNzdWU0NTkxNTQ2MTI=layer_norm_eps2019-06-21T11:37:50Z2019-06-21T14:27:01ZTrue
MDU6SXNzdWU0NTkxNzQ5NDM=A way to increase input length limitation?2019-06-21T12:33:32Z2019-06-25T08:06:53ZTrue
MDU6SXNzdWU0NTkzNDU4NTE=BERT Tokenizer not working! Failed to load the bert-base-uncased model.2019-06-21T19:41:48Z2019-10-14T19:11:55ZTrue
MDU6SXNzdWU0NTk0NTI5NDE=TypeError: expand_as() takes 1 positional argument but 5 were given2019-06-22T08:41:11Z2019-08-28T11:00:01ZTrue
MDU6SXNzdWU0NTk1MjAzMDY=BPE vocab2019-06-22T23:38:38Z2019-08-29T12:07:59ZTrue
MDU6SXNzdWU0NTk3MzQ3MjA=Embedding and predictions in one forward pass2019-06-24T07:31:48Z2019-06-25T08:05:04ZTrue
MDU6SXNzdWU0NTk5MDk0MDc=Import Error: cannot import name 'warmup_linear'2019-06-24T14:00:40Z2019-08-05T08:59:54ZTrue
MDU6SXNzdWU0NTk5NDk4MjY=Usual loss when pretraining?2019-06-24T15:13:35Z2019-09-09T19:29:52ZTrue
MDU6SXNzdWU0NjAxNDQwMDU=low accuracy when fine tuning for the MRPC task with large model2019-06-24T23:48:54Z2019-08-31T17:02:23ZTrue
MDU6SXNzdWU0NjA1MzM4NjM=BERT Input size reduced to half in forward function 2019-06-25T16:52:21Z2019-06-26T03:15:16ZTrue
MDU6SXNzdWU0NjA3MjUxNTc=Examples does not work with apex optimizers2019-06-26T02:12:21Z2019-07-16T09:51:24ZTrue
MDU6SXNzdWU0NjA3NDczNjM=Poor Training and evaluation accuracy even with low loss2019-06-26T03:57:51Z2019-09-06T17:38:58ZTrue
MDU6SXNzdWU0NjA4MzY3NTc=UnicodeDecodeError:2019-06-26T08:39:21Z2019-09-01T14:06:26ZTrue
MDU6SXNzdWU0NjA4NDE2NzQ=Grover generator support2019-06-26T08:49:43Z2019-09-01T10:02:23ZTrue
MDU6SXNzdWU0NjA5NDg3MDI=bertForNextSentencePrediction2019-06-26T12:43:42Z2019-06-29T07:06:01ZTrue
MDU6SXNzdWU0NjExMzE0OTE=GPT & GPT2: binary classification fails2019-06-26T19:00:32Z2019-09-01T22:06:28ZTrue
MDU6SXNzdWU0NjEzNDI2NTY=Erroneous Code2019-06-27T06:34:24Z2019-09-02T08:06:27ZTrue
MDU6SXNzdWU0NjE2NDg3ODY=BERT encoding layer produces same output for all inputs during evaluation 2019-06-27T17:12:22Z2019-07-09T15:44:50ZTrue
MDU6SXNzdWU0NjE3ODkyMzQ=Question regarding crossentropy loss function for BERTMaskedLM 2019-06-27T23:21:13Z2019-09-10T07:29:52ZTrue
MDU6SXNzdWU0NjE4MTUyMDI=gpt-2 model doesn't output hidden states of all layers.2019-06-28T01:30:28Z2019-09-04T14:17:13ZTrue
MDU6SXNzdWU0NjE4NDUyMzA=BertTokenizer never_split issue2019-06-28T04:05:43Z2019-09-06T09:36:14ZTrue
MDU6SXNzdWU0NjIwODA5MTA="where is ""pytorch_model.bin""?"2019-06-28T15:09:50Z2019-09-03T17:19:30ZTrue
MDU6SXNzdWU0NjIyOTM3MjQ=How to get perplexity score of a sentence using anyone of the given Language Models?2019-06-29T11:30:25Z2019-09-04T12:19:30ZTrue
MDU6SXNzdWU0NjIzMDQ3MzQ=Using BertForNextSentencePrediction and GPT2LMHeadModel in a GAN setup.2019-06-29T13:55:58Z2019-07-03T11:40:31ZTrue
MDU6SXNzdWU0NjI0MTAzOTM=Cannot reproduce results from version 0.4.02019-06-30T14:22:07Z2019-07-01T03:50:41ZTrue
MDU6SXNzdWU0NjI3MTI3NDk=Recommended multilingual bert cased model returns similar embeddings 2019-07-01T13:24:04Z2019-09-06T21:38:58ZTrue
MDU6SXNzdWU0NjMxMTgyODI=GPT2Tokenizer for Hindi Data2019-07-02T09:22:14Z2019-10-27T08:30:37ZTrue
MDU6SXNzdWU0NjMxNDMwNzI=BERT pretraining routine2019-07-02T10:14:06Z2019-07-13T21:26:32ZTrue
MDU6SXNzdWU0NjMzNTY1MTg=Attribute Error : 'BertModel' object has no attribute 'bert'2019-07-02T17:45:04Z2019-09-13T11:02:46ZTrue
MDU6SXNzdWU0NjM0MjU0MTA=Incorrect training loss scaling factor in examples/run_classifier.py?2019-07-02T20:39:55Z2019-09-14T22:13:20ZTrue
MDU6SXNzdWU0NjM0OTA3NDg=Slower and more memory hungry than the TensorFlow BERT?2019-07-03T00:30:47Z2019-11-14T21:03:33ZTrue
MDU6SXNzdWU0NjM1NzgwMzk=how to set the init learning rate when use bertAdam?2019-07-03T06:57:04Z2019-09-08T07:39:32ZTrue
MDU6SXNzdWU0NjM5NTkzMDE=`bert-base-uncased` works for CoLA, `bert-large-uncased` always predicts one class2019-07-03T21:23:12Z2019-09-08T22:59:08ZTrue
MDU6SXNzdWU0NjM5NjcxNDE=Get Attention Values for Pretrained Model2019-07-03T21:45:56Z2019-09-10T07:29:51ZTrue
MDU6SXNzdWU0NjQyODI3MzU=Invalid Syntax Error trying to run pregenerate_training_data.py2019-07-04T14:00:56Z2019-09-13T17:02:47ZTrue
MDU6SXNzdWU0NjQ3Njg1NDQ=Simple LM finetuning falls with RunTime Error: CUDA out of memory2019-07-05T20:41:42Z2019-09-27T22:08:21ZTrue
MDU6SXNzdWU0NjUwMDQwOTU=Help loading BioBERT weights2019-07-07T23:23:36Z2019-10-03T04:01:36ZTrue
MDU6SXNzdWU0NjUwNTE4OTA=randrange() error when running pregenerate_training_data.py code in lm_finetuning2019-07-08T04:45:29Z2019-09-13T06:02:46ZTrue
MDU6SXNzdWU0NjUxNDkwODE=''bert-large-uncased-whole-word-masking-finetuned-squad' CAN'T be reached.2019-07-08T09:24:16Z2019-09-14T21:13:20ZTrue
MDU6SXNzdWU0NjUzMzcyNDY=Adding extra inputs when fine-tuning BERT2019-07-08T15:55:58Z2019-09-18T00:32:10ZTrue
MDU6SXNzdWU0NjU1MTE4NjE=Is is possible to fine-tune GPT2 on downstream tasks currently?2019-07-09T00:16:41Z2019-10-11T10:44:12ZTrue
MDU6SXNzdWU0NjU3Nzg0MzI=Fine tune Xlnet2019-07-09T13:23:07Z2019-09-22T07:23:28ZTrue
MDU6SXNzdWU0NjU4NjE0MjA=GPT-2 language model decoding method2019-07-09T15:55:04Z2019-07-13T21:13:39ZTrue
MDU6SXNzdWU0NjYwOTkzMzc=XLNet tensor at wrong device issuse2019-07-10T04:56:24Z2019-07-13T21:11:05ZTrue
MDU6SXNzdWU0NjYzOTQzNTk=How can I load a fine-tuned model? 2019-07-10T16:03:27Z2019-09-18T21:38:28ZTrue
MDU6SXNzdWU0NjY0NzUyODA=Performance dramatically drops down without training. 2019-07-10T19:19:38Z2019-07-13T21:06:28ZTrue
MDU6SXNzdWU0NjY1NjA4MDU=Cannot load 'bert-base-german-cased'2019-07-10T22:48:48Z2019-07-11T10:27:16ZTrue
MDU6SXNzdWU0NjY2MzIyNzc=XLNet text generation ability2019-07-11T02:57:50Z2019-07-13T21:04:09ZTrue
MDU6SXNzdWU0NjY5MTI4NjI=Order of tokens in vocabulary of German model2019-07-11T14:02:16Z2019-09-22T09:23:28ZTrue
MDU6SXNzdWU0NjcwODQ3ODI=Should close the SummaryWriter after using it2019-07-11T20:12:59Z2019-07-13T21:01:51ZTrue
MDU6SXNzdWU0NjcxMjc2MzU=Fail to run finetune_on_pregenerated.py2019-07-11T22:01:23Z2019-09-16T22:45:52ZTrue
MDU6SXNzdWU0NjcxNzU0MzE=Why the activation function is tanh in BertPooler2019-07-12T01:23:47Z2019-07-13T21:04:20ZTrue
MDU6SXNzdWU0NjcxODE5Mjk=how to get the word vector from bert pretrain model ?2019-07-12T01:53:41Z2019-07-12T06:39:14ZTrue
MDU6SXNzdWU0NjcyMjY0MjA=[bug] from_pretrained  error with from_tf2019-07-12T05:22:08Z2019-07-13T20:59:18ZTrue
MDU6SXNzdWU0NjcyNzIyMzA=Implementation of 15% words masking would cause the drop of performance in short text 2019-07-12T07:50:50Z2019-09-17T08:45:53ZTrue
MDU6SXNzdWU0Njc5MDQzMTk=How to use Bert QA model for predictions?2019-07-15T00:50:48Z2019-09-23T00:33:57ZTrue
MDU6SXNzdWU0NjgxNDA2ODE=bert-large config file2019-07-15T13:52:49Z2019-09-20T15:02:12ZTrue
MDU6SXNzdWU0NjgzOTAwODM=XLNet text generation ability : inference is slow2019-07-16T00:23:34ZFalse
MDU6SXNzdWU0Njg1NzQ4ODI=XLNet Embeddings2019-07-16T10:27:47Z2019-08-27T12:16:04ZTrue
MDU6SXNzdWU0Njg3OTA0NjM=Issue running run_transfo_xl.py2019-07-16T18:03:38Z2019-07-16T19:22:26ZTrue
MDU6SXNzdWU0Njg3OTI1Mjc=BertModel docstring missing pooled_output2019-07-16T18:08:51Z2019-07-16T19:36:02ZTrue
MDU6SXNzdWU0Njg4NzgwMzc=XLNet-large-cased: hyper-parameters for fine-tuning on SST-22019-07-16T21:42:09Z2019-09-30T11:09:30ZTrue
MDU6SXNzdWU0NjkwMDEyMTg=[bug]BertAdam change to AdamW in example2019-07-17T05:59:02Z2019-07-19T07:10:04ZTrue
MDU6SXNzdWU0NjkwMDgzMDI=Error while adding new tokens to GPT2 tokenizer2019-07-17T06:22:02Z2019-08-05T17:17:48ZTrue
MDU6SXNzdWU0NjkwMTE1MDg=attention_mask at run_squad.py2019-07-17T06:30:54Z2019-07-17T11:51:20ZTrue
MDU6SXNzdWU0NjkwODYyODE=fp16+xlnet did not gain any speed increase 2019-07-17T09:30:23Z2019-11-21T15:49:12ZTrue
MDU6SXNzdWU0NjkxMzU3OTA=AssertionError in BERT-Quickstart example2019-07-17T11:21:44Z2019-07-17T12:23:03ZTrue
MDU6SXNzdWU0NjkxOTU2MDM=Answers to Bullet/List Items by bert2019-07-17T13:31:49Z2019-09-22T14:23:28ZTrue
MDU6SXNzdWU0NjkyNzA4NTI="Where is ""run_bert_classifier.py""?"2019-07-17T14:57:53Z2019-07-17T15:34:03ZTrue
MDU6SXNzdWU0NjkzNjA0NTE=AttributeError: 'tuple' object has no attribute 'softmax'2019-07-17T17:53:07Z2019-07-17T19:07:58ZTrue
MDU6SXNzdWU0NjkzODA0NzQ=GPT2 model does not have attention mask2019-07-17T18:36:10Z2019-08-20T23:54:07ZTrue
MDU6SXNzdWU0Njk0Mjk2ODI=Problem loading finetuned XLNet model2019-07-17T20:30:57Z2019-07-25T11:38:08ZTrue
MDU6SXNzdWU0Njk0MzY0NjA=SEG_ID constants for XLNet misleading/off2019-07-17T20:45:40Z2019-07-18T21:36:07ZTrue
MDU6SXNzdWU0Njk1MTA5NDI=do I need to add sep and cls token in each sequence ?2019-07-18T00:22:57Z2019-07-19T00:26:41ZTrue
MDU6SXNzdWU0Njk1MTU1NTU=How to use BertModel ?2019-07-18T00:41:46Z2019-10-01T08:09:04ZTrue
MDU6SXNzdWU0Njk1MzUzNzY=Is there any plan of developing softmax-weight function for using 12 hidden BERT layer? 2019-07-18T02:03:24Z2019-09-24T16:29:11ZTrue
MDU6SXNzdWU0Njk1OTMyNzI=from pytorch-pretrained-bert to pytorch-transformers，some problem2019-07-18T06:32:50Z2019-09-23T23:29:11ZTrue
MDU6SXNzdWU0Njk2MDUxNTc=GPT sentence log loss: average or summed loss?2019-07-18T07:09:05Z2019-07-18T21:26:17ZTrue
MDU6SXNzdWU0Njk2MDc5NTA=Output of BertModel does not match the last hidden layer from fixed feature vectors2019-07-18T07:16:38Z2019-10-30T03:12:56ZTrue
MDU6SXNzdWU0Njk2OTI2NDE=RuntimeError: Creating MTGP constants failed2019-07-18T10:29:49Z2019-11-16T06:53:18ZTrue
MDU6SXNzdWU0Njk3MzEzNTA=Couldn't reach server 2019-07-18T12:03:44Z2019-11-02T13:51:37ZTrue
MDU6SXNzdWU0Njk3OTE5MzI=XLNet-large-cased on Squad 2.0: can't replicate results2019-07-18T14:09:31Z2019-10-27T02:07:30ZTrue
MDU6SXNzdWU0Njk4MzI2Mzg=Updating simple_lm_finetuning.py for FP16 training2019-07-18T15:19:54Z2019-10-12T16:40:24ZTrue
MDU6SXNzdWU0Njk4NjI0Nzk=Bertology example is probably broken2019-07-18T16:15:13Z2019-09-21T15:50:04ZTrue
MDU6SXNzdWU0Njk4Nzc5Mjg=Chinese BERT broken probably after `pytorch-transformer` release2019-07-18T16:49:13Z2019-07-26T08:19:31ZTrue
MDU6SXNzdWU0Njk4ODc4MjY=Providing older documentation2019-07-18T17:09:06Z2019-07-19T07:37:13ZTrue
MDU6SXNzdWU0Njk5NDczMzA=xlnet input_mask and attention_mask type error2019-07-18T19:25:01Z2019-07-23T12:06:56ZTrue
MDU6SXNzdWU0Njk5NzgzMzU=CUDA error: invalid configuration argument when not using DataParallel2019-07-18T20:38:46Z2019-07-19T14:22:11ZTrue
MDU6SXNzdWU0NzAwMTI4ODc=RoBERTa support2019-07-18T22:05:10Z2019-12-04T13:50:39ZTrue
MDU6SXNzdWU0NzAwNzQwNzU=AdamW does not have args warmup and t_total2019-07-19T00:39:41Z2019-09-28T14:00:07ZTrue
MDU6SXNzdWU0NzAwNzU0Mjc=finetune_on_pregenerate Loss.backwards() throw an error 2019-07-19T00:42:46Z2019-07-23T12:12:48ZTrue
MDU6SXNzdWU0NzAxMDY3MDE=Training with wrong GPU count2019-07-19T02:27:13Z2019-08-09T22:46:41ZTrue
MDU6SXNzdWU0NzAxNTI0Njk=missing 1 required positional argument: 'num_classes' in 'from_pretrained'2019-07-19T06:00:59Z2019-08-09T01:19:30ZTrue
MDU6SXNzdWU0NzAxNTQxOTk=git pull pytorch-transformers??2019-07-19T06:07:16Z2019-07-19T15:07:27ZTrue
MDU6SXNzdWU0NzAxNzczNzA=How to use the pretrain script with only token classification task ?2019-07-19T07:20:16Z2019-08-09T22:46:51ZTrue
MDU6SXNzdWU0NzAzNDQxODg=BertForNextSentencePrediction labels2019-07-19T14:06:03Z2019-08-09T22:47:19ZTrue
MDU6SXNzdWU0NzAzNDgwNzM=run_openai_gpt.py issues with Adamw2019-07-19T14:13:50Z2019-09-28T23:24:33ZTrue
MDU6SXNzdWU0NzAzNzIzNDA=Standardized head for Question Answering2019-07-19T15:03:36Z2019-11-25T10:31:02ZTrue
MDU6SXNzdWU0NzA1MTUxMTM=How to restore a training?2019-07-19T19:58:37Z2019-09-30T18:09:31ZTrue
MDU6SXNzdWU0NzA1NTI3NjE=AttributeError: 'BertModel' object has no attribute '_load_from_state_dict'2019-07-19T21:08:44Z2019-08-03T11:15:10ZTrue
MDU6SXNzdWU0NzA2MTMzOTA=Detaching Variables2019-07-20T00:24:35Z2019-09-28T16:00:09ZTrue
MDU6SXNzdWU0NzA2MjAyMTI=16 GB dataset for finetuning fail on reduce_memory 2019-07-20T01:28:11Z2019-09-25T02:04:30ZTrue
MDU6SXNzdWU0NzA2MzEyNDE=Issue 2019-07-20T03:51:49Z2019-07-20T07:16:12ZTrue
MDU6SXNzdWU0NzA3MjQwMjI=XLNET completely wrong and random output2019-07-20T23:25:57Z2020-02-09T14:58:55ZTrue
MDU6SXNzdWU0NzA3ODExOTA=adaptive softmax in transformer-xl2019-07-21T13:22:04Z2019-09-28T16:00:09ZTrue
MDU6SXNzdWU0NzA3ODI3ODI=can't find utils_glue2019-07-21T13:38:55Z2019-09-27T14:29:41ZTrue
MDU6SXNzdWU0NzA3ODY5Njk=Confused about the prune heads operation.2019-07-21T14:21:07Z2019-07-24T07:35:26ZTrue
MDU6SXNzdWU0NzA4NTkxMjY=problem when calling resize_token_embeddings2019-07-22T02:08:29Z2019-10-11T10:44:14ZTrue
MDU6SXNzdWU0NzA4Njg0Mzc=UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.2019-07-22T02:55:22Z2019-10-07T19:54:30ZTrue
MDU6SXNzdWU0NzA4ODEyNzM=Error loading converted pytorch checkpoint2019-07-22T04:01:29Z2019-07-24T02:22:51ZTrue
MDU6SXNzdWU0NzA4ODY4NTY=Get the different result at BertModel2019-07-22T04:31:33Z2019-09-28T16:00:10ZTrue
MDU6SXNzdWU0NzA4OTIwODE=modeling_xlnet.py lines 798  torch.eisum('i,d->id', pos_seq, inv_freq)2019-07-22T04:55:53Z2019-12-01T03:07:47ZTrue
MDU6SXNzdWU0NzA4OTk5NTE=manually download models2019-07-22T05:31:09Z2019-10-05T11:43:30ZTrue
MDU6SXNzdWU0NzEwMDMwODc=XLMForMaskedLM2019-07-22T09:57:54Z2019-09-28T18:00:08ZTrue
MDU6SXNzdWU0NzEwNjQ5Mjk=CLS segment_id for BERT2019-07-22T12:23:08Z2019-07-23T14:46:03ZTrue
MDU6SXNzdWU0NzEwNjU4NzE=Bug of BertTokenizer2019-07-22T12:25:06Z2019-07-24T00:51:17ZTrue
MDU6SXNzdWU0NzExNzg5NDI=Deleting models2019-07-22T16:32:13Z2019-07-22T16:54:05ZTrue
MDU6SXNzdWU0NzEyMTk4MjQ=Bert encodings2019-07-22T17:43:30Z2019-10-11T10:44:11ZTrue
MDU6SXNzdWU0NzEyNjY0NDk=PreTrainedModel.from_pretrained(...) doesn't pass cache_dir to PretrainedConfig.from_pretrained(...)2019-07-22T19:15:00Z2019-07-23T16:18:01ZTrue
MDU6SXNzdWU0NzEyOTMwOTY=Using Fp16 half precision makes Bert prediction slower.2019-07-22T20:01:12Z2019-10-11T13:44:10ZTrue
MDU6SXNzdWU0NzE0NTExMjM=XLnet sentence vector2019-07-23T02:06:26Z2019-10-11T10:44:13ZTrue
MDU6SXNzdWU0NzE1NTA1MTc=fp16 is broken2019-07-23T08:18:21Z2019-07-23T15:46:14ZTrue
MDU6SXNzdWU0NzE1NTE2MTU= module 'torch.nn' has no attribute 'Identity'2019-07-23T08:20:57Z2019-07-23T16:16:36ZTrue
MDU6SXNzdWU0NzE1NzI5MDY=How to load a fine-tuned model pytorch_model.bin produced by run_bert_swag.py2019-07-23T09:04:06Z2019-07-24T07:49:45ZTrue
MDU6SXNzdWU0NzE2NTI2Mzk=fp16 is not work2019-07-23T11:52:50Z2019-07-23T15:59:05ZTrue
MDU6SXNzdWU0NzE4MzU1MTc=Fine-tuning model and Generation2019-07-23T17:43:02Z2019-11-15T08:03:34ZTrue
MDU6SXNzdWU0NzE4NTAwNTI=XLNet bidirectional input pipeline requires batch size at least 22019-07-23T18:18:01Z2019-09-28T20:00:09ZTrue
MDU6SXNzdWU0NzE5ODg3MzU=How to use BERT for finding similar sentences or similar news? 2019-07-23T22:16:01ZFalse
MDU6SXNzdWU0NzE5OTAzMTk=error when tried to migrate from pretrained-bert to transformers.2019-07-23T22:18:56Z2019-07-24T16:02:59ZTrue
MDU6SXNzdWU0NzIxMTM4ODc=Fail to load pre-trained tokens.2019-07-24T07:02:30Z2019-10-20T13:44:00ZTrue
MDU6SXNzdWU0NzIxMTU2NjM=Printing Iteration every example problem2019-07-24T07:07:29Z2019-10-04T01:04:33ZTrue
MDU6SXNzdWU0NzIxMjYwMjA=can not convert_tf_checkpoint_to_pytorch2019-07-24T07:35:32Z2019-07-24T08:12:30ZTrue
MDU6SXNzdWU0NzIxOTc3NTA=Upgrade to new FP162019-07-24T10:13:11Z2019-07-27T14:18:57ZTrue
MDU6SXNzdWU0NzIyMjQ5MzQ=Customized BertForTokenClassification Model2019-07-24T11:16:09Z2020-04-26T12:31:08ZTrue
MDU6SXNzdWU0NzIzMDcxMTc=Can lm_finetuning be used with non-english data ? 2019-07-24T14:11:50Z2019-07-25T12:36:37ZTrue
MDU6SXNzdWU0NzIzMjY0Njk=BERT uncased model outputs a tuple instead of a normal pytorch tensor 2019-07-24T14:46:30Z2019-07-24T14:53:46ZTrue
MDU6SXNzdWU0NzIzNjgwNzM=No gradient clipping in AdamW2019-07-24T16:03:40Z2019-10-11T11:44:10ZTrue
MDU6SXNzdWU0NzI0ODU1OTU=Increased number of hidden states returned from transformers in latest release2019-07-24T19:57:32Z2019-07-25T13:45:41ZTrue
MDU6SXNzdWU0NzI1MjI3NjM=PreTrainedTokenizer.from_pretrained should be more general2019-07-24T20:56:49Z2019-09-30T16:09:31ZTrue
MDU6SXNzdWU0NzI1OTQyNTY=BERT: run_squad.py falling over after eval2019-07-24T23:19:46Z2019-07-25T13:00:20ZTrue
MDU6SXNzdWU0NzI1OTQ0Njg=How to add new special token2019-07-24T23:20:38Z2019-07-27T01:18:00ZTrue
MDU6SXNzdWU0NzI2NDI4MjA=Sequence length more than 5122019-07-25T03:11:39Z2019-09-30T13:09:30ZTrue
MDU6SXNzdWU0NzI2OTkxNDA=fp16 is still has the problem2019-07-25T07:02:21Z2019-08-01T12:17:57ZTrue
MDU6SXNzdWU0NzI3NDg0MDE=SpanBERT support2019-07-25T09:02:22Z2019-11-18T09:20:06ZTrue
MDU6SXNzdWU0NzI3NjgwNjE=bug: it is broken to use tokenizer path2019-07-25T09:44:26Z2019-07-26T19:36:25ZTrue
MDU6SXNzdWU0NzI4MDQwMjg=Torchscript Trace slower with C++ runtime environment.2019-07-25T11:06:57Z2019-10-14T06:00:30ZTrue
MDU6SXNzdWU0NzI4MTc0NDk=why the acc of chinese model(bert) is just 0.4382019-07-25T11:40:18Z2019-10-24T06:42:25ZTrue
MDU6SXNzdWU0NzMwMzcwNzA=AssertionError while using DataParallelModel2019-07-25T19:40:06Z2019-10-11T16:44:10ZTrue
MDU6SXNzdWU0NzMyMzM2NzY=cuda out of memory2019-07-26T08:12:11Z2020-02-09T21:58:58ZTrue
MDU6SXNzdWU0NzM0NDI5MDA=Cannot inherit from BertPretrainedModel  anymore after migrating to pytorch-transformers2019-07-26T16:36:25Z2019-07-26T19:36:22ZTrue
MDU6SXNzdWU0NzM2MTIzMzY=adding vocabulary in OpenAI GPT2 tokenizer issue2019-07-27T07:57:04Z2019-07-30T00:07:26ZTrue
MDU6SXNzdWU0NzM2OTUxMTM=Best practices for combining large pretrained models with smaller models?2019-07-28T01:42:10Z2019-10-03T03:01:35ZTrue
MDU6SXNzdWU0NzM2OTU3MTg=Using new pretrained model with it's own vocab.txt file. 2019-07-28T01:53:51Z2019-11-08T08:30:31ZTrue
MDU6SXNzdWU0NzM3MjcwOTY=Wrong layer names for selecting parameters groups (run_openai_gpt.py)2019-07-28T10:01:17Z2019-10-04T01:04:32ZTrue
MDU6SXNzdWU0NzM3MzM4NDE=Avoid i/o in class __init__ methods2019-07-28T11:31:25Z2019-10-04T09:52:40ZTrue
MDU6SXNzdWU0NzM4NjM1ODg=XLNet: Sentence probability/perplexity2019-07-29T05:57:27Z2019-08-27T13:20:30ZTrue
MDU6SXNzdWU0NzQwOTM3MjI=Export to Tensorflow not properly implemented2019-07-29T14:46:13Z2019-08-05T10:55:30ZTrue
MDU6SXNzdWU0NzQyOTA0Mzg=Code snippet on docs page using old import2019-07-29T22:48:31Z2019-08-05T11:45:34ZTrue
MDU6SXNzdWU0NzQzNTAzODM=Unigram frequencies in GPT-2 or XLnet?2019-07-30T03:21:39Z2019-08-08T06:33:54ZTrue
MDU6SXNzdWU0NzQzODU0NTg=Issues in visualizing a fine tuned model2019-07-30T05:48:15Z2019-10-13T15:00:30ZTrue
MDU6SXNzdWU0NzQ0MjgzMzc=TypeError: 'NoneType' object is not callable2019-07-30T07:48:06Z2019-10-11T18:44:10ZTrue
MDU6SXNzdWU0NzQ1MjE4NTc=[RuntimeError: sizes must be non-negative] in run_squad.py using xlnet large model2019-07-30T11:09:44Z2019-08-05T12:39:03ZTrue
MDU6SXNzdWU0NzQ2MTk4MzM=Torchscipt mode for BertForPreTraining2019-07-30T14:29:39Z2019-08-01T13:48:44ZTrue
MDU6SXNzdWU0NzQ2OTA5NzY=Feature request: roBERTa2019-07-30T16:45:02Z2019-07-30T17:48:14ZTrue
MDU6SXNzdWU0NzQ4NzUyOTk=`do_wordpiece_only` argument2019-07-31T00:08:19Z2019-10-10T09:44:41ZTrue
MDU6SXNzdWU0NzQ5Mjg5MTA=ERNIE 2.0 ?2019-07-31T04:25:52Z2019-10-07T04:32:07ZTrue
MDU6SXNzdWU0NzUwNDE3NjY=AttributeError: 'NoneType' object has no attribute 'split'2019-07-31T09:42:09Z2019-08-05T12:44:00ZTrue
MDU6SXNzdWU0NzUzNzc3MjA=Updating run_swag script for new pytorch_transformers setup2019-07-31T22:03:44Z2019-10-11T13:44:11ZTrue
MDU6SXNzdWU0NzU0MTAwNzg="pip install error: ""regex_3/_regex.c:48:10: fatal error: Python.h: No such file or directory"""2019-08-01T00:09:39Z2019-08-01T00:43:59ZTrue
MDU6SXNzdWU0NzU0NDEwNTU=Feature Request : run_swag with XLNet and XLM 2019-08-01T02:42:08Z2019-08-05T12:47:07ZTrue
MDU6SXNzdWU0NzU0ODEyMzA=run_glue : Evaluating in every grad_accumulation_step if flag eval during training is true2019-08-01T05:35:10Z2019-08-01T05:44:07ZTrue
MDU6SXNzdWU0NzU0ODQ2OTM=XLNet large low accuracy2019-08-01T05:48:23Z2019-10-11T13:44:12ZTrue
MDU6SXNzdWU0NzU1MzgzODE=Wrong refactoring of mandatory parameters for run_squad.py2019-08-01T08:11:17Z2019-10-11T15:44:10ZTrue
MDU6SXNzdWU0NzU1NDk3Mzk=Performance dramatically drops down after replacing pytorch-pretrained-bert with pytorch-transformers2019-08-01T08:36:01Z2019-08-05T14:29:04ZTrue
MDU6SXNzdWU0NzU1NTEwODU=Chinese BERT broken2019-08-01T08:38:55Z2019-10-11T14:58:29ZTrue
MDU6SXNzdWU0NzU1NTM4MDE=Unexpectedly preprocess when multi-gpu using2019-08-01T08:44:49Z2020-01-11T07:47:05ZTrue
MDU6SXNzdWU0NzU1OTcyMjM=Using BERT for predicting masked token2019-08-01T10:16:20Z2019-10-12T07:44:10ZTrue
MDU6SXNzdWU0NzU2ODQ0NzE=Is pytorch-transformers useful for training from scratch on a custom dataset?2019-08-01T13:30:17Z2019-10-27T08:30:36ZTrue
MDU6SXNzdWU0NzU3NDQ5ODI=Missing lines in Readme examples?2019-08-01T15:21:50Z2019-08-05T15:17:15ZTrue
MDU6SXNzdWU0NzU4NDQ1OTM=_convert_id_to_tokens for XLNet not working2019-08-01T19:13:25Z2019-10-11T17:44:10ZTrue
MDU6SXNzdWU0NzU4NDc5OTQ=Using memory states with XLNet / TransfoXL2019-08-01T19:22:06Z2019-10-12T21:40:25ZTrue
MDU6SXNzdWU0NzYwMDEwNTY=[XLNet] Parameters to reproduce SQuAD scores2019-08-02T05:20:52Z2020-01-26T04:13:34ZTrue
MDU6SXNzdWU0NzYwMzYzNzY=How to train BertModel2019-08-02T07:23:21Z2019-08-05T16:19:44ZTrue
MDU6SXNzdWU0NzYxNzQwODU=<model>ForQuestionAnswering loading non-deterministic weights2019-08-02T13:15:04Z2019-08-05T15:24:57ZTrue
MDU6SXNzdWU0NzYxOTQzNTk=CONFIG_NAME and WEIGHTS_NAME are missing in modeling_transfo_xl.py2019-08-02T13:59:39Z2019-08-05T15:26:40ZTrue
MDU6SXNzdWU0NzYyNzg5NDg=How to add some parameters in gpt-2 (in attention layer) and initialize the original gpt-2 parameters with pre-trained model and the new introduced parameters randomly?2019-08-02T17:17:05Z2019-11-08T07:30:35ZTrue
MDU6SXNzdWU0NzY0MDk3MzI=Bert model instantiated from BertForMaskedLM.from_pretrained('bert-base-uncased') and BertForMaskedLM(BertConfig.from_pretrained('bert-base-uncased')) give different results 2019-08-03T03:11:00Z2019-10-12T04:44:10ZTrue
MDU6SXNzdWU0NzY0MzA4NDg=Tokenizer added special token attributes missing2019-08-03T08:47:04Z2019-08-16T06:45:36ZTrue
MDU6SXNzdWU0NzY0NzM1OTY=total training steps and tokenization in run_glue2019-08-03T17:41:25Z2019-08-08T00:29:31ZTrue
MDU6SXNzdWU0NzY1NTYzOTY=Use the fine-tuned model for another task2019-08-04T13:58:58Z2019-10-14T15:11:52ZTrue
MDU6SXNzdWU0NzY1NzQwNDY=Deep learning NLP models for children's story understanding?2019-08-04T17:11:22Z2019-12-08T17:54:42ZTrue
MDU6SXNzdWU0NzY2NDU0MDc=How to output a vector2019-08-05T04:00:22Z2019-08-08T08:01:47ZTrue
MDU6SXNzdWU0NzY3MTY5MzQ=AttributeError: module 'tensorflow.python.training.training' has no attribute 'list_variables'2019-08-05T08:12:07Z2019-10-11T09:44:11ZTrue
MDU6SXNzdWU0NzY3MzgyNzc= Unable to load weights properly from tf checkpoint2019-08-05T08:59:44Z2019-12-10T10:23:12ZTrue
MDU6SXNzdWU0NzY4ODg3NzI=Error when running run_squad.py in colab2019-08-05T14:23:42Z2019-10-11T15:44:11ZTrue
MDU6SXNzdWU0NzY5NDA4MjA=Finetune GPT2 2019-08-05T16:03:31Z2019-08-05T16:16:10ZTrue
MDU6SXNzdWU0NzY5NTA3NDY=How to use   GPT2LMHeadModel  for conditional generation2019-08-05T16:27:06Z2019-08-05T19:20:44ZTrue
MDU6SXNzdWU0NzY5ODQ1ODA=Brackets are not aligned in the DocString of Bert.2019-08-05T17:54:46Z2019-08-08T14:37:16ZTrue
MDU6SXNzdWU0NzcwMTU4OTg=XLNetForQuestionAnswering - weight pruning2019-08-05T19:16:51Z2019-10-30T01:12:55ZTrue
MDU6SXNzdWU0NzcyODUxMDM=Support longer sequences with BertForSequenceClassification2019-08-06T09:57:56Z2019-11-25T14:31:03ZTrue
MDU6SXNzdWU0NzcyOTE1NzY=Inconsistant output between pytorch-transformers and pytorch-pretrained-bert2019-08-06T10:11:20Z2019-10-12T22:40:24ZTrue
MDU6SXNzdWU0Nzc0MDQzMjc=Issue: Possibly wrong documentation about labels in BERT classifier2019-08-06T14:09:39Z2019-08-08T14:39:08ZTrue
MDU6SXNzdWU0Nzc1NTc1MDE=RuntimeError: bool value of Tensor with more than one value is ambiguous2019-08-06T19:34:53Z2019-08-06T20:53:35ZTrue
MDU6SXNzdWU0Nzc4MjMyMTM=The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False.2019-08-07T09:49:29Z2019-08-07T15:23:07ZTrue
MDU6SXNzdWU0Nzc4NjA4MDE=How to predict masked whole word which was tokenized as sub-words for bert-base-multilingual-cased2019-08-07T11:06:23Z2019-10-17T12:25:58ZTrue
MDU6SXNzdWU0Nzc4OTg4NjQ=Worse performance of gpt2 than gpt2019-08-07T12:29:32Z2020-01-20T19:33:19ZTrue
MDU6SXNzdWU0Nzc5NjU5OTI=Unable to read pre-trained model using BertModel.from_pretrained 2019-08-07T14:31:51Z2019-11-02T12:51:36ZTrue
MDU6SXNzdWU0Nzc5ODI1ODU=Potential bug with gradient clipping when using gradient accumulation in examples2019-08-07T14:59:58Z2019-12-09T17:47:56ZTrue
MDU6SXNzdWU0NzgzNDkzNTY=seq2seq model with transformer2019-08-08T09:20:43Z2019-10-21T07:16:34ZTrue
MDU6SXNzdWU0NzgzNTY4OTc="Using hidden states from BERT (Similar to using precomputed hidden states in GPT2 model ""past"" argument)"2019-08-08T09:35:04Z2019-10-25T13:58:36ZTrue
MDU6SXNzdWU0NzgzNzQxODY=bert-base-multilingual-uncased vocabulary not consecutive2019-08-08T10:08:18Z2019-10-26T10:07:29ZTrue
MDU6SXNzdWU0Nzg0MjkwMDk=Supress long sequence tokenization warning2019-08-08T12:05:12Z2019-08-12T13:35:14ZTrue
MDU6SXNzdWU0Nzg0NDQyNTQ=Any idea how to use pytorch-transformers for Entity Linking?2019-08-08T12:36:28Z2019-10-14T13:11:53ZTrue
MDU6SXNzdWU0Nzg1OTg0OTU=RuntimeError:  Invalid index in gather at ../aten/src/TH/generic/THTensorEvenMoreMath.cpp:469  (GPT2DoubleHeadsModel)2019-08-08T17:27:18Z2019-08-10T18:04:43ZTrue
MDU6SXNzdWU0Nzg2ODI0OTc=Pretrained GPT2 mdoels does not load unk special symbol2019-08-08T20:53:10Z2019-08-10T20:01:27ZTrue
MDU6SXNzdWU0Nzg4OTkwMTU=BERT with sequence pairs & padding2019-08-09T09:46:46Z2019-08-12T09:53:13ZTrue
MDU6SXNzdWU0NzkwNDA2MDE=Is XLA feature existed in current repo?2019-08-09T15:19:29Z2019-08-09T22:26:43ZTrue
MDU6SXNzdWU0NzkxMDQzODc=Running the pytorch.distributed.launch example of Glue hangs at evaluation2019-08-09T18:03:56Z2019-10-27T05:30:37ZTrue
MDU6SXNzdWU0NzkxNTE2NjE=Multi_Head Attention in BERT different from Transformer?2019-08-09T20:20:13Z2019-08-12T22:29:31ZTrue
MDU6SXNzdWU0NzkxNjkwNzM=Running on GPU?2019-08-09T21:12:58Z2019-08-09T21:53:46ZTrue
MDU6SXNzdWU0NzkyMzg0NjQ=How do a put a different classifier on top of BertForSequenceClassification?2019-08-10T07:19:49Z2019-08-17T10:58:19ZTrue
MDU6SXNzdWU0NzkyNjg1MDc=How to make a new line when using gpt2 to generate lyrics?2019-08-10T13:40:35Z2019-10-21T14:47:27ZTrue
MDU6SXNzdWU0NzkyNzEyNzk=Can't GPT-2 set special_tokens? (or unk tokens)2019-08-10T14:12:38Z2019-10-25T13:58:37ZTrue
MDU6SXNzdWU0NzkzNTg3MjY=Can't get attribute 'Corpus' on <module '__main__' from 'convert_transfo_xl_checkpoint_to_pytorch.py'>2019-08-11T11:15:20Z2019-08-14T07:52:48ZTrue
MDU6SXNzdWU0Nzk0MDE0Mzg=can somebody share an example of how to use GPT2 model for multiclass classification problem with fine tuning Language model ?2019-08-11T19:17:18Z2019-10-17T20:11:05ZTrue
MDU6SXNzdWU0Nzk0NTA4MDc=How can I use only one layer transformer via this repository?2019-08-12T03:06:25Z2019-08-14T04:05:08ZTrue
MDU6SXNzdWU0Nzk1MDgzMDU="GPT2 Sentence Probability: Necessary to Prepend ""<|endoftext|>""?"2019-08-12T07:46:31Z2019-08-15T10:01:39ZTrue
MDU6SXNzdWU0Nzk1ODAwOTk=Order of inputs of forward function problematic for jit with Classification models2019-08-12T10:48:10Z2019-09-26T15:41:02ZTrue
MDU6SXNzdWU0Nzk2MTQwMTM=run_classifier.py missing from examples dir2019-08-12T12:17:39Z2019-10-19T00:46:15ZTrue
MDU6SXNzdWU0Nzk2MzUyNzQ=inconsistency of the model (XLNet) output  / related to #475 #7352019-08-12T13:05:40Z2019-12-16T08:03:10ZTrue
MDU6SXNzdWU0Nzk3NzI2NjY=XLNet / sentence padding2019-08-12T17:53:43Z2019-10-27T02:07:31ZTrue
MDU6SXNzdWU0Nzk3OTk1NDY=BertTokenizer.save_vocabulary() doesn't work as docstring described2019-08-12T18:58:22Z2019-08-20T23:54:07ZTrue
MDU6SXNzdWU0Nzk4MDE0MjI=Logic issue with evaluating cased models in `run_squad.py`2019-08-12T19:02:47Z2019-08-20T23:20:48ZTrue
MDU6SXNzdWU0Nzk4MjExODI=inconsistent between class name (Pretrained vs PreTrained)2019-08-12T19:53:05Z2019-10-19T15:46:16ZTrue
MDU6SXNzdWU0Nzk4Mjk1ODU=the execution order of `scheduler.step()` and `optimizer.step()`2019-08-12T20:14:25Z2019-08-21T20:22:24ZTrue
MDU6SXNzdWU0Nzk4NzgxNjI=Fine-tuning approach for Bert and GPT2 classifiers2019-08-12T22:26:46Z2019-08-14T13:28:21ZTrue
MDU6SXNzdWU0Nzk5MjIyMDM=Intended Behaviour for Impossible (out-of-span) SQuAD Features2019-08-13T01:50:21Z2019-10-19T02:46:14ZTrue
MDU6SXNzdWU0Nzk5ODc2NTc=When I set fp16_opt_level == O2 or O3,  I can not use multiple GPU2019-08-13T06:49:51Z2019-10-25T14:58:35ZTrue
MDU6SXNzdWU0ODAwNDU3OTg="""mask_padding_with_zero"" for xlnet"2019-08-13T09:12:35Z2019-08-21T03:17:37ZTrue
MDU6SXNzdWU0ODA1MTM5NjI=fail to download vocabulary behind proxy server2019-08-14T07:01:15Z2019-08-15T02:24:40ZTrue
MDU6SXNzdWU0ODA1NTEyOTE=puzzling issue regarding evaluation phase2019-08-14T08:35:41Z2019-10-20T10:44:00ZTrue
MDU6SXNzdWU0ODA1NzQ4ODc=if cutoffs=[], convert_transfo_xl_checkpoint_to_pytorch.py has a bug2019-08-14T09:27:38Z2019-11-08T09:30:31ZTrue
MDU6SXNzdWU0ODA2MzE4MTI=Tokenizer not found after conversion from TF checkpoint to PyTorch2019-08-14T11:42:04Z2019-10-25T16:58:36ZTrue
MDU6SXNzdWU0ODA3ODMzMzU=Efficient data loading functionality2019-08-14T16:50:02Z2019-10-20T17:44:00ZTrue
MDU6SXNzdWU0ODA4Mjc0Njg=GPT2 Tokenizer got an expected argument `skip_special_tokens`2019-08-14T18:35:35Z2019-08-14T18:48:50ZTrue
MDU6SXNzdWU0ODA4MzI0MDY=GPT2 Tokenizer got an expected argument `skip_special_tokens`2019-08-14T18:46:54Z2019-08-16T21:26:55ZTrue
MDU6SXNzdWU0ODA4NzAwNzI=Getting embedding from XLM in differnet languages2019-08-14T20:20:55Z2019-08-20T23:54:07ZTrue
MDU6SXNzdWU0ODExMjk4NDA=Customize BertTokenizer and Feature Extraction from Bert Model2019-08-15T12:32:55Z2019-10-30T03:12:57ZTrue
MDU6SXNzdWU0ODEyNzMwODA=wrong generation of training sentence pairs. method: get_corpus_line, in finetune_on_pregenerated.py2019-08-15T18:17:38Z2019-10-26T13:07:35ZTrue
MDU6SXNzdWU0ODEzMzg3MzI=Adding new tokens to GPT tokenizer2019-08-15T21:05:05Z2019-08-15T21:40:03ZTrue
MDU6SXNzdWU0ODEzNzc3NzY=Minor bug in evaluation phase in example code for SQUAD2019-08-15T23:21:01Z2019-08-16T16:28:07ZTrue
MDU6SXNzdWU0ODE2MzY1NTg=Issue in running run_glue.py in Roberta, XLNet, XLM in latest release2019-08-16T14:28:22Z2019-08-16T15:53:30ZTrue
MDU6SXNzdWU0ODE3MTg1Nzc=Unable to load custom tokens2019-08-16T17:53:55Z2019-08-16T18:37:00ZTrue
MDU6SXNzdWU0ODE4ODM1ODI=mnli results for BERT2019-08-17T13:02:20Z2019-10-23T14:09:33ZTrue
MDU6SXNzdWU0ODE5NDY2OTM=Issue using Roberta2019-08-18T02:49:57Z2019-08-19T13:12:26ZTrue
MDU6SXNzdWU0ODE5NzU3MTk=Very bad performances with BertModel on sentence classification2019-08-18T10:00:15Z2019-08-20T20:34:59ZTrue
MDU6SXNzdWU0ODE5OTIxMTM=BUG: run_openai_gpt.py bug of GPTTokenizer and GPTDoubleHeadsModel2019-08-18T13:08:40Z2019-08-21T07:14:50ZTrue
MDU6SXNzdWU0ODE5OTM5MjI=Error in converting tensorflow checkpoints to pytorch 2019-08-18T13:27:47Z2019-10-25T11:58:38ZTrue
MDU6SXNzdWU0ODIwNjgwNzU=BUG: run_openai_gpt.py load ROCStories data error2019-08-19T01:44:55Z2019-08-21T07:17:29ZTrue
MDU6SXNzdWU0ODIyODM1ODQ=reproducing bert results on snli and mnli 2019-08-19T12:29:22Z2019-10-25T13:58:35ZTrue
MDU6SXNzdWU0ODI0ODM0MTg=simple example of BERT input features : position_ids and head_mask 2019-08-19T19:21:28Z2019-08-20T11:01:17ZTrue
MDU6SXNzdWU0ODI3NjM3NTU=Initialising XLMTokenizer 2019-08-20T09:59:41Z2019-10-26T11:07:29ZTrue
MDU6SXNzdWU0ODI5NTU0NTk=GPT2 774M weights released!2019-08-20T16:13:29Z2019-08-22T17:11:36ZTrue
MDU6SXNzdWU0ODMwODQ4Nzk=Example in OpenAIGPTDoubleHeadsModel can't run2019-08-20T21:10:51Z2019-08-21T00:08:50ZTrue
MDU6SXNzdWU0ODMxMTMwNDM=Can't load the RobertaTokenizer from AutoTokenizer.from_pretrained interface2019-08-20T22:30:47Z2019-08-21T00:17:50ZTrue
MDU6SXNzdWU0ODMxNDc2NzE=Has anyone reproduced RoBERTa scores on Squad dataset?2019-08-21T00:56:55Z2019-11-23T03:55:02ZTrue
MDU6SXNzdWU0ODMxODgzMTk=`run_squad.py` not using the dev cache2019-08-21T04:07:17Z2019-10-27T05:30:38ZTrue
MDU6SXNzdWU0ODMzMDc2MDA=LM fine-tuning for non-english dataset (hindi)2019-08-21T09:32:06Z2019-10-28T11:22:58ZTrue
MDU6SXNzdWU0ODMzMjUwMzI=ru language2019-08-21T10:03:14Z2019-10-02T11:05:53ZTrue
MDU6SXNzdWU0ODM0MzI0NjQ=Support for Tensorflow (& or Keras)2019-08-21T13:47:35Z2019-11-11T06:24:30ZTrue
MDU6SXNzdWU0ODM1NDk2Mjk=Missing tf variables in convert_pytorch_checkpoint_to_tf.py2019-08-21T17:23:19Z2019-08-22T20:05:11ZTrue
MDU6SXNzdWU0ODM1NzI1OTk=Unable to get hidden states and attentions BertForSequenceClassification 2019-08-21T18:09:22Z2019-08-29T00:05:25ZTrue
MDU6SXNzdWU0ODM3MjI4NTM=can this project select the specific version of BERT?2019-08-22T01:29:33Z2019-08-22T01:45:54ZTrue
MDU6SXNzdWU0ODM3NDY2ODA=Index misplacement of Vocab.txt BUG BUG BUG2019-08-22T03:14:15Z2019-08-22T08:40:02ZTrue
MDU6SXNzdWU0ODM3ODE5NDU=Getting tokenization ERROR while running run_generation.py 2019-08-22T05:44:55Z2019-10-28T20:22:58ZTrue
MDU6SXNzdWU0ODM5MzIxNDc=hwo to get RoBERTaTokenizer  vocab.json and also merge file2019-08-22T11:16:10Z2019-10-29T17:20:31ZTrue
MDU6SXNzdWU0ODM5NTk3NzM=Xlnet for multi-label classification2019-08-22T12:18:30Z2019-10-29T01:22:58ZTrue
MDU6SXNzdWU0ODM5ODM0Mzk=RuntimeError: Creating MTGP constants failed. at /opt/conda/conda-bld/pytorch_1533739672741/work/aten/src/THC/THCTensorRandom.cu:342019-08-22T13:06:15Z2019-10-28T21:22:57ZTrue
MDU6SXNzdWU0ODQwNjg2MjY=ProjectedAdaptiveLogSoftmax log_prob computation dimensions error2019-08-22T15:39:22Z2019-10-28T16:23:05ZTrue
MDU6SXNzdWU0ODQyOTExODM=❓ Why in `run_squad.py` using XLNet, CLS token is not set at the end ?2019-08-23T01:53:29Z2019-10-29T12:20:31ZTrue
MDU6SXNzdWU0ODQ1MzMwNzM=No such file or directory: '..\\VERSION'2019-08-23T13:32:42Z2020-01-02T07:31:21ZTrue
MDU6SXNzdWU0ODQ2NjcwNjM=Problem with mask token id in RoBERTa vocab2019-08-23T18:54:38Z2019-11-02T13:51:36ZTrue
MDU6SXNzdWU0ODQ3OTkwNzU=fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN2at7getTypeERKNS_6TensorE2019-08-24T09:36:18Z2019-08-27T10:29:51ZTrue
MDU6SXNzdWU0ODQ4NTQ0MTY=Performing MRPC task after Fine Tuning2019-08-24T19:25:53Z2019-08-26T11:22:56ZTrue
MDU6SXNzdWU0ODQ4ODQ2NjI=some words not in xlnet vocabulary ,especially name 2019-08-25T03:10:49Z2019-09-05T04:24:11ZTrue
MDU6SXNzdWU0ODQ5NjA5NjU=modifying config2019-08-25T18:26:51Z2019-11-01T22:30:03ZTrue
MDU6SXNzdWU0ODQ5ODUyMjg=Support multiprocessing when loading pretrained weights2019-08-25T22:46:37Z2019-11-03T01:03:29ZTrue
MDU6SXNzdWU0ODUwMDIyOTg=Missing RobertaForMultipleChoice2019-08-26T01:26:10Z2019-11-01T11:30:01ZTrue
MDU6SXNzdWU0ODUwMDYwMDk=Writing predictions in a separate output file2019-08-26T01:50:17Z2019-08-29T07:39:35ZTrue
MDU6SXNzdWU0ODUxNTAwOTU=evaluate bert on Senteval dataset2019-08-26T09:51:09Z2019-11-01T12:30:01ZTrue
MDU6SXNzdWU0ODUxNzY3NTY=Wrong documentation example for RoBERTa2019-08-26T10:59:20Z2019-08-26T22:13:12ZTrue
MDU6SXNzdWU0ODUxODM5ODQ=Roberta semantic similarity2019-08-26T11:19:29Z2019-09-17T07:35:03ZTrue
MDU6SXNzdWU0ODUyMTE2MzM=How to get pooler state's (corresponds to CLS token) attention vector?2019-08-26T12:30:41Z2019-08-29T13:32:25ZTrue
MDU6SXNzdWU0ODUzMzI1ODE=sample_text.txt is broken (404 ERROR)2019-08-26T16:49:01Z2019-08-27T12:50:29ZTrue
MDU6SXNzdWU0ODUzNzIxODk=Changing the _read_tsv method in class DataProcessor2019-08-26T18:19:39Z2019-11-08T00:52:10ZTrue
MDU6SXNzdWU0ODUzNzg2MzI=using BERT as pretraining with custom classifier2019-08-26T18:33:26Z2019-11-02T00:51:36ZTrue
MDU6SXNzdWU0ODUzODY2ODQ=keeping encoder fixed from pretrained model but changing classifier2019-08-26T18:50:00Z2019-08-26T22:47:31ZTrue
MDU6SXNzdWU0ODU0OTIxNTg=Can we get a 1.1.1 release so that AutoRoberta is included?2019-08-26T22:52:25Z2019-11-02T13:51:38ZTrue
MDU6SXNzdWU0ODU1NjMyNTI=Implement the QuickStart but got an error when  using BertForMaskedLM to predict a masked token2019-08-27T03:33:10Z2019-08-27T04:27:27ZTrue
MDU6SXNzdWU0ODU1NjY1MDA=[Help] How to do mean/max pooling to get sentence embedding?2019-08-27T03:46:58Z2019-08-27T04:48:47ZTrue
MDU6SXNzdWU0ODU2NDU3MDk=Does RoBERTa needs input_type_ids as Bert ?2019-08-27T07:52:14Z2019-08-27T08:10:17ZTrue
MDU6SXNzdWU0ODU2ODEyMDg=No parameter which is presented in documentation2019-08-27T09:03:33Z2019-08-27T12:56:46ZTrue
MDU6SXNzdWU0ODU2OTAwNzk=Wrong parameter name in documentation2019-08-27T09:20:09Z2019-08-27T12:58:52ZTrue
MDU6SXNzdWU0ODU3NDU0ODA=Tons of warnings on use of TransfoXLModel. masked_fill_ input dtype torch.uint8 should be changed to torch.bool2019-08-27T11:11:29Z2019-08-27T13:01:02ZTrue
MDU6SXNzdWU0ODU4MDgyOTM=Using pretrained XLNET for long sentences2019-08-27T13:23:54Z2019-11-02T14:51:36ZTrue
MDU6SXNzdWU0ODU4NjQ0NDY=PyTorch library dependency2019-08-27T14:59:49Z2019-11-27T22:18:52ZTrue
MDU6SXNzdWU0ODU4NzY2MTc=Extracting Features Example2019-08-27T15:21:11Z2019-12-12T11:48:51ZTrue
MDU6SXNzdWU0ODU5NzU1NzE=XLNet resize embedding size ERROR2019-08-27T18:52:10Z2019-09-02T21:14:56ZTrue
MDU6SXNzdWU0ODYwMjE2NDg=UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 1176: character maps to <undefined>2019-08-27T20:37:09Z2019-09-01T23:18:49ZTrue
MDU6SXNzdWU0ODYxMjAwNTQ=Bert initialization2019-08-28T02:01:59Z2019-09-02T06:53:22ZTrue
MDU6SXNzdWU0ODYyMzExNzM=cannot import name 'RobertaConfig2019-08-28T08:26:49Z2019-08-28T08:31:54ZTrue
MDU6SXNzdWU0ODYyNTY5NjQ=Fine-tuning (BERT & RoBERTa) base outperforms large2019-08-28T09:18:14Z2019-11-09T16:40:24ZTrue
MDU6SXNzdWU0ODYyNjA1MDM=Output of BertModel does not match fixed feature vectors extracted from the last hidden layer  2019-08-28T09:25:08Z2019-11-17T01:03:10ZTrue
MDU6SXNzdWU0ODYyNjI1ODA=mems output in XLNet2019-08-28T09:29:10Z2019-08-28T20:41:48ZTrue
MDU6SXNzdWU0ODYyODIxMzI=How to split consecutive numbers?2019-08-28T10:07:06Z2019-10-28T02:04:23ZTrue
MDU6SXNzdWU0ODYzNzgxOTc=GPT2 Tokenizer decoding fails when the added tokens include a space2019-08-28T13:19:20Z2019-09-02T07:01:32ZTrue
MDU6SXNzdWU0ODY0NjM4NzE=Schedulers cause memory accumulation across folds in cross-validation?2019-08-28T15:45:53Z2019-12-04T11:56:55ZTrue
MDU6SXNzdWU0ODY1NDYzNjA=Cannot import DistilBert classes2019-08-28T18:41:09Z2019-08-28T18:50:09ZTrue
MDU6SXNzdWU0ODY3MzQ1MjE=loss explosion2019-08-29T04:45:34Z2019-08-29T06:25:11ZTrue
MDU6SXNzdWU0ODY3ODM1MjU=Can't Using Binarization Script for DistilBERT2019-08-29T07:20:18Z2019-08-30T16:05:24ZTrue
MDU6SXNzdWU0ODY4NjI0Mzg=FP16_Optimizer is not an Optimizer when fp_162019-08-29T10:03:42Z2019-09-02T07:01:50ZTrue
MDU6SXNzdWU0ODY4ODIwNzU=Why still using old implementation of apex fp162019-08-29T10:44:12Z2019-08-30T21:29:18ZTrue
MDU6SXNzdWU0ODY4ODI1MzI=where can i assign step in function lr_lambda of Class WramupLinearSchedule?2019-08-29T10:45:10Z2019-11-04T19:54:44ZTrue
MDU6SXNzdWU0ODY5Mjk5MTk=How to finetune GPT22019-08-29T12:32:40Z2019-11-16T20:03:11ZTrue
MDU6SXNzdWU0ODY5NjU2MTQ=Attention values occasionally exceed 1 in BertModel2019-08-29T13:40:30Z2020-01-10T17:39:32ZTrue
MDU6SXNzdWU0ODcwMzExODM=GPT2-large fails to load the tokenizer2019-08-29T15:31:08Z2019-08-29T20:43:35ZTrue
MDU6SXNzdWU0ODcwNTg5NjA=Closing bracket is missing in token_counts.py for DistilBERT2019-08-29T16:23:57Z2019-08-29T19:31:42ZTrue
MDU6SXNzdWU0ODcxMDU2Mjk=What is the relationship between `run_lm_finetuning.py` and the scripts in `lm_finetuning`?2019-08-29T18:15:45Z2019-12-30T15:04:14ZTrue
MDU6SXNzdWU0ODcxNTc1Mjc=Idea to improve DistilBERT2019-08-29T20:20:22Z2019-12-27T02:31:43ZTrue
MDU6SXNzdWU0ODczODIxMjM=About distilled the SQuAD?2019-08-30T09:24:11Z2019-11-05T10:59:58ZTrue
MDU6SXNzdWU0ODc0OTE2MDI=How to load pretraind XLM model2019-08-30T13:43:59Z2019-08-31T19:46:09ZTrue
MDU6SXNzdWU0ODc1MzAyMDg=Problem with optimizers after migration2019-08-30T14:59:43Z2019-11-08T00:52:11ZTrue
MDU6SXNzdWU0ODc1ODY0MjI=--seed does not change the fintuning results of the xlnet model2019-08-30T17:09:28Z2019-09-03T08:00:14ZTrue
MDU6SXNzdWU0ODc1OTE2MDc=Large Memory Layers2019-08-30T17:23:07Z2019-11-05T18:59:59ZTrue
MDU6SXNzdWU0ODc3NDM3Mzg=[Help] how to make a constrained text generation2019-08-31T08:02:09Z2019-11-08T00:52:12ZTrue
MDU6SXNzdWU0ODc3NTU4ODQ=Dependency errors when trying to use gpt2 using pytorch hub.2019-08-31T10:28:14Z2019-09-06T20:40:12ZTrue
MDU6SXNzdWU0ODc3OTYxMzQ=Roberta for NER task2019-08-31T18:02:17Z2019-12-23T15:13:25ZTrue
MDU6SXNzdWU0ODc3OTk5Mjg=ImportError: cannot import name 'DistilBertModel'2019-08-31T18:43:53Z2019-09-05T14:51:18ZTrue
MDU6SXNzdWU0ODc4MDcwNDk=How to add new pre-trained model pytorch-transformers2019-08-31T20:09:23Z2019-11-06T22:13:03ZTrue
MDU6SXNzdWU0ODc4MDkyMTA=Attribute errors with pytorch_transformers tests2019-08-31T20:35:49Z2019-12-04T12:36:56ZTrue
MDU6SXNzdWU0ODc4MjA3MTY=How to use BERT or word embedding for e-commerce product classification. 2019-08-31T23:23:18Z2019-12-08T10:38:10ZTrue
MDU6SXNzdWU0ODc4NDk5NjE=Can't get GPT2tokenizer to load correctly2019-09-01T07:01:02Z2019-09-01T22:32:17ZTrue
MDU6SXNzdWU0ODc4NzYxNDg=apex fp16 FusedLayerNorm type issues2019-09-01T11:45:28Z2019-09-02T00:36:27ZTrue
MDU6SXNzdWU0ODc4OTIzNTA=Write with Transformer doesn't show 774M model?2019-09-01T14:26:48Z2019-09-01T14:35:22ZTrue
MDU6SXNzdWU0ODc5NzQ2NzI=May I get the details of Bert pre-train procedure?2019-09-02T03:17:59Z2019-09-02T07:31:46ZTrue
MDU6SXNzdWU0ODgxMTQyOTg=How to install previous versions of pytorch-transformers 2019-09-02T10:16:43Z2019-11-08T22:30:30ZTrue
MDU6SXNzdWU0ODgxOTg1MDk=DistilBERT training is killed because OOM2019-09-02T13:45:52Z2019-10-11T13:07:16ZTrue
MDU6SXNzdWU0ODgyMTYxOTc=DistilBERT baseline2019-09-02T14:25:41Z2019-09-03T23:48:21ZTrue
MDU6SXNzdWU0ODgyMjc1OTA=DistilBERT Loss Function Choice and further query on extending to GPT2.2019-09-02T14:52:11Z2019-09-10T15:41:08ZTrue
MDU6SXNzdWU0ODg0MTMxMTg='DistilBertModel' object has no attribute 'init_weights'2019-09-03T06:20:34Z2019-09-09T01:33:40ZTrue
MDU6SXNzdWU0ODg0MjI4Mzc=Convert RoBERTa to TF checkpoint2019-09-03T06:50:00Z2019-11-10T00:40:23ZTrue
MDU6SXNzdWU0ODg1NTA2MzY=XLnet output attentions doesn't work2019-09-03T11:32:20Z2019-09-03T12:46:48ZTrue
MDU6SXNzdWU0ODg2NjkyNTY=Using do_eval from run_glue.py uses the cached result2019-09-03T15:18:52Z2019-11-12T21:56:12ZTrue
MDU6SXNzdWU0ODg4NzUwNDg=BertEncoder head_mask not subscript-able error when not passed2019-09-03T23:56:41Z2019-12-19T18:07:35ZTrue
MDU6SXNzdWU0ODg4ODcwMzE=Roberta tokenizer fails on certain unicode characters2019-09-04T00:53:45Z2019-09-05T23:55:54ZTrue
MDU6SXNzdWU0ODg5ODQ3OTM=how to use 'spiece.model' to create the xlnet_tokenizer2019-09-04T07:15:54Z2019-11-15T08:03:33ZTrue
MDU6SXNzdWU0ODkwNDc1MTU=Finetuning BertModel to extract textual features for VQA shows bad results2019-09-04T09:30:37Z2019-09-05T14:40:45ZTrue
MDU6SXNzdWU0ODkwNTUyMTY=how to get distilbert-base-uncased-distilled-squad?2019-09-04T09:45:42Z2019-11-30T21:12:11ZTrue
MDU6SXNzdWU0ODkwODIzODA=How to finetune DistilBERT on custom data?2019-09-04T10:43:04Z2019-11-11T16:31:10ZTrue
MDU6SXNzdWU0ODkxMzc4NDk=RoBERTa/GPT2 tokenization2019-09-04T12:44:52Z2019-09-26T10:11:05ZTrue
MDU6SXNzdWU0ODkzNTY2Njc=How to fine-tune xlnet on SQuAD with the parameter setting provided in the paper?2019-09-04T19:38:25Z2019-12-03T16:56:12ZTrue
MDU6SXNzdWU0ODk0MzAxMDI=Distributed device ordinal question2019-09-04T22:21:59Z2019-11-10T23:24:33ZTrue
MDU6SXNzdWU0ODk1NTczMjY=Learning word-pieces garble the predictions2019-09-05T06:40:10Z2019-11-11T08:31:12ZTrue
MDU6SXNzdWU0ODk2MzI4Mjg=Can't trace any model with pytorch-transformers 1.22019-09-05T09:21:19Z2019-11-11T11:09:54ZTrue
MDU6SXNzdWU0ODk2NzIyMjg=the best way to cut the upper layers2019-09-05T10:40:45Z2019-10-11T17:15:04ZTrue
MDU6SXNzdWU0ODk3NDI2MjM=convert_roberta_checkpoint_to_pytorch.py 514 max position?2019-09-05T13:13:03Z2019-11-11T14:31:10ZTrue
MDU6SXNzdWU0ODk4MTY5OTE=How to set the token_type_ids in XLNet correctly?2019-09-05T14:52:03Z2019-09-09T07:22:22ZTrue
MDU6SXNzdWU0OTAwOTMzMDI=run_squad.py predictions2019-09-06T02:16:05Z2019-11-12T05:31:10ZTrue
MDU6SXNzdWU0OTAxNTUwOTY=Finetuning distilbert-base-uncased2019-09-06T06:31:40Z2019-12-06T09:51:51ZTrue
MDU6SXNzdWU0OTAxOTExNzU=How to fine tune small dataset?2019-09-06T08:12:17Z2019-11-16T02:53:18ZTrue
MDU6SXNzdWU0OTAyMzIwMjI=LSTM returns nan after using the pretrained BERT embedding as input 2019-09-06T09:41:04Z2019-09-06T14:39:49ZTrue
MDU6SXNzdWU0OTAyNjU5NDU=Fine-tuned RoBERTa models on CPU2019-09-06T11:00:35Z2019-11-12T12:56:13ZTrue
MDU6SXNzdWU0OTA0MjA4MDM=Cut off sequences of length greater than max_length= 512 for roberta2019-09-06T16:41:04Z2019-11-13T00:56:13ZTrue
MDU6SXNzdWU0OTA0NjgxMzE=Is there any sample code for fine-tuning BERT on sequence labeling tasks, e.g., NER on CoNLL-2003?2019-09-06T18:38:07Z2019-12-28T12:42:13ZTrue
MDU6SXNzdWU0OTA1NjQ5Nzg=How to set the weight decay in other layers after BERT output?2019-09-07T00:04:41Z2019-11-16T16:53:18ZTrue
MDU6SXNzdWU0OTA2NjgwMTA=RuntimeError: Gather got an input of invalid size: got [2, 3, 12, 256, 64], but expected [2, 4, 12, 256, 64] (gather at /opt/conda/conda-bld/pytorch_1544199946412/work/torch/csrc/cuda/comm.cpp:227)2019-09-07T18:48:26Z2020-04-25T19:15:59ZTrue
MDU6SXNzdWU0OTA2OTE4NTg=Hi there, is bert-large-uncased-whole-word-masking-finetuned-squad trained for Squad 1.0 or 2.0?2019-09-07T23:47:24Z2019-11-14T17:29:19ZTrue
MDU6SXNzdWU0OTA3MTEzNTA=Citing DistilBERT2019-09-08T05:07:49Z2019-09-09T17:50:19ZTrue
MDU6SXNzdWU0OTA3MTU4Mzc=[RuntimeError: sizes must be non-negative]  : XLnet, Large and Base2019-09-08T06:16:46Z2019-09-17T08:25:16ZTrue
MDU6SXNzdWU0OTA3ODA4MjE=Remove duplicate hidden_states of the last layer in BertEncoder in modeling_bert.py2019-09-08T17:32:34Z2019-11-15T07:03:33ZTrue
MDU6SXNzdWU0OTA4MTA3NzM=Bert output last hidden state2019-09-08T21:51:29Z2019-11-16T15:53:18ZTrue
MDU6SXNzdWU0OTA4MzY0MzY=Question on the position embedding of DistilBERT2019-09-09T01:24:12Z2019-09-09T19:31:30ZTrue
MDU6SXNzdWU0OTEwMjg4Nzc=class DistilBertForMultiLabelSequenceClassification()2019-09-09T11:04:40Z2019-11-15T12:03:33ZTrue
MDU6SXNzdWU0OTExODc0NTI=How to deal with oov tokens with pretrained models2019-09-09T16:03:44Z2019-09-10T17:04:07ZTrue
MDU6SXNzdWU0OTEyNjUwMjg=Unable to load DistilBertModel after training2019-09-09T18:51:26Z2019-09-09T20:40:43ZTrue
MDU6SXNzdWU0OTEzMzAwMzE=Can't reproduce XNLI zero-shot results from MBERT in Chinese2019-09-09T21:13:54Z2019-09-10T04:18:17ZTrue
MDU6SXNzdWU0OTE0MDk4NTY=❓ How to finetune `token_type_ids` of RoBERTa ?2019-09-10T02:05:18Z2020-01-03T01:22:12ZTrue
MDU6SXNzdWU0OTE0NDE2NjE=Quick questions about details2019-09-10T04:21:50Z2019-11-16T04:53:18ZTrue
MDU6SXNzdWU0OTE0Nzg3NDQ=Roberta for squad2019-09-10T06:35:53Z2019-11-16T06:53:19ZTrue
MDU6SXNzdWU0OTE1ODEzNjc=Issue in fine-tuning distilbert on Squad 1.02019-09-10T10:16:31Z2019-12-23T21:18:27ZTrue
MDU6SXNzdWU0OTE2MzI2ODA=how to finetuning with roberta-large2019-09-10T12:10:08Z2019-09-10T14:14:09ZTrue
MDU6SXNzdWU0OTE3NTU4MTQ=ModuleNotFoundError in distillation/scripts/binarized_data.py2019-09-10T15:45:49Z2019-09-11T14:21:49ZTrue
MDU6SXNzdWU0OTE3ODM3NTI=Special tokens / XLNet2019-09-10T16:41:32Z2019-11-25T11:31:03ZTrue
MDU6SXNzdWU0OTE4MDczODc=Can pytorch-transformers be used to get XLM sentence embeddings for multiple languages?2019-09-10T17:36:29Z2019-11-16T20:03:10ZTrue
MDU6SXNzdWU0OTE4MTU2MzE=unconditional generation with run_generation.py2019-09-10T17:55:56Z2019-11-17T21:20:07ZTrue
MDU6SXNzdWU0OTE4MjY2NzI=Different performance between pip install vs. download zip code2019-09-10T18:21:52Z2019-09-11T18:07:36ZTrue
MDU6SXNzdWU0OTE4MzY2NTQ=breaking change2019-09-10T18:44:41Z2019-11-24T08:27:55ZTrue
MDU6SXNzdWU0OTE5Njk1Mzg=KnowBert2019-09-11T01:23:01Z2020-01-26T00:43:39ZTrue
MDU6SXNzdWU0OTIwNjAzNjY=model_type for gpt2019-09-11T07:16:52Z2019-11-17T16:03:09ZTrue
MDU6SXNzdWU0OTIwODI0NDg=R-BERT implementation2019-09-11T08:09:31Z2019-11-24T08:27:52ZTrue
MDU6SXNzdWU0OTIyNzg3NDQ=Why you need DistilBertModel class?2019-09-11T14:35:28Z2019-09-17T19:00:26ZTrue
MDU6SXNzdWU0OTI1NTg5NDQ=Running XLNet on Squad2019-09-12T03:01:41Z2019-11-24T15:27:52ZTrue
MDU6SXNzdWU0OTI4MDExMDA=Write With Transformer adding spaces?2019-09-12T13:19:04Z2019-11-25T13:31:04ZTrue
MDU6SXNzdWU0OTI4MDMxNTA=examples/lm_finetuning/simple_lm_finetuning.py crashes with cublas runtime error2019-09-12T13:22:43Z2019-09-18T11:11:50ZTrue
MDU6SXNzdWU0OTI4NTA1ODQ=Could you please implement a Adafactor optimizer? :)2019-09-12T14:41:24Z2019-11-24T08:27:53ZTrue
MDU6SXNzdWU0OTI5MDM0NjU=Training time increased from 45 min per epoch to 6 hours per epoch in colab 2019-09-12T16:14:34Z2019-11-19T11:26:23ZTrue
MDU6SXNzdWU0OTMwNTk0MDU=Cannot install the library 2019-09-12T22:32:17Z2019-11-19T00:26:23ZTrue
MDU6SXNzdWU0OTMzMzIzMjE=XLNet tokenizer returns empty list instead of string for some indexes2019-09-13T13:41:29Z2019-10-01T23:09:18ZTrue
MDU6SXNzdWU0OTMzMzIzMzg=SequenceSummary / quenstion regarding summary types2019-09-13T13:41:31Z2019-11-24T14:27:53ZTrue
MDU6SXNzdWU0OTMzODU1Nzc=run_generation.py  'encode' error for gpt2 and xlnet2019-09-13T15:24:33Z2019-09-15T15:40:50ZTrue
MDU6SXNzdWU0OTM1NTIyMjI=Offsets in original text from tokenizers2019-09-13T23:29:36Z2019-11-24T08:27:54ZTrue
MDU6SXNzdWU0OTM2MzcxNDk=Error running openai-gpt on ROCstories2019-09-14T15:51:23Z2019-09-18T08:07:56ZTrue
MDU6SXNzdWU0OTM3MDQ5MTI=different results shown each time when I run the example code for BertForMultipleChoice2019-09-15T07:20:06Z2019-11-24T09:27:52ZTrue
MDU6SXNzdWU0OTM3NDExODQ=Fine-tune distilbert-base-uncased under run_glue2019-09-15T14:04:06Z2019-09-27T21:49:09ZTrue
MDU6SXNzdWU0OTM3NDI2ODk=Accuracy not increasing with BERT Large model2019-09-15T14:17:07Z2019-12-19T18:07:36ZTrue
MDU6SXNzdWU0OTM3NjU2ODc=How to use pytorch-transformers for transfer learning?2019-09-15T17:42:59Z2019-11-22T17:36:53ZTrue
MDU6SXNzdWU0OTM4MTYzNDE=could you add an option to transfer variables from float32 to float16 in GPT2 model to reduce model size and accelerate the inference speed 2019-09-16T01:56:39Z2019-11-24T09:27:53ZTrue
MDU6SXNzdWU0OTM5OTMzMTg=BERT returns different embedding for same sentence2019-09-16T11:31:00Z2019-09-19T14:20:50ZTrue
MDU6SXNzdWU0OTQxOTQ2MTU=get NaN loss when I run the example code run_squad.py2019-09-16T18:00:39Z2019-09-18T12:23:12ZTrue
MDU6SXNzdWU0OTQyNzkwODQ=How long does it take? (BERT Model Finetuning using Masked ML objective)2019-09-16T21:10:39Z2019-11-22T22:36:53ZTrue
MDU6SXNzdWU0OTQ0MDk3MTA=ModuleNotFoundError: No module named 'pytorch_transformers.modeling' using convert_pytorch_checkpoint_to_tf.py2019-09-17T05:32:40Z2019-11-23T05:55:02ZTrue
MDU6SXNzdWU0OTQ4NDgxMDQ=Write with Transformer: Please, add an autosave to browser cache!2019-09-17T20:56:43Z2019-11-25T13:31:03ZTrue
MDU6SXNzdWU0OTQ4ODk1NjI=No language embedding weights in pre-trained xlm models. 2019-09-17T22:40:23Z2019-09-20T19:50:55ZTrue
MDU6SXNzdWU0OTQ5NDEyOTg='Default process group is not initialized' Error2019-09-18T01:50:39Z2019-11-24T14:27:52ZTrue
MDU6SXNzdWU0OTQ5NjI4Njk=connection limit of pregenerate_training_data.py2019-09-18T03:16:47Z2019-11-24T04:27:52ZTrue
MDU6SXNzdWU0OTQ5ODQ2MzY=FineTuning using single sentence document2019-09-18T04:40:48Z2020-01-02T19:22:12ZTrue
MDU6SXNzdWU0OTUwODI3MTg=start_position=0 in utils_squad.py when span is impossible2019-09-18T08:53:09Z2019-09-18T09:11:02ZTrue
MDU6SXNzdWU0OTUwODk3Nzg=Is training from scratch possible now?2019-09-18T09:04:55Z2019-11-28T10:13:25ZTrue
MDU6SXNzdWU0OTUzMDc3ODA=GPT2 Tokenizer Decoding Adding Space2019-09-18T15:42:20Z2019-09-26T10:11:05ZTrue
MDU6SXNzdWU0OTUzMzc5NTc=Evaluation result.txt path suggestion2019-09-18T16:41:42Z2019-12-09T07:48:00ZTrue
MDU6SXNzdWU0OTU0MzUyOTE=TransfoXLLMHeadModel compatibility with pytorch 1.1.02019-09-18T20:20:54Z2019-10-01T22:42:50ZTrue
MDU6SXNzdWU0OTU0Nzc0NzI=MemoryError on run_lm_finetuning.py2019-09-18T22:05:45Z2019-11-24T22:27:52ZTrue
MDU6SXNzdWU0OTU1MjMwNzQ=traced_model 2019-09-19T01:12:59Z2019-12-06T14:13:01ZTrue
MDU6SXNzdWU0OTU1ODk5Nzk=Fine Tuning GPT2 on wikitext-103-raw2019-09-19T06:00:03Z2020-01-22T11:49:01ZTrue
MDU6SXNzdWU0OTU2MDY2MjE=cannot import name 'XLNetForMultipleChoice' but python can import2019-09-19T06:48:40Z2019-09-30T13:51:31ZTrue
MDU6SXNzdWU0OTU3NzgyNTM=Where are BERT's pretrained Embeddings loaded?2019-09-19T12:48:50Z2019-09-20T11:44:10ZTrue
MDU6SXNzdWU0OTYxMTU3Nzg=What is the best CPU inference acceleration solution for BERT now?2019-09-20T02:50:55Z2019-11-20T01:42:25ZTrue
MDU6SXNzdWU0OTYyMDM5OTU=❓ Why the criterion of XLNet LMHeadModel use ignore_index = -1 ?2019-09-20T07:53:20Z2019-10-03T23:36:03ZTrue
MDU6SXNzdWU0OTYzMzk1ODQ=Rectified Adam + LARS2019-09-20T13:00:54Z2020-02-03T09:55:35ZTrue
MDU6SXNzdWU0OTYzNDM2Mjk=Getting an unexpected EOF when trying to download 'bert-large-uncased-whole-word-masking-finetuned-squad' model.2019-09-20T13:09:18Z2020-02-01T10:20:09ZTrue
MDU6SXNzdWU0OTYzNDkyNTI=max_len_single_sentence should be max_len - 2 for RoBERTa2019-09-20T13:20:46Z2019-09-27T21:03:01ZTrue
MDU6SXNzdWU0OTY0MDc0NjM=Dataset format and Best Practices For Language Model Fine-tuning2019-09-20T15:12:26Z2019-12-01T14:07:47ZTrue
MDU6SXNzdWU0OTY0NDA0MzY=Which model is best to used for language model rescoring for ASR2019-09-20T16:23:09Z2019-12-15T12:21:09ZTrue
MDU6SXNzdWU0OTY1NjM3MjM=mask_tokens sometimes masks special tokens 2019-09-20T22:01:49Z2019-12-06T15:12:59ZTrue
MDU6SXNzdWU0OTY2NjA2MDQ=Planned support for new Grover 1.5B models?2019-09-21T14:15:12Z2019-11-29T18:57:22ZTrue
MDU6SXNzdWU0OTY2OTcyNDI=Best loss2019-09-21T20:19:37Z2019-09-28T20:40:52ZTrue
MDU6SXNzdWU0OTY3MzAwMDg=Redundant sep_token_extra option for RoBERTa Fine-tuning2019-09-22T03:49:35Z2019-09-27T23:37:00ZTrue
MDU6SXNzdWU0OTY3NDM5MDE=RoBERTa : add_special_tokens=True2019-09-22T07:29:04Z2019-12-02T07:20:26ZTrue
MDU6SXNzdWU0OTY3NTA2MjY=In BertForSequenceClassification, why is loss initialised in every forward?2019-09-22T08:45:51Z2020-04-14T23:25:53ZTrue
MDU6SXNzdWU0OTY4MTczMzQ=How to preprocess my own data to use RoBERTa of Multiple GPUs2019-09-22T18:46:43Z2019-12-09T00:38:10ZTrue
MDU6SXNzdWU0OTY4NzA2MzE=How to predict missing word [MASK] using Robert2019-09-23T02:41:12Z2019-09-24T03:43:51ZTrue
MDU6SXNzdWU0OTY5NTAwMDI=BertTokenizer provides wrong encode function for Japanese BERT2019-09-23T08:07:27Z2019-09-26T10:18:25ZTrue
MDU6SXNzdWU0OTcwMjk3ODY=A sequence with no special tokens has been passed to the RoBERTa model. This model  requires special tokens in order to work. Please specify add_special_tokens=True in  your encoding.2019-09-23T11:02:30Z2019-12-20T12:20:31ZTrue
MDU6SXNzdWU0OTcxMzU0MzY=BertForQuestionAnswering output to predict text2019-09-23T14:31:51Z2019-10-17T02:32:39ZTrue
MDU6SXNzdWU0OTcyNjg2OTQ=Why does padding affect the embedding results for XLNet? Pre-padding returns different embeddings than post-padding. Which one should be used?2019-09-23T18:56:10Z2020-01-12T23:39:03ZTrue
MDU6SXNzdWU0OTczMjE5NTQ="Using pytorch-transformer to reimplement the ""Attention is all you need"" paper"2019-09-23T20:51:36Z2019-09-30T19:28:00ZTrue
MDU6SXNzdWU0OTc1NDc1MTY=parameter never_split not added in BasicTokenizer's tokenize2019-09-24T08:48:21Z2019-11-30T09:12:11ZTrue
MDU6SXNzdWU0OTc1NzI0ODQ=How to build a Text-to-Feature Extractor based on Fine-Tuned BERT Model2019-09-24T09:35:17Z2019-09-26T12:14:00ZTrue
MDU6SXNzdWU0OTc2NDQ3MDM=A Micro BERT2019-09-24T12:04:24Z2019-12-04T05:38:47ZTrue
MDU6SXNzdWU0OTc3MzcxODc=RuntimeError: expected scalar type Half but found Float2019-09-24T14:46:25Z2020-02-10T10:19:20ZTrue
MDU6SXNzdWU0OTc5MDgzNDc=Sequence Classification pooled output vs last hidden state2019-09-24T20:30:19Z2019-09-30T17:42:44ZTrue
MDU6SXNzdWU0OTgwMjM4MTI=Loading errors for BERT base on GPU with PyTorch 0.4.1 2019-09-25T03:15:34Z2019-09-25T03:23:47ZTrue
MDU6SXNzdWU0OTgwMzgyNTU=Is the UI code for https://transformer.huggingface.co open source? 2019-09-25T04:18:43Z2019-09-26T13:51:43ZTrue
MDU6SXNzdWU0OTgxNzU3Nzc=pytorch-transformers returns output of 13 layers?2019-09-25T09:51:36Z2019-09-27T08:30:08ZTrue
MDU6SXNzdWU0OTgyODMxOTU=Typo in modeling_bert file2019-09-25T13:21:30Z2019-09-27T06:59:47ZTrue
MDU6SXNzdWU0OTg1MTQyNjM=Optimize XLNet model to generate embedding of long documents2019-09-25T20:44:48Z2019-09-26T15:49:08ZTrue
MDU6SXNzdWU0OTg5MjMyODI=Extending `examples/` to TensorFlow2019-09-26T14:29:20Z2019-12-08T16:38:10ZTrue
MDU6SXNzdWU0OTg5NTgyNjY=Why is the vocabulary of token_type_ids and input_ids shared? 2019-09-26T15:25:33Z2019-12-02T17:20:28ZTrue
MDU6SXNzdWU0OTkwMDI5MTM=Size mismatch when loading pretrained model2019-09-26T16:52:53Z2019-09-26T17:56:33ZTrue
MDU6SXNzdWU0OTkwMjgxOTA=Examples in Colab2019-09-26T17:49:19Z2019-12-04T23:38:46ZTrue
MDU6SXNzdWU0OTkwNDE5NzM=AttributeError: 'RobertaTokenizer' object has no attribute 'add_special_tokens_sentences_pair'2019-09-26T18:19:40Z2019-09-26T20:29:32ZTrue
MDU6SXNzdWU0OTkwOTIzOTM=RobertaTokenizer documentation is off with the new transformers library2019-09-26T20:11:49Z2019-09-26T20:49:17ZTrue
MDU6SXNzdWU0OTkxNzM1MDI=Errors when using fp16 with traced models2019-09-27T00:25:19Z2019-12-03T00:56:13ZTrue
MDU6SXNzdWU0OTkyOTE1MDE=Ram utilisation of DistilBERT2019-09-27T07:46:33Z2019-12-03T08:56:11ZTrue
MDU6SXNzdWU0OTkzMjE1NDM=Use PyTorch's GELU activation2019-09-27T08:53:51Z2019-12-03T09:56:14ZTrue
MDU6SXNzdWU0OTkzMzQwODI=Urgent: RoBERTa-Large-MNLI does not work for 2-way classification anymore2019-09-27T09:20:06Z2020-02-09T23:58:58ZTrue
MDU6SXNzdWU0OTk0MTQxMjk=Custom models: MixUp Transformers with TF.Keras code2019-09-27T12:22:13Z2019-12-16T13:03:09ZTrue
MDU6SXNzdWU0OTk0NTE5NjE=SQUAD: V2 referenced at top of Readme; V1 referenced in usage instructions2019-09-27T13:38:08Z2019-09-27T13:42:07ZTrue
MDU6SXNzdWU0OTk0NjU1MTk=wwm-bert lm_finetune 2019-09-27T14:02:51Z2019-12-03T14:56:12ZTrue
MDU6SXNzdWU0OTk0OTc2OTU=run_tf_glue.py breaks when changing to a glue dataset different from mrpc2019-09-27T15:03:28Z2019-10-01T07:57:20ZTrue
MDU6SXNzdWU0OTk1MjY2MjI=GPT and BERT pretrained models in French2019-09-27T16:01:31Z2020-04-07T10:55:16ZTrue
MDU6SXNzdWU0OTk1NjQwMzE=Support for SuperGLUE fine-tune/eval?2019-09-27T17:33:54Z2019-12-03T18:56:11ZTrue
MDU6SXNzdWU0OTk1NzQzMzQ=How to contribute to “Write with transformer”?2019-09-27T17:59:29Z2020-01-29T13:39:17ZTrue
MDU6SXNzdWU0OTk2MjYzNTU=Chunking Long Documents for Classification Tasks2019-09-27T20:03:14Z2019-09-28T12:45:30ZTrue
MDU6SXNzdWU0OTk3NjE5ODY=Why the RoBERTa's max_position_embeddings size is 512+2=514?2019-09-28T11:52:45Z2019-12-04T16:38:46ZTrue
MDU6SXNzdWU0OTk3NjkyODg=Is there any plan for Roberta in SQuAD?2019-09-28T12:56:27Z2019-09-29T06:17:59ZTrue
MDU6SXNzdWU0OTk3NzQ1MDg=Why add the arguments 'head_mask' and when to use this arguments2019-09-28T13:40:38Z2019-12-04T14:38:47ZTrue
