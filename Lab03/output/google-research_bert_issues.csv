idtitlecreatedAtclosedAtclosed
MDU6SXNzdWUzNzQxOTUwNTk=please quick！2018-10-26T01:44:16Z2018-10-31T17:09:34ZTrue
MDU6SXNzdWUzNzQ0NTk4MjQ=pertained Chinese language model request, please.2018-10-26T16:34:19Z2018-11-01T00:06:24ZTrue
MDU6SXNzdWUzNzQ3MzI1OTk=Could tensor2tensor support bert?2018-10-28T09:03:57Z2018-10-31T18:06:56ZTrue
MDU6SXNzdWUzNzQ3NjYwMjk=Fine tuning Bert base/large on GPUs2018-10-28T15:31:23Z2018-11-01T00:06:16ZTrue
MDU6SXNzdWUzNzU3NTkzNjg=the date would be delayed?????2018-10-31T01:20:50Z2018-10-31T15:22:31ZTrue
MDU6SXNzdWUzNzYwODQ1NTc=TensorFlow Hub Module?2018-10-31T17:43:46Z2019-02-12T01:45:11ZTrue
MDU6SXNzdWUzNzYwOTc0MjU=Adding domain specific vocabulary2018-10-31T18:14:35Z2018-11-01T00:23:04ZTrue
MDU6SXNzdWUzNzYxNzY4MTg=Missing requirements.txt2018-10-31T21:59:09Z2018-10-31T23:07:20ZTrue
MDU6SXNzdWUzNzYxODY4NDQ=throwing bad_alloc after calling model_fn2018-10-31T22:38:02Z2018-11-01T05:30:08ZTrue
MDU6SXNzdWUzNzYxOTU4ODE=Need clarification for pre-training2018-10-31T23:18:06Z2018-11-01T03:05:54ZTrue
MDU6SXNzdWUzNzYyMjk5MjU=how to implement the Bidirectional Transformer?2018-11-01T02:32:58Z2018-11-01T03:08:09ZTrue
MDU6SXNzdWUzNzYyMzYzNzU=What does the type token mean in modeling.py2018-11-01T03:09:04Z2018-11-01T13:58:55ZTrue
MDU6SXNzdWUzNzYyNTc1MDk=Training WordPiece vocabulary2018-11-01T05:20:52Z2018-11-01T19:08:17ZTrue
MDU6SXNzdWUzNzYyNzgwOTY=how is the perfermance when inference？if it cost much time, may a smaller model reach a good result? 2018-11-01T07:04:50Z2018-11-02T07:21:12ZTrue
MDU6SXNzdWUzNzYyOTgwNjA=failed to squad on cased model2018-11-01T08:25:49Z2018-11-01T19:08:06ZTrue
MDU6SXNzdWUzNzYzMDcwMjU=tensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version2018-11-01T08:59:19Z2018-11-01T09:20:46ZTrue
MDU6SXNzdWUzNzYzNzc4OTM=How many word pieces is suitable for Chinese?2018-11-01T12:46:11Z2018-11-01T22:55:50ZTrue
MDU6SXNzdWUzNzY1MTE3NjE=Need clarification for tokenizations of numbers2018-11-01T18:23:27Z2018-11-01T22:54:54ZTrue
MDU6SXNzdWUzNzY1NzM4ODk=Training on data sets not in the discussed data sets2018-11-01T21:15:34Z2018-11-02T03:50:18ZTrue
MDU6SXNzdWUzNzY2NDE0NDI=Clarification : Fixed feature vectors2018-11-02T02:12:06Z2018-11-02T02:28:08ZTrue
MDU6SXNzdWUzNzY2NDQzMjY=Plans to support longer sequences?2018-11-02T02:27:54Z2018-11-03T20:15:15ZTrue
MDU6SXNzdWUzNzY2NDc0Mjk=Are linear decay, L2 normalization and learned positional embs essential to the performance?2018-11-02T02:45:51Z2018-11-02T22:01:30ZTrue
MDU6SXNzdWUzNzY2NTgzNDA=There is a endless loop when max_seq_length=64.2018-11-02T03:40:54Z2018-11-02T22:52:53ZTrue
MDU6SXNzdWUzNzY2NjM2MTY=run run_pretraining.py but use CPU instead of GPU2018-11-02T04:14:28Z2018-11-02T05:29:17ZTrue
MDU6SXNzdWUzNzY2NzYwMDM=Why there is no results on SNLI dataset ?2018-11-02T05:37:17Z2018-11-02T05:41:47ZTrue
MDU6SXNzdWUzNzY2NzY4MTc=Plans to release sequence tagging task fine-tuning code?2018-11-02T05:42:00Z2018-11-02T05:53:01ZTrue
MDU6SXNzdWUzNzY2OTcyNDk=[Clarification] Feature vectors : Creating the input file2018-11-02T07:26:51Z2018-11-02T22:01:45ZTrue
MDU6SXNzdWUzNzY3MDI1NDk=can the pre-trained model be used as a  language model?2018-11-02T07:48:32Z2018-11-02T22:01:56ZTrue
MDU6SXNzdWUzNzcwMTk4NDA=plan to release SWAG code?2018-11-03T03:45:14Z2018-11-06T05:30:19ZTrue
MDU6SXNzdWUzNzcwMjk2MDY=Clarification of document2018-11-03T06:54:05Z2018-11-03T20:15:07ZTrue
MDU6SXNzdWUzNzcwODY1MjE="linear projection ""bias=True"" != original t2t implementation transformer"2018-11-03T19:38:24Z2018-11-03T20:13:19ZTrue
MDU6SXNzdWUzNzcxMzc2Nzc=Support for tied weights / Universal Transformer-like model?2018-11-04T09:59:46Z2018-11-04T18:56:44ZTrue
MDU6SXNzdWUzNzcxODY1OTc=Why is there extra denser layer in pooler?2018-11-04T19:39:55Z2018-11-05T18:22:46ZTrue
MDU6SXNzdWUzNzcyMjc3NTc="why need to change words to ""###*""by apply tokenization?"2018-11-05T02:25:03Z2018-11-05T17:46:36ZTrue
MDU6SXNzdWUzNzcyNDkyODc=Problem in generating the pertained output like Elmo2018-11-05T04:47:34Z2018-11-05T17:49:33ZTrue
MDU6SXNzdWUzNzcyODYxODQ=input_fn_builder() got an unexpected keyword argument 'features'2018-11-05T07:56:20Z2018-11-05T19:16:32ZTrue
MDU6SXNzdWUzNzcyODc0MDU="in the function ""get_masked_lm_output"", why set the output weights the same as the input embeddings?"2018-11-05T08:01:14Z2018-11-05T18:10:41ZTrue
MDU6SXNzdWUzNzczMTk3MzQ=num_tpu_cores means number of Cloud TPUs？2018-11-05T09:43:43Z2018-11-05T18:09:02ZTrue
MDU6SXNzdWUzNzczNDEzMzM=I get attribute error when I run classifier code2018-11-05T10:41:04Z2018-11-05T19:17:07ZTrue
MDU6SXNzdWUzNzczNTY4MTE=where is the XnliProcessor?2018-11-05T11:24:58Z2018-11-05T17:52:08ZTrue
MDU6SXNzdWUzNzc0MjAyMzI=What are the requirements of the language in order to included in the BERT?2018-11-05T14:19:44Z2018-11-05T18:02:49ZTrue
MDU6SXNzdWUzNzc0Mjc2Njk=SentencePiece2018-11-05T14:37:21Z2018-11-05T18:02:21ZTrue
MDU6SXNzdWUzNzc0NTM4NDg=PyTorch implementation2018-11-05T15:36:04Z2018-11-05T20:23:01ZTrue
MDU6SXNzdWUzNzc1MDI0ODE=Colab notebook is out of sync with the latest update2018-11-05T17:24:19Z2018-11-05T18:21:54ZTrue
MDU6SXNzdWUzNzc2NjMwMjY=run run_classifier.py on chinese data, Failed to find any matching files for /path/chinese_L-12_H-768_A-12/bert_model.ckpt2018-11-06T02:09:36Z2018-11-06T04:29:03ZTrue
MDU6SXNzdWUzNzc2NjgwMDM=Trouble to understand position embedding.2018-11-06T02:34:42Z2018-11-06T18:18:41ZTrue
MDU6SXNzdWUzNzc2Njk3NTA=how to generate vocab file that BERT model was trained on?2018-11-06T02:44:28Z2018-11-06T18:18:49ZTrue
MDU6SXNzdWUzNzc2NzE5Mjk=How to get the word embedding after pre-training?2018-11-06T02:56:10Z2018-11-06T20:54:51ZTrue
MDU6SXNzdWUzNzc3MDQ0Mjg=How BERT would perform on IMDB, Trec-6?2018-11-06T06:04:39Z2018-11-07T02:01:59ZTrue
MDU6SXNzdWUzNzc3MjMzNzQ=Why Chinese vocab contains ##word?2018-11-06T07:31:33Z2018-11-06T19:25:35ZTrue
MDU6SXNzdWUzNzc3MjgyMTM=Model become 3 times larger after finetune?2018-11-06T07:51:20Z2018-11-06T19:24:16ZTrue
MDU6SXNzdWUzNzc3NTE2OTk=How to get the probability of masked words with pre-trained model2018-11-06T09:09:25Z2018-11-07T06:08:02ZTrue
MDU6SXNzdWUzNzc4MzA2MTQ=How are out of vocabulary words handled for Chinese?2018-11-06T12:44:33Z2018-11-06T19:22:39ZTrue
MDU6SXNzdWUzNzc4NDc4NjM=Extracting features on for long sequences / SQuAD2018-11-06T13:31:58Z2018-11-07T06:08:08ZTrue
MDU6SXNzdWUzNzc5Njg1ODE=Unable to run Colab notebook with batch size < 82018-11-06T18:05:17Z2018-11-07T00:34:51ZTrue
MDU6SXNzdWUzNzgwODc2OTg=how to see loss per steps or epoch during train?2018-11-07T00:09:43Z2018-11-07T06:08:22ZTrue
MDU6SXNzdWUzNzgxMzA2Mzg=Features extracted from layer -1  represent sentence embedding for a sentence?2018-11-07T03:42:44Z2018-11-07T23:01:05ZTrue
MDU6SXNzdWUzNzgxNTg1NDc=Feature vectors represent word embeddings ? 2018-11-07T06:29:08Z2018-11-07T06:35:27ZTrue
MDU6SXNzdWUzNzgxNzM5MTQ=Plan to release 'run_scorer.py' ?2018-11-07T07:41:26Z2018-11-15T03:02:58ZTrue
MDU6SXNzdWUzNzgxODMyOTA=How to train models on GPU instead of CPU when TPU is not available?2018-11-07T08:17:00Z2018-11-08T02:28:51ZTrue
MDU6SXNzdWUzNzgzODkyNzE=extract_features.py failed to load trained model2018-11-07T17:21:38Z2018-11-07T18:12:19ZTrue
MDU6SXNzdWUzNzg1MjE1NDQ=Key Error on Sentence Classification example2018-11-08T00:01:15Z2018-11-08T00:20:59ZTrue
MDU6SXNzdWUzNzg1MzgyMjU=I get error when I run classifier in task MRPC 2018-11-08T01:18:42Z2018-11-08T02:28:43ZTrue
MDU6SXNzdWUzNzg1NTc3ODI=run_pretraining.py - clip gradient error: Found Inf or NaN global norm: Tensor had NaN values2018-11-08T02:56:38Z2018-11-13T04:41:24ZTrue
MDU6SXNzdWUzNzg1NjkyNDU=The feature of bidirection2018-11-08T03:57:21Z2018-11-08T18:15:21ZTrue
MDU6SXNzdWUzNzg2MzQyNDE=Import error with extract_features.py 2018-11-08T08:56:38Z2018-11-08T18:14:31ZTrue
MDU6SXNzdWUzNzg2NjU1MzA=mask 15% words in random?2018-11-08T10:21:31Z2018-11-08T18:14:18ZTrue
MDU6SXNzdWUzNzg2ODY0OTY=How to run bert on SWAG dataset2018-11-08T11:17:03Z2018-11-09T09:31:16ZTrue
MDU6SXNzdWUzNzg5OTY1NjQ=Plan to have a FP16 flag for GPU that can save the memory usage ?2018-11-09T02:22:10Z2018-11-09T15:30:17ZTrue
MDU6SXNzdWUzNzkwMDE0MDg=It took a several days to create pretraining data and hasn't finished.2018-11-09T02:47:09Z2018-11-10T17:14:28ZTrue
MDU6SXNzdWUzNzkwNTQyNjQ=Expected masked_lm_accuracy2018-11-09T07:39:37Z2018-11-10T17:13:32ZTrue
MDU6SXNzdWUzNzkwNjkwODg=Huge embedding output file2018-11-09T08:37:13Z2018-11-10T21:15:00ZTrue
MDU6SXNzdWUzNzkwODc3MTE="python run_classifier.py  InvalidArgumentError (see above for traceback): Found Inf or NaN global norm. : Tensor had NaN values 	 [[{{node VerifyFinite/CheckNumerics}} = CheckNumerics[T=DT_FLOAT, message=""Found Inf or NaN global norm."", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](global_norm/global_norm)]]"2018-11-09T09:35:39Z2018-11-09T09:53:29ZTrue
MDU6SXNzdWUzNzkzOTcxNDQ=run_classifier.py missing online prediction function 2018-11-10T06:48:40Z2018-11-12T05:50:33ZTrue
MDU6SXNzdWUzNzk0MTg1MzY=When to stop training? What is a good valid loss value to stop ? How to improve classification performance?2018-11-10T12:32:46Z2018-11-24T01:18:22ZTrue
MDU6SXNzdWUzNzk1MDE4MzI=Bert_model.ckpt not found with run_squad.py on TPU2018-11-11T08:34:42Z2018-11-12T17:45:16ZTrue
MDU6SXNzdWUzNzk1MzI1MjQ=How to get distributed checkpoints to reduce the size of model only for prediction 2018-11-11T15:18:54Z2018-11-12T05:50:43ZTrue
MDU6SXNzdWUzNzk1Mzg3NTQ=For facebook/page2018-11-11T16:28:39Z2018-11-11T16:29:11ZTrue
MDU6SXNzdWUzNzk1NzgwMDE=Hyperparameters for GLUE results in paper2018-11-11T23:51:16ZFalse
MDU6SXNzdWUzNzk2MzAwOTY=Possible to release the final dense layer in pre training2018-11-12T05:46:46Z2018-11-12T17:47:15ZTrue
MDU6SXNzdWUzNzk2NDkwNDI=how to get the probability of a missing word in a sentence2018-11-12T07:13:58Z2018-11-12T17:46:49ZTrue
MDU6SXNzdWUzNzk2NTM3OTk=how to run bert with multi GPU on demo 2018-11-12T07:33:12Z2018-11-12T17:45:03ZTrue
MDU6SXNzdWUzNzk2ODMxNDY=how can I print run_pretraining.py loss?2018-11-12T09:13:07Z2018-11-12T17:44:00ZTrue
MDU6SXNzdWUzNzk3NDc5MjM=fine-tuned for a document task2018-11-12T12:07:52Z2018-11-12T17:50:57ZTrue
MDU6SXNzdWUzNzk4MzA4NTQ=issue with input_fn_builder when making prediction2018-11-12T15:36:01Z2019-07-30T11:34:31ZTrue
MDU6SXNzdWUzODAwMTkwNzg=How to redirect logging to a file?2018-11-13T01:28:58Z2018-11-15T03:01:17ZTrue
MDU6SXNzdWUzODAwMzUzNDQ=restore parameters from previous checkpoints2018-11-13T02:50:42Z2018-11-13T09:37:05ZTrue
MDU6SXNzdWUzODAwODI3ODI=could you supply the pretraining dataset ?2018-11-13T06:48:54Z2018-11-15T03:01:07ZTrue
MDU6SXNzdWUzODAxMTYxODA=Classification quality is depends on max_sequence_length2018-11-13T08:46:12Z2018-11-24T01:18:54ZTrue
MDU6SXNzdWUzODAxMjQ5OTU=Restore model each time doing  estimator.predict2018-11-13T09:10:35Z2018-11-15T03:00:49ZTrue
MDU6SXNzdWUzODAxMzc3ODc=how to save the best model according to the valid dataset2018-11-13T09:42:45Z2018-11-15T02:59:49ZTrue
MDU6SXNzdWUzODAyMTM4NDk=The problem of tokenizer2018-11-13T12:58:23Z2018-11-14T17:34:53ZTrue
MDU6SXNzdWUzODA0ODUxNzA=How to handle create_pretraining_data.py for extremely large input data?2018-11-14T00:34:09Z2018-11-14T05:16:48ZTrue
MDU6SXNzdWUzODA1MzQxNTQ=ResourceExhaustedError (see above for traceback): OOM when allocating tensor2018-11-14T04:46:25Z2018-11-14T06:41:02ZTrue
MDU6SXNzdWUzODA1ODA5NDQ=When will the BERT-large-cased model be ready?2018-11-14T08:11:37Z2018-11-25T00:53:06ZTrue
MDU6SXNzdWUzODA5NzAzODk=Trying to run SQuAD which seems to run but does not produce a predictions.json file2018-11-15T02:18:55Z2018-11-15T03:00:00ZTrue
MDU6SXNzdWUzODA5ODIwOTU=BERT feature extraction as a service2018-11-15T03:16:18ZFalse
MDU6SXNzdWUzODEwMjk5MDk=Seems the pre-trained Bert-base Chinese model only support binary classification?2018-11-15T07:16:13Z2018-11-24T01:12:03ZTrue
MDU6SXNzdWUzODExMjA0NDc=why all  the next_sentence_labels equal 1 with run create_pretraining_data.py?2018-11-15T11:33:57Z2018-11-15T16:48:09ZTrue
MDU6SXNzdWUzODExNzQzNzQ=Cloud bucket error when pretraining on colab2018-11-15T14:02:37Z2018-11-24T15:30:51ZTrue
MDU6SXNzdWUzODExODQ0NDA=Is that possible to enlarge the segment ID during fine-tune?2018-11-15T14:26:51Z2018-11-15T16:47:09ZTrue
MDU6SXNzdWUzODEyODA3NTk=Obtaining low scores in the STS 2012 task2018-11-15T18:13:02ZFalse
MDU6SXNzdWUzODE1MDAwNDE=bert按中文字符分割好还是按中文词语分割好...2018-11-16T08:44:52Z2018-11-19T06:20:49ZTrue
MDU6SXNzdWUzODE1MDQ5NDI=Japanese voice sound mark is not an accent mark.2018-11-16T08:58:05Z2018-11-17T18:42:07ZTrue
MDU6SXNzdWUzODE1ODk1NDg=Japanese words consist of Hiragana and Chinese characters (Kanji)2018-11-16T12:59:30Z2018-11-17T18:42:24ZTrue
MDU6SXNzdWUzODE1OTk2NTI=Whitespace around Chinese characters may not keep the original intention of the sentence.2018-11-16T13:28:30Z2018-11-17T18:42:30ZTrue
MDU6SXNzdWUzODE2ODI1ODM=Korean Hangul is decomposed to Jamo (consonant/vowel chars)2018-11-16T16:59:24Z2018-11-17T18:42:20ZTrue
MDU6SXNzdWUzODE2OTIxNzk=Incorrect description in multilingual.md2018-11-16T17:26:54Z2018-11-24T01:13:57ZTrue
MDU6SXNzdWUzODE4MzIyNTI=Vowel symbols are removed from Devanagari (Hindi) scripts2018-11-17T05:59:20Z2018-11-17T18:40:41ZTrue
MDU6SXNzdWUzODE4ODUyOTQ=BERT as a language model2018-11-17T17:56:27Z2018-11-23T22:01:23ZTrue
MDU6SXNzdWUzODE5NTQ3NjE=fine tuning on chinese dataset getting unwell result2018-11-18T12:16:39Z2019-03-02T16:22:50ZTrue
MDU6SXNzdWUzODIwMzU0OTk=Wrong URL for SQuAD dev-v2.0.json2018-11-19T02:37:32Z2018-11-23T22:01:38ZTrue
MDU6SXNzdWUzODIwNDYyNjk=apply bert as basic encoder to intergate with classificial architecture, but achieve worse result than original finetuning2018-11-19T03:45:24Z2018-11-24T01:06:49ZTrue
MDU6SXNzdWUzODIwNzIyNTI=Using custom fine-tuned model, get predictions for each line of test data2018-11-19T06:19:39ZFalse
MDU6SXNzdWUzODI0MTMwNjk=run_classifier error with CoLA dataset2018-11-19T22:08:45ZFalse
MDU6SXNzdWUzODI0NDI1OTc=Fine tuning BERT to extract embeddings (like ELMo)2018-11-20T00:00:09Z2018-11-23T22:03:22ZTrue
MDU6SXNzdWUzODI0NTAwNTY=Use BERT fine-tuned model for Tensorflow serving2018-11-20T00:35:39ZFalse
MDU6SXNzdWUzODI0NzU2NTg=how to make prediction using cpu2018-11-20T02:42:07ZFalse
MDU6SXNzdWUzODI1MzcyMDM=how to speed up the prediction?2018-11-20T07:41:33Z2018-11-23T22:03:07ZTrue
MDU6SXNzdWUzODI1NDIzODQ=the vocab size of pretrained model is small2018-11-20T08:00:18Z2018-11-23T22:09:47ZTrue
MDU6SXNzdWUzODI1NTk4NjY=Some detail about bert2018-11-20T08:56:44Z2018-11-23T22:06:18ZTrue
MDU6SXNzdWUzODI3MDc5MzY=My own dataset fine-tuning2018-11-20T15:11:14Z2018-11-24T01:16:09ZTrue
MDU6SXNzdWUzODI3MjM5NzY=Missing data processors?2018-11-20T15:44:53Z2018-11-21T16:33:10ZTrue
MDU6SXNzdWUzODI4MzQ2Mzg=Question about the used optimizer AdamWeightDecayOptimizer2018-11-20T20:25:34Z2018-11-23T22:03:57ZTrue
MDU6SXNzdWUzODI5ODg1MzU=Getting all negative predictions when fine-tune my data2018-11-21T07:26:01Z2018-11-21T12:42:12ZTrue
MDU6SXNzdWUzODMwMjE2ODY=BERT-Base Chinese data details2018-11-21T09:14:06Z2018-11-25T01:32:09ZTrue
MDU6SXNzdWUzODMxMTc1ODk=Something not friendly when eval the bert in run_classifier.py2018-11-21T13:27:00Z2018-12-03T02:00:35ZTrue
MDU6SXNzdWUzODMyMjk5MDQ=Simplifying BERT for Q&A - One paragraph and Query2018-11-21T17:44:36Z2018-11-23T22:08:23ZTrue
MDU6SXNzdWUzODMzNTk4MTM=BERT-SST2018-11-22T02:40:06ZFalse
MDU6SXNzdWUzODM0MjkwMTU=Reproducing paper results from feature vectors (STS-B dataset)2018-11-22T08:36:07Z2018-11-23T07:36:58ZTrue
MDU6SXNzdWUzODM0NDk3NjQ=Differece between bert's attention and transformer's.2018-11-22T09:34:31Z2018-11-23T22:19:48ZTrue
MDU6SXNzdWUzODM1NTgwMjc=BERT Vector Space shows issues with unknown words2018-11-22T14:26:38Z2018-11-23T22:17:02ZTrue
MDU6SXNzdWUzODM2Njk5NjY=Pretrained checkpoint contains absolute path2018-11-22T23:04:27Z2018-11-23T22:05:36ZTrue
MDU6SXNzdWUzODM3MjE4NjE=Is CLS token also Masked in pre-training?2018-11-23T07:15:46Z2018-11-23T22:04:11ZTrue
MDU6SXNzdWUzODQwNzE1OTY="is ""new_global_step = global_step + 1"" necessary?"2018-11-25T11:48:46Z2018-12-06T15:51:29ZTrue
MDU6SXNzdWUzODQxNDE4ODU=Question about mask strategy.2018-11-26T01:19:23Z2018-11-28T23:47:14ZTrue
MDU6SXNzdWUzODQxNjU1OTA=Questions about pretraining 2018-11-26T04:00:42ZFalse
MDU6SXNzdWUzODQxNzcxMTA=finetuning of Chinese-base model with distributed dl framework uber/horovod, got worse results results 2018-11-26T05:13:12ZFalse
MDU6SXNzdWUzODQxODUzNjY=how to use chinese word vector generate by bert to calculate sentence similarity2018-11-26T06:01:53ZFalse
MDU6SXNzdWUzODQxOTc2Nzg=How to set hyperparameters when fine-tune?2018-11-26T06:59:08ZFalse
MDU6SXNzdWUzODQyMDU1Mzk=How to apply this model to QA tasks (no paragraphs)2018-11-26T07:32:03ZFalse
MDU6SXNzdWUzODQyNTU4OTU=Start_logit/End_logit in run_squad.py2018-11-26T10:05:55ZFalse
MDU6SXNzdWUzODQzMjkyNzY=Pretraining BERT without next sentence prediction2018-11-26T13:24:31Z2018-12-07T23:02:11ZTrue
MDU6SXNzdWUzODQ1MTkzMDg=Can I use a new activation function?2018-11-26T21:32:36ZFalse
MDU6SXNzdWUzODQ1OTQ1NTA=Next sentence acc always be equals to 1 after a few training steps2018-11-27T02:38:26Z2018-11-27T12:09:23ZTrue
MDU6SXNzdWUzODQ2MDIwMzg=About the pretraining data of Chinese2018-11-27T03:15:24ZFalse
MDU6SXNzdWUzODQ2ODIwMDU="Model detail: Why does ""attention_heads"" exist in ""modeling.py""?"2018-11-27T08:45:10ZFalse
MDU6SXNzdWUzODQ2OTMyNzY=python run_classifier.py error!!!2018-11-27T09:15:22ZFalse
MDU6SXNzdWUzODQ3MDA5MDg="Has anyone done with preprocessor for ""Quora Question duplicate, QQP dataset""?"2018-11-27T09:33:42Z2018-11-28T11:00:41ZTrue
MDU6SXNzdWUzODQ3MDM2NzI=How can I use only one language in multilingual model, for faster inference?2018-11-27T09:40:24ZFalse
MDU6SXNzdWUzODQ3NTM2MTQ=After fine-tuning BERT on SQUAD, how do I test what output it gives2018-11-27T11:38:05Z2018-11-27T14:41:20ZTrue
MDU6SXNzdWUzODQ3NjY2Njc=`create_pretraining_data.py` so slowly..2018-11-27T12:13:15Z2018-11-28T01:29:13ZTrue
MDU6SXNzdWUzODQ5ODA1NzU=MXNet/Gluon Implementation and Tutorial2018-11-27T20:51:54ZFalse
MDU6SXNzdWUzODUwNzI0MjA=How to use BERT to handle bilingual tasks?2018-11-28T02:26:09Z2018-12-20T12:04:59ZTrue
MDU6SXNzdWUzODUwODEwNTU=what is the max length of the context?2018-11-28T03:06:45ZFalse
MDU6SXNzdWUzODUxMTQzNTA=seems run_squad.py code error2018-11-28T06:00:48ZFalse
MDU6SXNzdWUzODUxNTk2NTY=not good when I use BERT for seq2seq model in keyphrase generation2018-11-28T08:47:21ZFalse
MDU6SXNzdWUzODUyMzA0NjY=Question about the implementation of learning rate scheduling2018-11-28T11:47:09Z2018-11-29T02:21:14ZTrue
MDU6SXNzdWUzODUzODg4Mjk=Some Questions about vocab?2018-11-28T17:55:15ZFalse
MDU6SXNzdWUzODUzOTk5MDY=Can i run_classifiy with out pretrained model in new dataset?2018-11-28T18:25:51ZFalse
MDU6SXNzdWUzODU1MjY2MDY=why the pooled_output just use first token to represent the whole sentence?2018-11-29T01:20:45ZFalse
MDU6SXNzdWUzODU1NDgxOTg=Best way to get the representation of One sentence.2018-11-29T03:01:38Z2018-11-29T03:43:48ZTrue
MDU6SXNzdWUzODU1NTYyMTg=Can we change the length of feature extraction's ouput2018-11-29T03:38:58Z2018-11-29T06:34:47ZTrue
MDU6SXNzdWUzODU1ODIyOTU=questions on the softmax layer in pretraining and also the way of avoiding mismatch during fine tuning2018-11-29T06:00:08Z2018-11-29T09:33:02ZTrue
MDU6SXNzdWUzODU4ODE5MjQ=Support for multiclass sentence classification2018-11-29T19:06:05ZFalse
MDU6SXNzdWUzODU5MzMyNDQ=How to use a pre-trained model with additional custom features2018-11-29T21:27:09ZFalse
MDU6SXNzdWUzODYwMDM2NDk=Is it possible to fine-tune BERT for SQuAD-like task on another language2018-11-30T01:54:06Z2018-12-15T07:17:33ZTrue
MDU6SXNzdWUzODYxMzQ3MzM=Request to provide deployment code extract_features.py2018-11-30T10:46:52ZFalse
MDU6SXNzdWUzODYyNjMwMTg=Thai-only BERT model is available2018-11-30T16:39:34ZFalse
MDU6SXNzdWUzODYzODgzMzc=prediction from classifier2018-11-30T23:32:32ZFalse
MDU6SXNzdWUzODY0MTQ1Njc=is sos and eos in bert vocab2018-12-01T02:50:00Z2018-12-01T02:51:26ZTrue
MDU6SXNzdWUzODY0MTQ5MTc=are sos and eos in bert vocab2018-12-01T02:54:26ZFalse
MDU6SXNzdWUzODY0MTY2MjQ=I have weights for every example. Need to multiple them with the loss function2018-12-01T03:17:26Z2019-01-02T16:12:48ZTrue
MDU6SXNzdWUzODY0MjM1NjU="How to ""partially"" restore from the checkpoint?"2018-12-01T04:59:52Z2019-02-13T20:53:22ZTrue
MDU6SXNzdWUzODY0MzQ3MzA=Sometime I get running error, maybe it is a bug2018-12-01T07:48:48Z2019-01-21T09:29:00ZTrue
MDU6SXNzdWUzODY0ODE3MTc=Fine-tuning takes a long time to save checkpoints2018-12-01T18:03:00ZFalse
MDU6SXNzdWUzODY0ODUyOTY= Request to add multi GPUs support and plz don`t make TPU evil.2018-12-01T18:45:45ZFalse
MDU6SXNzdWUzODY1NzIxMDE=train_batch_size in run_classifier.py2018-12-02T15:52:48Z2019-05-01T04:35:51ZTrue
MDU6SXNzdWUzODY2MzgwOTg=Can I use Bert for checking sentence similarity?2018-12-03T02:45:55ZFalse
MDU6SXNzdWUzODY2NTM4NjQ=Run SQuAD 2.0 locally with base model?2018-12-03T04:20:57ZFalse
MDU6SXNzdWUzODY3MDg1OTY=Can you release the hyper-parameter of NER task?2018-12-03T08:32:21Z2019-06-21T13:18:50ZTrue
MDU6SXNzdWUzODY3NzU4NTg=Incorrect number of predicted examples2018-12-03T11:31:19Z2018-12-04T09:15:31ZTrue
MDU6SXNzdWUzODcxNjQwMjk=summary2018-12-04T08:05:34Z2018-12-04T08:06:46ZTrue
MDU6SXNzdWUzODcxOTMzNzE=BERT Embeddings trainable2018-12-04T09:30:38Z2018-12-13T15:37:08ZTrue
MDU6SXNzdWUzODc0NzY1OTc=BERT-large abnormal value in the token embedding vector 2018-12-04T20:57:35Z2018-12-06T22:30:10ZTrue
MDU6SXNzdWUzODc1OTY0NTM=nothing2018-12-05T05:13:03Z2018-12-05T05:15:13ZTrue
MDU6SXNzdWUzODc1OTY4MTk=batch inference with GPU takes a long time!2018-12-05T05:15:10ZFalse
MDU6SXNzdWUzODc4MzE4MzI=Keep a CHANGELOG file2018-12-05T16:13:34Z2019-06-18T22:25:27ZTrue
MDU6SXNzdWUzODc4NjgzNDM=in run_classifier, do_eval fails for language en - XNLI-MT-1.0/xnli.dev.tsv No such file2018-12-05T17:36:32ZFalse
MDU6SXNzdWUzODgwOTEwMjY=run run_pretraining.py OOM2018-12-06T07:37:45Z2018-12-07T07:33:29ZTrue
MDU6SXNzdWUzODgyNjMwOTQ=Handling domain specific vocabulary2018-12-06T15:24:51Z2018-12-06T18:22:13ZTrue
MDU6SXNzdWUzODgyODQxNjk=how to decide value of the dupe_factor when run create_pretraining_data.py2018-12-06T16:10:22ZFalse
MDU6SXNzdWUzODg0ODY3MzE=Sequence length implications2018-12-07T03:03:47ZFalse
MDU6SXNzdWUzODg0OTA1Mjc=Get a bad result  about the dataset of sts20172018-12-07T03:23:41ZFalse
MDU6SXNzdWUzODg2MzUzNTc=Visualization of a 12-layer BERT for sentence encoding/embedding2018-12-07T12:29:19ZFalse
MDU6SXNzdWUzODg2NTY2NDE=[Request] Register official package to PyPI2018-12-07T13:33:15ZFalse
MDU6SXNzdWUzODg5NDQ2NTE=Prediction on custom dataset2018-12-08T18:03:19ZFalse
MDU6SXNzdWUzODkwMjYwNTE=Case sensitiveness for SQuAD training2018-12-09T14:00:51ZFalse
MDU6SXNzdWUzODk1ODU5MzQ=C安2018-12-11T03:52:10Z2018-12-11T03:52:15ZTrue
MDU6SXNzdWUzODk1ODY1Nzk=Can BERT run on RTX 2070 * 22018-12-11T03:55:40ZFalse
MDU6SXNzdWUzODk1ODY5MzE=run_classifier: clip_by_global_norm got nan/inf2018-12-11T03:57:44ZFalse
MDU6SXNzdWUzODk2MzE2NDI=what ' s max_position_embeddings to do ?   2018-12-11T07:37:56Z2018-12-11T10:16:47ZTrue
MDU6SXNzdWUzODk3ODIyODA=where is the classifier after fine-tuning bert?2018-12-11T14:10:09ZFalse
MDU6SXNzdWUzODk3ODg3MjU=What will happen with a much higher mask rate?2018-12-11T14:25:05ZFalse
MDU6SXNzdWUzOTAwODQxNDk=extract featture of the trained chinese model error: Attempting to use uninitialized value bert/encoder/layer_11/output/LayerNorm/beta2018-12-12T06:34:25ZFalse
MDU6SXNzdWUzOTAwOTQ3MTI=why  TFRecordWriter so slow ？ I have  8 million sentences which has taken one day in processing the data. is it normal?2018-12-12T07:16:58ZFalse
MDU6SXNzdWUzOTAxMTQyMTI=Chinese Pretraining2018-12-12T08:27:44ZFalse
MDU6SXNzdWUzOTAxMTQ3MzM=an question about the position embedding of the chinese trained model2018-12-12T08:29:18Z2019-07-23T23:57:43ZTrue
MDU6SXNzdWUzOTA1MDk4NzQ=Is BERT powerful enough to learn sentence embedding and word embedding?2018-12-13T04:07:41ZFalse
MDU6SXNzdWUzOTA1NDA3MDQ=What need I TODO with [CLS] and [SEPS] mark when fine-tuning for  NER task?2018-12-13T06:48:54ZFalse
MDU6SXNzdWUzOTA1NDQzMjY=flask to deploy on line2018-12-13T07:03:19ZFalse
MDU6SXNzdWUzOTA2NTk1Mjg=how can i get the label when running run_classifier.py2018-12-13T12:35:55Z2018-12-25T05:07:10ZTrue
MDU6SXNzdWUzOTA2NjMxMDc=How to print step loss during train?2018-12-13T12:45:54ZFalse
MDU6SXNzdWUzOTA5NTYxMjE=no attribute 'get_assigment_map_from_checkpoint'2018-12-14T03:57:01Z2018-12-14T07:43:33ZTrue
MDU6SXNzdWUzOTEwNDM2Mjc=List the reason for un-decrease loss when fine-tune2018-12-14T10:03:16Z2018-12-15T11:08:38ZTrue
MDU6SXNzdWUzOTEyNTc4NjA=tokenization_test.py Python3 compatibility2018-12-14T20:06:42Z2018-12-20T08:06:44ZTrue
MDU6SXNzdWUzOTEzNjQwODM=could you share pretrain data or the script to create it for chinese model?2018-12-15T10:10:13Z2019-07-23T23:57:23ZTrue
MDU6SXNzdWUzOTEzOTIxMjY=Evaluation on held out training data2018-12-15T16:29:13ZFalse
MDU6SXNzdWUzOTE2NTc0NzA=Why I got 1.3G checkpoint in local. But released model was 0.4G2018-12-17T10:55:23Z2018-12-17T14:49:40ZTrue
MDU6SXNzdWUzOTE3MDA5MzI=Sentence embedding for STS task by fine-tuning bert2018-12-17T12:58:29ZFalse
MDU6SXNzdWUzOTE4MDAyOTM=multilingual training2018-12-17T16:50:23ZFalse
MDU6SXNzdWUzOTE4NDE4MzQ=Fine-tune BERT on Azure platform2018-12-17T18:44:02ZFalse
MDU6SXNzdWUzOTE5Mzk5NDI=Pre-training logs2018-12-17T23:58:35ZFalse
MDU6SXNzdWUzOTIwMTUyMTE=pip package for BERT?2018-12-18T06:32:38ZFalse
MDU6SXNzdWUzOTIxNzA1NTg=Profiling BERT speed of predictions2018-12-18T14:03:36Z2018-12-19T07:06:08ZTrue
MDU6SXNzdWUzOTI1MDU1NTM=An error occur when I run pretrian2018-12-19T09:14:27Z2018-12-26T07:13:38ZTrue
MDU6SXNzdWUzOTI1MDU1NjM=A wrong occured when I did pretrain 2018-12-19T09:14:28Z2018-12-19T09:21:17ZTrue
MDU6SXNzdWUzOTI1MjcyMjM=tensorflow.python.framework.errors_impl.InternalError: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version2018-12-19T10:10:14ZFalse
MDU6SXNzdWUzOTI1NDI3OTk=Serving a fine-tuned model for sentence/token-level embedding2018-12-19T10:48:55ZFalse
MDU6SXNzdWUzOTI3MzM4MTE=low acc when training Bert-Large2018-12-19T18:53:40Z2018-12-20T10:22:03ZTrue
MDU6SXNzdWUzOTI4NTk4ODU=why add exclude_from_weight_decay for norm-related weight?2018-12-20T02:24:46ZFalse
MDU6SXNzdWUzOTI5NTMxMDc=How to handle label in a sequence labeling task2018-12-20T09:13:42ZFalse
MDU6SXNzdWUzOTMwNzk0NzQ=run_squad.py without GPU.. Without CUPY2018-12-20T14:52:37Z2018-12-21T09:33:11ZTrue
MDU6SXNzdWUzOTMyODgyNjU=pre_training with extra data2018-12-21T02:28:21ZFalse
MDU6SXNzdWUzOTM2MzY0MjM=modeling/embedding_lookup function issue2018-12-22T02:45:07ZFalse
MDU6SXNzdWUzOTM2NTE0NTc=Ask question without passing context passage2018-12-22T07:25:18ZFalse
MDU6SXNzdWUzOTM2NjY3MTA=run_classifier.py gets struck while saving checkpoint2018-12-22T11:42:07ZFalse
MDU6SXNzdWUzOTM2ODU2MTE=Anyone could share the checkpoint of a trained BERT Large model for SQuAD 2.0?2018-12-22T16:24:57ZFalse
MDU6SXNzdWUzOTM3NDc1NDU=How to skip context and just pass question ?2018-12-23T12:51:52ZFalse
MDU6SXNzdWUzOTM3NzgxMDY=BERT feature extraction for tensorflow serving2018-12-23T20:23:29ZFalse
MDU6SXNzdWUzOTM4MDE4NDk=why must pre-train two tasks at same time, can we just pre-train MLM?2018-12-24T03:12:51ZFalse
MDU6SXNzdWUzOTM4MDQzMDI=Some thoughts on Bert's fine-tuning2018-12-24T03:41:47ZFalse
MDU6SXNzdWUzOTM4Mjk1OTc=Classification of sentence pair with two different languages2018-12-24T07:48:03ZFalse
MDU6SXNzdWUzOTM4NzI0OTE=Can I put the Chinese translation of the original paper here?2018-12-24T12:24:56ZFalse
MDU6SXNzdWUzOTM5MTk1MDg=How to use multiple tpus?2018-12-24T18:38:02ZFalse
MDU6SXNzdWUzOTM5NTI2MDM=this is a Slack channel about BERT usage ,We can share point and any question2018-12-25T03:05:29ZFalse
MDU6SXNzdWUzOTM5ODI5NTA=fine-tuning with additional masked lm loss, and masked lm loss diverged2018-12-25T08:07:36Z2018-12-26T07:33:51ZTrue
MDU6SXNzdWUzOTQxMDQ2MTI=Unable to convert fine-tuned model to tflite model2018-12-26T07:37:20ZFalse
MDU6SXNzdWUzOTQxNjA0MDg=How to fine-tuning the BERT  with different  hiddens2018-12-26T12:43:06ZFalse
MDU6SXNzdWUzOTQxODk1NDA=can we do text analysis, understanding a text and answer our questions from text2018-12-26T15:32:22Z2019-01-04T10:28:24ZTrue
MDU6SXNzdWUzOTQyODQ5MzQ=Extract features return different layer values (vectors) each time, is it working well?2018-12-27T03:35:15ZFalse
MDU6SXNzdWUzOTQyOTA1MTA=When do you release the BERT-large for multilingual model?2018-12-27T04:23:05ZFalse
MDU6SXNzdWUzOTQ0MDIwODI=Why not the mlm use the information of adjacent sentences?2018-12-27T14:00:30ZFalse
MDU6SXNzdWUzOTQ1NTE1NDk=How to pad sentence A if I want fix the length of sentence A and B?2018-12-28T05:34:09Z2019-02-18T07:40:59ZTrue
MDU6SXNzdWUzOTQ1NzQzMTE=Why hidden size must be a multiple of the number of attention head2018-12-28T07:59:03ZFalse
MDU6SXNzdWUzOTQ1ODYzMDA=What is the effect of intermediate MLP layer?2018-12-28T09:04:40Z2019-11-14T04:04:00ZTrue
MDU6SXNzdWUzOTQ1ODY2MTg=What is the effect of adding the residual?2018-12-28T09:06:24Z2019-11-14T04:03:57ZTrue
MDU6SXNzdWUzOTQ1OTUzMzM=how the model reflect 'bidirectional'?2018-12-28T09:47:51ZFalse
MDU6SXNzdWUzOTQ3NTE5OTE=Why BERT can learn different attention info for each layer and each head?2018-12-29T02:21:41Z2019-11-14T04:03:53ZTrue
MDU6SXNzdWUzOTQ3NTIwOTY="when I do ner task after fine-tuning,should I set the param ""is_predict = true"" to train my bilstm networkd?"2018-12-29T02:22:47ZFalse
MDU6SXNzdWUzOTQ3ODEyNzc=how to get fine_tune model output probability2018-12-29T10:00:01ZFalse
MDU6SXNzdWUzOTUxMjEwMTQ=how use BERT language model to predict next word 2019-01-01T23:34:56ZFalse
MDU6SXNzdWUzOTUxODA2NDc=It is the problem of shuffle. I did not shuffle my data.2019-01-02T08:48:12Z2019-01-06T10:38:05ZTrue
MDU6SXNzdWUzOTUxOTM1ODM=Failed to connect to the Tensorflow master2019-01-02T09:45:31ZFalse
MDU6SXNzdWUzOTUyMjcyNzk=binary classification only!?2019-01-02T12:01:16Z2019-01-10T08:25:08ZTrue
MDU6SXNzdWUzOTU0MjIxNDA=Fine-Tuning specifications for MNLI/XNLI2019-01-03T00:15:54Z2019-02-18T02:52:06ZTrue
MDU6SXNzdWUzOTU0Njk0NzQ=Chinese vocab contains ##word which embeddings seem meaningful as I test them in a Chinese sequence classification task?2019-01-03T06:31:58Z2019-01-03T09:34:04ZTrue
MDU6SXNzdWUzOTU2MDcwMjk=How to load a model checkpoint using INIT_CHECKPOINT2019-01-03T15:09:58ZFalse
MDU6SXNzdWUzOTU2ODMwMDU=MultiLingual Pretraining Sampling Schedule2019-01-03T18:44:48Z2019-01-04T17:03:35ZTrue
MDU6SXNzdWUzOTU4MTc2NDg=How can I save one model as a .pb file?2019-01-04T06:02:04ZFalse
MDU6SXNzdWUzOTU4MjA2NzI=I encountered key error by using my own data set2019-01-04T06:23:00Z2019-01-09T03:49:55ZTrue
MDU6SXNzdWUzOTU4MjEwNzM=Sorry my mistake!2019-01-04T06:25:58Z2019-01-04T07:33:36ZTrue
MDU6SXNzdWUzOTYyMzAxOTU=how to ensemble the bert fintune baseline in squad2019-01-06T05:39:46ZFalse
MDU6SXNzdWUzOTYyNDk4Mjc=How to improve the multi-classifiction performance based on BERT-Base Chinese model?2019-01-06T11:27:44ZFalse
MDU6SXNzdWUzOTY0NzM4Nzg=How to actually use the fine tuned model?2019-01-07T12:46:36ZFalse
MDU6SXNzdWUzOTY4NzMwMzU=Paper Publication2019-01-08T11:52:05ZFalse
MDU6SXNzdWUzOTcxOTUyNDA=Wiki Data Formation Problem, Need Sentence Split2019-01-09T03:21:49ZFalse
MDU6SXNzdWUzOTczODc5MDg=Unreachable part2019-01-09T14:10:29ZFalse
MDU6SXNzdWUzOTc0NjYzMDU=User Warning2019-01-09T17:04:18Z2019-01-10T06:57:38ZTrue
MDU6SXNzdWUzOTc2OTY1NjY=Still met key error with my data set2019-01-10T06:58:44Z2019-01-15T15:39:16ZTrue
MDU6SXNzdWUzOTc3MDAzNjg=The fine_tune codes for NER CoNLL2003 with bert_base(cased) model2019-01-10T07:14:38ZFalse
MDU6SXNzdWUzOTc3MDMxODE=Can we use BERT for Punctuation Prediction?2019-01-10T07:25:49ZFalse
MDU6SXNzdWUzOTc5MjE5OTc=ResourceExhaustedError: XNLI Fine-tuning Example2019-01-10T16:52:18Z2019-01-10T16:54:07ZTrue
MDU6SXNzdWUzOTc5NzM0NDU=Constructed Languages Used in Training Multilingual2019-01-10T19:11:24ZFalse
MDU6SXNzdWUzOTgwNzg2NjM=How can I make word embedding using Bert?2019-01-11T00:35:00ZFalse
MDU6SXNzdWUzOTgxMjY1OTg=Python3.6 returns totally different outputs than Python3.5 for fine-tuning single sentence classification task2019-01-11T04:22:21ZFalse
MDU6SXNzdWUzOTgxNDg0OTM=How to use it in chat robot task?2019-01-11T06:27:09ZFalse
MDU6SXNzdWUzOTgyMzM5OTg=BERT for text summarization2019-01-11T10:45:41ZFalse
MDU6SXNzdWUzOTg0NzczNzc=run_squad.py for Squad 2.0 fails on empty question text or empty paragraph context2019-01-11T22:37:30ZFalse
MDU6SXNzdWUzOTg1MTg4Mjc=Errors encountered during pre-training2019-01-12T04:11:41ZFalse
MDU6SXNzdWUzOTg1Mjc5MjQ=Question: Why did you use a Wordpiece instead of Fasttext?2019-01-12T06:50:57ZFalse
MDU6SXNzdWUzOTg1NDQ4MDY=Speedup using Transformer-XL 2019-01-12T11:10:12ZFalse
MDU6SXNzdWUzOTg2NDc2MjM=Can I run the run_classifier.py file in Windows 10?2019-01-13T11:22:54ZFalse
MDU6SXNzdWUzOTg3Mzc5ODc=NotFoundError (see above for traceback): Restoring from checkpoint failed. 2019-01-14T03:31:59Z2019-01-22T02:32:03ZTrue
MDU6SXNzdWUzOTg4MjA2NjU=How to get an word embedding from embeddings of tokens2019-01-14T10:12:02Z2019-01-18T12:32:39ZTrue
MDU6SXNzdWUzOTg4Mzg5MzM=Can we use BERT for custom labeling?2019-01-14T11:01:53ZFalse
MDU6SXNzdWUzOTg4ODI4Mjc=BERT vs Word2vec2019-01-14T13:14:02ZFalse
MDU6SXNzdWUzOTkwMTM2NjI=What's the performance of BERT-Large on Squad 2.0 dev ?2019-01-14T18:19:25ZFalse
MDU6SXNzdWUzOTkxNjA1NjU=Does the learning_rate will change through the trainning?2019-01-15T02:21:47ZFalse
MDU6SXNzdWUzOTkxODg2NDE=How long for training models with RTX 2080 8G 2019-01-15T04:57:52Z2019-01-15T09:41:14ZTrue
MDU6SXNzdWUzOTkzODU1NTU=Fine-tune with TriviaQA2019-01-15T15:03:27ZFalse
MDU6SXNzdWU0MDAxOTg4NjQ=How to use those three ckpt file while finetuning pre-train model using run_classifier.py?2019-01-17T10:07:08Z2019-01-17T11:19:12ZTrue
MDU6SXNzdWU0MDAyMTcxMzk=How to choose warm-up steps depending on the train steps during pre-training?2019-01-17T10:49:35ZFalse
MDU6SXNzdWU0MDA0MTY1NDU=Weights from next sentence prediction2019-01-17T18:56:43ZFalse
MDU6SXNzdWU0MDA1NDgyMDM=How do multi label classification2019-01-18T02:40:01ZFalse
MDU6SXNzdWU0MDA1ODEzNTU=Two to Three mask word prediction at same sentence is very complex?2019-01-18T05:48:06ZFalse
MDU6SXNzdWU0MDA2NDc2MjA=Very Low F1 score of  run_squad.py2019-01-18T09:47:24ZFalse
MDU6SXNzdWU0MDA2OTE2MzQ=Memory issue2019-01-18T11:47:25ZFalse
MDU6SXNzdWU0MDA3MTQ5MjM=extract_features on TPU error (missing train_batch_size)2019-01-18T13:00:21ZFalse
MDU6SXNzdWU0MDA5NjY3MTE=FP16 inference performance of BERT2019-01-19T06:23:33ZFalse
MDU6SXNzdWU0MDA5NzIxNDU="where can i fine the ""model.ckpt"" file?"2019-01-19T07:51:40ZFalse
MDU6SXNzdWU0MDA5OTgzMzk=Evaluation of pretrained model with Gutenberg dataset on NSP task2019-01-19T13:55:54ZFalse
MDU6SXNzdWU0MDEyMDE4Mzc=pretraining error -no init_checkpoint 2019-01-21T05:44:52ZFalse
MDU6SXNzdWU0MDEyMDU0MTU=An error occur when I run run_classifier.py2019-01-21T06:02:48ZFalse
MDU6SXNzdWU0MDE1NzUxMTk=ValueError: Assignment map with scope only name xxx should map to scope only xxx. Should be 'scope/': 'other_scope/'.2019-01-22T02:37:26ZFalse
MDU6SXNzdWU0MDE1ODk3OTM=Running SQuAD 1.1 on TPU encounters error2019-01-22T03:56:33Z2019-01-24T21:55:35ZTrue
MDU6SXNzdWU0MDE2NjcwMjg=dose <s> represent whitespace in the chinese pretrained vocabulary?2019-01-22T09:17:56ZFalse
MDU6SXNzdWU0MDE3MTMxNjM=Can anyone point me in the code for the segment and position embeddings?2019-01-22T11:09:21Z2019-02-19T17:37:05ZTrue
MDU6SXNzdWU0MDE4NjQ0MjQ=Do You Need [SEP] Token for Single Sentence Tasks?2019-01-22T17:07:02ZFalse
MDU6SXNzdWU0MDIwNDA1ODA="can I use ""multi_cased_L-12_H-768_A-12"" for machine translation，if true then how "2019-01-23T02:20:14ZFalse
MDU6SXNzdWU0MDIwNTU2ODE=How to avoiding to use TFRecordWriter2019-01-23T03:32:27Z2019-02-11T04:20:56ZTrue
MDU6SXNzdWU0MDIwODAxOTg=Overfitting to fine-tuning dataset2019-01-23T05:41:52ZFalse
MDU6SXNzdWU0MDIxNTA1Mjk=BERT with FP16 and XLA inference speed2019-01-23T09:42:14ZFalse
MDU6SXNzdWU0MDIxODIzNjQ=For training, each question should have exactly 1 answer2019-01-23T10:57:04Z2019-03-06T12:44:08ZTrue
MDU6SXNzdWU0MDI1MDU4NDk=The code format of run_classifier.py is in a mess.. why not reformat it?2019-01-24T01:44:18Z2019-02-02T11:24:12ZTrue
MDU6SXNzdWU0MDI1MTU3NDY=fine-tuning bert large uncased_L-24_H-1024_A-16 got checkpoint restoring error2019-01-24T02:33:33Z2019-01-25T02:02:24ZTrue
MDU6SXNzdWU0MDI1NDMzNjY="Can I use a ""[CLS]...[SEP]...[SEP]...[SEP]""  in tokens?"2019-01-24T04:59:33ZFalse
MDU6SXNzdWU0MDI1OTA2ODA=How to use my own additional vocabulary dictionary?2019-01-24T08:21:46ZFalse
MDU6SXNzdWU0MDI5NTA1MDk=Scaling extract_features2019-01-25T00:09:22ZFalse
MDU6SXNzdWU0MDMzOTU3OTA=Does training_batch_size affect model accuracy when fine-tuning?2019-01-26T02:28:04ZFalse
MDU6SXNzdWU0MDM0MTgwMjE=Different result of evaluation2019-01-26T07:54:57ZFalse
MDU6SXNzdWU0MDM0NDI3ODM=What is the result if we do not pretrain?2019-01-26T13:41:43Z2019-11-14T04:03:39ZTrue
MDU6SXNzdWU0MDM3OTE1Mjk=Input preprocessing2019-01-28T12:30:50ZFalse
MDU6SXNzdWU0MDM5MTAzNzg=Can't retrain with different models in colab BERT FineTuning with Cloud TPU: Sentence and Sentence-Pair Classification Tasks2019-01-28T16:55:11ZFalse
MDU6SXNzdWU0MDQxNTYyNDA=add a special token to never_split tuples2019-01-29T07:27:40Z2019-01-30T04:48:18ZTrue
MDU6SXNzdWU0MDQzMzg0MDI=Anyone could share the checkpoint of a trained bert-large model for SQuAD 1.0?2019-01-29T15:13:16ZFalse
MDU6SXNzdWU0MDQ2MDM0Mzg=How can I change vocab size for pretrained model?2019-01-30T05:03:35ZFalse
MDU6SXNzdWU0MDQ4ODYzNDc=Typo in params of model_fn_builder2019-01-30T17:42:11ZFalse
MDU6SXNzdWU0MDU2MDk5NTY=can't use the trained check points to retrain on different data set2019-02-01T09:03:02ZFalse
MDU6SXNzdWU0MDU3NzY4NjY=Using BERT with custom QA dataset2019-02-01T16:31:27ZFalse
MDU6SXNzdWU0MDU3OTg3NTI=How to extract the word embedding parameters from the pretrained files?2019-02-01T17:27:15ZFalse
MDU6SXNzdWU0MDYwNTkwMTE=Fine tuning Bert for Question answering2019-02-03T06:42:06Z2019-02-12T07:09:39ZTrue
MDU6SXNzdWU0MDY1OTc4MDU=Is Abstract summary 2019-02-05T01:47:42Z2019-02-05T01:57:08ZTrue
MDU6SXNzdWU0MDY1OTkyNDY=Is Abstract Summary Possible on Only Encoder Model like BERT?2019-02-05T01:55:32ZFalse
MDU6SXNzdWU0MDY5NTc5NDg=BERT SQuAD 2 fails on specific types of questions - Found New Info...2019-02-05T20:20:28ZFalse
MDU6SXNzdWU0MDczMzA2Nzk=Can one expand the vocabulary for fine-tuning by replacing foreign unicode characters?2019-02-06T16:51:57ZFalse
MDU6SXNzdWU0MDc1NDc2NDA=run_classifier_with_tfhub.py not found2019-02-07T05:29:49Z2019-02-08T16:35:22ZTrue
MDU6SXNzdWU0MDc2ODI0Njc=Intent prediction from conversation history2019-02-07T12:45:12ZFalse
MDU6SXNzdWU0MDc4MzIzNTU=Limitations on NLP using BERT2019-02-07T18:18:18ZFalse
MDU6SXNzdWU0MDgyMjkzMDA=No Hub in tf HUB.2019-02-08T16:33:50Z2019-02-08T16:35:59ZTrue
MDU6SXNzdWU0MDg0ODkwMTQ=How to integrate bert into a different model?2019-02-10T01:15:20Z2019-02-14T19:32:09ZTrue
MDU6SXNzdWU0MDg1Njk4NDY=What is exactly the learning rate warmup described in the paper?2019-02-10T19:33:40Z2019-02-18T10:10:28ZTrue
MDU6SXNzdWU0MDg2NDY3OTQ=inference time on CPU take so long2019-02-11T06:14:30ZFalse
MDU6SXNzdWU0MDg5Nzg1NjQ=When pretraining, what was the accuracy of the masked-LM task?2019-02-11T21:12:36ZFalse
MDU6SXNzdWU0MDk1ODE4NDY=ValueError: Cannot create a tensor proto whose content is larger than 2GB.2019-02-13T01:34:11ZFalse
MDU6SXNzdWU0MDk1OTkwMTA=Issue on running the tf_hub (sentiment analysis) example which is on colab2019-02-13T02:46:33Z2019-02-13T06:24:36ZTrue
MDU6SXNzdWU0MDk2Nzk3NjM=ModuleNotFoundError: No module named 'modeling'2019-02-13T08:20:03Z2019-02-13T17:16:31ZTrue
MDU6SXNzdWU0MTAxNDc3NTE=TypeError: batch() got an unexpected keyword argument 'drop_remainder'2019-02-14T06:26:32ZFalse
MDU6SXNzdWU0MTAyMDE5NjY=Always blank answer after v2.0 fine tuning training2019-02-14T09:20:56ZFalse
MDU6SXNzdWU0MTA2MzI1OTA=how to use bert to classifing text after had fine-tuning2019-02-15T07:02:51ZFalse
MDU6SXNzdWU0MTA2NzIyODg=Clarification of document for BookCorpus2019-02-15T09:15:29ZFalse
MDU6SXNzdWU0MTA3NDE0Nzg=QA system architecture (inference)2019-02-15T12:10:22ZFalse
MDU6SXNzdWU0MTEwMjI3NzY=How can I use BERT to train on translation task?2019-02-16T03:59:10ZFalse
MDU6SXNzdWU0MTEwNzQzNTA=Any one tried to use these model to write next sentence ?2019-02-16T13:47:26ZFalse
MDU6SXNzdWU0MTExODc5NTY=How to use the QA model to do single prediction?2019-02-17T13:31:14Z2019-04-11T08:41:08ZTrue
MDU6SXNzdWU0MTE3OTM1MTE=SQUAD 2.0 error while saving checkpoint.2019-02-19T08:04:17ZFalse
MDU6SXNzdWU0MTE4MjQ3MDQ=How to synchronize the tf.IndexedSlices? 2019-02-19T09:26:44ZFalse
MDU6SXNzdWU0MTIwNzgyODc=Wiki Chinese dump preprocessing: #lines not matching2019-02-19T19:06:25Z2019-02-20T00:28:43ZTrue
MDU6SXNzdWU0MTI4NDgwMDY=Fine-Tune encodings on unsupervised data?2019-02-21T10:18:13ZFalse
MDU6SXNzdWU0MTM0NDExOTg=Issue with multiclass text classification2019-02-22T14:59:51Z2019-02-22T15:30:28ZTrue
MDU6SXNzdWU0MTM3MDQ1Njg=run_squad.py only seems to use one cpu (and ignore the GPU)2019-02-23T15:09:46Z2019-03-04T14:16:17ZTrue
MDU6SXNzdWU0MTM3NDk2Mjk=Different accuracy when predicting the dev set with do_predict2019-02-23T22:27:42Z2019-03-05T06:56:41ZTrue
MDU6SXNzdWU0MTM3ODY1NTY=What is is_impossible for run_squad.py ?2019-02-24T06:10:24Z2019-02-25T12:16:29ZTrue
MDU6SXNzdWU0MTM5MDEzMTQ=How to specify max_to_keep in TPUEstimator?2019-02-25T01:55:44Z2019-02-25T03:31:01ZTrue
MDU6SXNzdWU0MTQyMzM0NjA=module 'tensorflow.python.platform.flags' has no attribute 'mark_flag_as_required'2019-02-25T18:02:56Z2019-02-25T18:09:38ZTrue
MDU6SXNzdWU0MTQ2MTgxNTY=Predicting Movie Reviews with BERT - IndexError: tuple index out of range2019-02-26T13:44:26Z2019-04-06T08:45:15ZTrue
MDU6SXNzdWU0MTUxNjg3MDQ=How is BERT able to do zero shot transfer on XNLI dataset?2019-02-27T15:02:10ZFalse
MDU6SXNzdWU0MTUzODU4MjM=function embedding_lookup in modeling.py have conflict comments2019-02-28T00:10:24ZFalse
MDU6SXNzdWU0MTU0NjQ3Mjg=Suspicious misuse of args in truncate_seq in create_pretraining_data2019-02-28T06:16:56ZFalse
MDU6SXNzdWU0MTU1MDM4MjQ=Can BERT do the next-word-predict task? As it is bidirectional.2019-02-28T08:32:28Z2019-03-01T02:05:46ZTrue
MDU6SXNzdWU0MTU1MjUwNjc=Reduce prediction time for question answering 2019-02-28T09:28:09ZFalse
MDU6SXNzdWU0MTU3MDE2NDA=BERT regression gives me same scores2019-02-28T16:10:10ZFalse
MDU6SXNzdWU0MTU5MDgzOTg=Activation function make something worse?2019-03-01T02:11:09ZFalse
MDU6SXNzdWU0MTU5MTg5ODk=Can I use Low-level TF APIs to fine-tuning bert for my task? Do I have to use Estimators?2019-03-01T03:00:37Z2019-03-01T09:58:38ZTrue
MDU6SXNzdWU0MTYwMzQ0MTU=gs://cloud-tpu-checkpoints/bert update2019-03-01T10:20:43ZFalse
MDU6SXNzdWU0MTYxOTMxOTA=What dataset is used in Bert to pre-train non-english locale encoding?2019-03-01T16:59:17Z2019-03-01T18:29:04ZTrue
MDU6SXNzdWU0MTYzNzI0MjA=How does best_f1_thresh work in evalutate?2019-03-02T08:04:20ZFalse
MDU6SXNzdWU0MTYzNzYyOTA=InvalidArgumentError, Found Inf or NaN global norm.2019-03-02T08:55:06ZFalse
MDU6SXNzdWU0MTY0NjU2NzU=export fine-tuned  bert model from colab and run locally2019-03-03T02:20:09ZFalse
MDU6SXNzdWU0MTY2NDQ0ODI=IMDB classification2019-03-04T06:01:35Z2019-03-04T06:13:28ZTrue
MDU6SXNzdWU0MTY4NTM5NTM=When trying to reproduce results for QQP the trained classifier always predicts one of the two classes.2019-03-04T15:25:19ZFalse
MDU6SXNzdWU0MTcwNzAzNDA=Crash issue when best_non_null_entry is None on SQuAD 2.02019-03-05T01:26:38ZFalse
MDU6SXNzdWU0MTcxNDk5OTU=Why the attention mask of `from_tensor` is not used?2019-03-05T07:11:09ZFalse
MDU6SXNzdWU0MTc1NDUwOTQ=Tensor wrong shape (swag)2019-03-05T23:11:21Z2019-03-07T17:52:03ZTrue
MDU6SXNzdWU0MTc1OTIwODU=Trying to run SQuAD with accumulated gradients but get killed automatically2019-03-06T02:25:07Z2019-03-07T09:53:33ZTrue
MDU6SXNzdWU0MTc3MjIwNTY=Little training has no impact2019-03-06T10:10:33ZFalse
MDU6SXNzdWU0MTc3ODM5ODQ=Unable to incrementally train BERT with custom training2019-03-06T12:41:25ZFalse
MDU6SXNzdWU0MTgxODA2NTQ=Replacing positional embedding with pre-calculated results in BERT leads to poor prediction result2019-03-07T08:16:07ZFalse
MDU6SXNzdWU0MTg0MDQ3NTc=Log learning rate to tensorboard summaries2019-03-07T16:37:19ZFalse
MDU6SXNzdWU0MTg2MjA4OTk=[REQUEST, SUGGESTION] BERT with TF 2.02019-03-08T03:54:41ZFalse
MDU6SXNzdWU0MTg2NTgxMTQ=Error recorded from infeed: End of sequence2019-03-08T06:58:26ZFalse
MDU6SXNzdWU0MTg4Mzc2Mjc=BERT Sentence Classification Error: Read less bytes than requested2019-03-08T15:36:45Z2019-05-01T07:47:02ZTrue
MDU6SXNzdWU0MTkwNzc5MDI=what is the synthetic self-training2019-03-09T14:38:01ZFalse
MDU6SXNzdWU0MTkxMzg1MzM=Separator token for custom QA input (multi paragraph, longer than 512)2019-03-10T02:34:34ZFalse
MDU6SXNzdWU0MTkxNzA4NTc=question: not binary but score2019-03-10T10:35:46ZFalse
MDU6SXNzdWU0MTkxODkxNzQ="Is it possible to replicate the results on XNLI dataset which are present on ""Multilingual README"" page  ?"2019-03-10T14:00:24ZFalse
MDU6SXNzdWU0MTk0NTM3NDI=BERT accuracy reduced after providing custom training..The answer is also not correct2019-03-11T12:53:15ZFalse
MDU6SXNzdWU0MTk4OTIyOTU=Sensitive content detection using BERT2019-03-12T09:51:36ZFalse
MDU6SXNzdWU0MjAwNDcyODI=How to test QA model using own input? (Single prediction question)2019-03-12T15:22:29Z2019-03-12T18:19:11ZTrue
MDU6SXNzdWU0MjAxOTA2NTI=Splitting context and question for BERT2019-03-12T20:28:46ZFalse
MDU6SXNzdWU0MjAyMzg1ODc=Bert tf.Hub module not suitable for serving2019-03-12T22:44:13ZFalse
MDU6SXNzdWU0MjAzMTk3OTI=xnli fin-tunining downlink invalid2019-03-13T05:09:14Z2019-07-19T08:25:38ZTrue
MDU6SXNzdWU0MjAzNTUyMjg=Custom Domain Training2019-03-13T07:33:51ZFalse
MDU6SXNzdWU0MjA5ODE1Mjk=Bert movie review - prediction's on same record are changing widely for each run2019-03-14T12:05:50ZFalse
MDU6SXNzdWU0MjExNzk0Nzg=Poor performance on squad 2 evaluation performed outside of the GPU(s)2019-03-14T18:29:21Z2019-06-04T19:36:44ZTrue
MDU6SXNzdWU0MjIwMTIyMTE=Is this piece of code in function 'transformer_model' useless?2019-03-18T02:34:23ZFalse
MDU6SXNzdWU0MjIxMDAyMzc=Pre-trained monolingual in French2019-03-18T08:53:29ZFalse
MDU6SXNzdWU0MjI4NzIwMzU=How to share BERT between tasks in multi-task setting?2019-03-19T17:52:54ZFalse
MDU6SXNzdWU0MjMwNjI0ODk=Reproduce the results on CoLA and STS-B2019-03-20T04:34:55ZFalse
MDU6SXNzdWU0MjMyMzI3NDc=Bert fine tuning for MCQ style reading comprehension tasks?2019-03-20T12:47:35ZFalse
MDU6SXNzdWU0MjM0NjkyNTM=Are BERT word-embeddings capable of synonyms?2019-03-20T20:58:12ZFalse
MDU6SXNzdWU0MjM2MTY2MzA=how to make bert model to read examples and fine-tune together2019-03-21T08:32:16ZFalse
MDU6SXNzdWU0MjM2MTY2NjQ=Error recorded from training_loop: Found Inf or NaN global norm. : Tensor had NaN values2019-03-21T08:32:22Z2019-05-12T05:27:33ZTrue
MDU6SXNzdWU0MjM2NzE4NTc=Questions on BERT Tensorflow Hub module2019-03-21T10:56:01ZFalse
MDU6SXNzdWU0MjM4MTAyMDQ=Best performance on concatenated layers: which dimension?2019-03-21T16:01:23Z2019-03-22T10:55:15ZTrue
MDU6SXNzdWU0MjQwMDQ1NDM=About load pretrain model 2019-03-22T01:05:20ZFalse
MDU6SXNzdWU0MjQzNDUyNTE=Is BERT a kind of cheating?2019-03-22T18:29:30ZFalse
MDU6SXNzdWU0MjQzNDgxMzg=Is there a larger unreleased BERT model?2019-03-22T18:37:19ZFalse
MDU6SXNzdWU0MjQ1MDM0NzA=What is suitable max_predictions_per_seq size when max_seq_length set to 512?2019-03-23T13:59:29ZFalse
MDU6SXNzdWU0MjQ2MDA5NzU=Colab TPU Timeoute Error on Google Colab2019-03-24T11:14:01ZFalse
MDU6SXNzdWU0MjQ3NTc5NjA=Dian2019-03-25T07:26:23ZFalse
MDU6SXNzdWU0MjQ4MTM1NjU=how to get embeddings after running run_pretraining.py code2019-03-25T10:01:36ZFalse
MDU6SXNzdWU0MjQ4NjgyNjA=Squad_prediction2019-03-25T12:10:24ZFalse
MDU6SXNzdWU0MjUyMTI5MjE=Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary2019-03-26T03:45:06ZFalse
MDU6SXNzdWU0MjUyNjc3NzE=How to get the previous layers output of the BERT using tf_hub?2019-03-26T07:40:29Z2020-02-07T12:55:04ZTrue
MDU6SXNzdWU0MjU3MjA1NDI=Return list of RELATED words like word2vec ???2019-03-27T01:30:46ZFalse
MDU6SXNzdWU0MjYzNjY1MzQ=Issue in training BERT base model, steps/sec very low2019-03-28T08:45:09ZFalse
MDU6SXNzdWU0MjY2NDI3NDI=I'm getting key error '2' when i run run_classifier.py 2019-03-28T18:21:11ZFalse
MDU6SXNzdWU0MjY3NzU1ODE=Bert server connection problem2019-03-29T01:34:02ZFalse
MDU6SXNzdWU0MjY4OTg1OTQ=bad results after pretraining2019-03-29T09:39:41ZFalse
MDU6SXNzdWU0MjcyNzEzMTE=Cannot find Synthetic self-training in this repository.2019-03-30T11:05:41ZFalse
MDU6SXNzdWU0Mjc1NjU0MzE=how to generates the vocab.txt file from corpus if I want do pre-training from scratch2019-04-01T08:04:54ZFalse
MDU6SXNzdWU0Mjc2MjA2Njk=Computing the softmax in run_squad.py2019-04-01T10:11:49ZFalse
MDU6SXNzdWU0Mjc2NzI3Nzk=questions about exporting a new tfhub Module2019-04-01T12:18:28ZFalse
MDU6SXNzdWU0MjgwMDAyNTg="shape[0] is ""None"" when eval or predict "2019-04-02T02:59:05ZFalse
MDU6SXNzdWU0MjgwMjk1OTQ=How to use pre-trained word embedding when pre-tranining?2019-04-02T05:22:27ZFalse
MDU6SXNzdWU0MjgwODA4ODU=run_classifier with large data2019-04-02T08:07:08ZFalse
MDU6SXNzdWU0MjgzMzMyMTk=emotion detector && minimum set of training samples2019-04-02T16:43:29ZFalse
MDU6SXNzdWU0MjgzNDQ3ODQ=A question about run_squad.py2019-04-02T17:10:55ZFalse
MDU6SXNzdWU0Mjg2MDA2ODc=How do you train custom corpus with bert? 2019-04-03T07:11:47ZFalse
MDU6SXNzdWU0Mjg5NjgwMTg=How to select a certain hidden layer as token's representation?2019-04-03T20:48:44ZFalse
MDU6SXNzdWU0MjkwNTcwNDY=Fine-tuning bert results in a strange output, what happened?2019-04-04T02:41:43ZFalse
MDU6SXNzdWU0MjkwNjY4MzY=AttributeError: module 'tensorflow.contrib.tpu' has no attribute 'InputPipelineConfig'2019-04-04T03:30:31Z2019-04-04T03:34:52ZTrue
MDU6SXNzdWU0MjkwOTk0ODU=Add QNLI in run_classifier.py 2019-04-04T06:11:27ZFalse
MDU6SXNzdWU0MjkyNTA4MzU=IndexError in run_classifier.py::MrpcProcessor::_create_examples2019-04-04T12:28:23ZFalse
MDU6SXNzdWU0MjkyNTI4MjM=IndexError in run_classifier.py::MrpcProcessor::_create_examples (2)2019-04-04T12:32:57ZFalse
MDU6SXNzdWU0MjkyODc5NzY=Application of DQN Syntax2019-04-04T13:44:36ZFalse
MDU6SXNzdWU0Mjk0MDA5ODM=Optimize input_fn2019-04-04T17:37:01ZFalse
MDU6SXNzdWU0Mjk0MzE2MDk=Reproducing README pre-training results2019-04-04T18:53:43Z2019-04-12T16:59:13ZTrue
MDU6SXNzdWU0Mjk5NTIyOTQ=Cannot import run_classifier_with_tfhub2019-04-05T22:07:09Z2019-04-08T15:43:28ZTrue
MDU6SXNzdWU0Mjk5OTE1MjM=masked_lm_accuracy is low at 0.51, but next_sentence_accuracy is high at 0.932019-04-06T03:11:54Z2019-04-12T03:05:02ZTrue
MDU6SXNzdWU0MzAwMTExNTg=if we only use mask LM in training and disable the'next sentence', how should I modify the create_pretraining_data.py2019-04-06T08:20:00ZFalse
MDU6SXNzdWU0MzAwOTYzMDc=problem multiclass text classification2019-04-07T02:13:04ZFalse
MDU6SXNzdWU0MzAyMzkwMjc=Problem with wordpiece tokenization2019-04-08T03:25:08ZFalse
MDU6SXNzdWU0MzAyNDQ3Nzc=Github project examples with BERT deployed using Swift2019-04-08T03:59:38ZFalse
MDU6SXNzdWU0MzA0NTAxMTY=Extract features of a word given a text2019-04-08T13:25:17ZFalse
MDU6SXNzdWU0MzA1NjI4NzU=accuracy for every checkpoint2019-04-08T17:09:32ZFalse
MDU6SXNzdWU0MzA2OTE0MTU=How to use BERT to predict IsNext/NotNext?2019-04-08T22:48:13ZFalse
MDU6SXNzdWU0MzA3MTU5NzQ=What is BERT?2019-04-09T00:39:53ZFalse
MDU6SXNzdWU0MzA5NTE4MzQ=words from 768 dim output2019-04-09T12:55:39Z2019-04-16T15:16:33ZTrue
MDU6SXNzdWU0MzE1MjY0NzM=How to use BERT for sequence labelling2019-04-10T14:10:26ZFalse
MDU6SXNzdWU0MzE4MDUzMjg=How many articles (Wiki+Book corpus) do Bert use in pretraining?2019-04-11T02:49:02ZFalse
MDU6SXNzdWU0MzE4NDY3NzA=how to use different optimizer other than adam 2019-04-11T06:13:20ZFalse
MDU6SXNzdWU0MzE5MjQyNDA=bert词表vocab.txt中汉语的##表示是什么意思？中文语料在tokenization之后好像从未出现过用##前缀表示的呀2019-04-11T09:34:38Z2019-04-16T11:19:03ZTrue
MDU6SXNzdWU0MzI2OTkxMjI=Which is it?. . . BERT is adding a word at the end or a MASK answer?2019-04-12T18:51:28ZFalse
MDU6SXNzdWU0MzI4MTkxMjI=how to use bert for text generation task like NMT, QA?2019-04-13T07:33:17ZFalse
MDU6SXNzdWU0MzI5NzY2Njk=how to use bert to text summary2019-04-14T13:27:49ZFalse
MDU6SXNzdWU0MzI5Nzg4MTU=BERT multilingual for zero-shot classification2019-04-14T13:44:25ZFalse
MDU6SXNzdWU0MzI5OTc5MjQ=Performance for multi-label classification is so low?2019-04-14T16:12:25Z2019-07-19T07:12:34ZTrue
MDU6SXNzdWU0MzMwMjUzNzE=Why BERT divides a word into 3 not meaningfull parts? Is it a bug?2019-04-14T19:51:14ZFalse
MDU6SXNzdWU0MzMxODEzNDc=Model Hyper Parameters to change after pretraining on the custom dataset2019-04-15T09:27:05Z2019-04-16T10:20:47ZTrue
MDU6SXNzdWU0MzM2MTU1MTc=Reproduce BERT-NER result2019-04-16T07:02:51ZFalse
MDU6SXNzdWU0MzM4MzIzNzk=how to get last 4 layers in classification2019-04-16T15:04:57ZFalse
MDU6SXNzdWU0MzQxNTAyODE=BERT has a non deterministic behaviour2019-04-17T08:15:01ZFalse
MDU6SXNzdWU0MzQxODUzNjc=Predicting Movie Reviews with BERT on TF Hub with tensorflow 2.02019-04-17T09:35:31ZFalse
MDU6SXNzdWU0MzQ2MzM5MzI=Re-using gs://.../train.tf_record2019-04-18T07:44:52ZFalse
MDU6SXNzdWU0MzQ2NzA4ODM=BERT Pretraining Learning Rate Schedule2019-04-18T09:17:56ZFalse
MDU6SXNzdWU0MzQ3MDgzNjg=BERT encode emojis as [UNK] token 2019-04-18T10:50:51ZFalse
MDU6SXNzdWU0MzQ5Njg4Njg=How to I extract embeddings from Bert code (tf v1.13)2019-04-18T21:34:48ZFalse
MDU6SXNzdWU0MzUwMjUyMTA=How to use my own vocabulary when do pre-training from scratch?2019-04-19T02:18:47ZFalse
MDU6SXNzdWU0MzUxMDIxNzA=Can you update the BibTex of the paper?2019-04-19T08:50:22ZFalse
MDU6SXNzdWU0MzUxMzQ0NTg=negative predictions when fine-tuning2019-04-19T10:41:32ZFalse
MDU6SXNzdWU0MzUyNDA5NjU=Word-based Chinese Model2019-04-19T16:59:21ZFalse
MDU6SXNzdWU0MzU0NzE3NzI=Why is the dev data set in run_classifier.py not used for model training?2019-04-21T03:37:50ZFalse
MDU6SXNzdWU0MzU2Mjg3MjQ=how many data does it require to do sentence pair classification task?2019-04-22T07:19:47ZFalse
MDU6SXNzdWU0MzU3MTkyMjM=Token embeddings used for pretraining of bert 2019-04-22T13:03:08ZFalse
MDU6SXNzdWU0MzU3NzU0NTY=Loading MRPC in bert_finetuning_with_cloud_tpus.ipynb fails due to Firebase hosting going over limit2019-04-22T15:46:52ZFalse
MDU6SXNzdWU0MzU5MTA3NDk=Is there a plan to release code for fine-tuning on CoQA dataset?2019-04-22T22:02:03ZFalse
MDU6SXNzdWU0MzczMTUzNDg=BERT Issues with run_squad.py2019-04-25T17:31:41Z2019-05-22T20:26:39ZTrue
MDU6SXNzdWU0MzczNzc4NTU=BERT with Brazilian Portuguese2019-04-25T20:14:07ZFalse
MDU6SXNzdWU0Mzc1MjE3ODE=Using bert for chinese entity recognition, it is very slow．2019-04-26T06:41:39ZFalse
MDU6SXNzdWU0Mzc1MzE1MDU=Please help to resolve this.2019-04-26T07:13:22ZFalse
MDU6SXNzdWU0Mzc2MjY3NzA=How No sentence loss? 2019-04-26T11:22:36ZFalse
MDU6SXNzdWU0Mzc2NDQ2OTQ=How to create two BERT model with shared weights?2019-04-26T12:15:26ZFalse
MDU6SXNzdWU0Mzc3MzY4NjU=How to train our own domain-specific data instead of using pre-training models？2019-04-26T15:50:26ZFalse
MDU6SXNzdWU0Mzc3NDI0NDQ=Suppress tensorflow info log2019-04-26T16:04:22ZFalse
MDU6SXNzdWU0Mzc5OTE3NzA=How to get masked word prediction probabilities2019-04-27T22:52:48ZFalse
MDU6SXNzdWU0MzgwOTQ0Mjk=Order of classes in test_results.tsv2019-04-28T20:03:57ZFalse
MDU6SXNzdWU0MzkwNTYxNDQ=Regarding reproducing the Chinese bert  2019-05-01T03:17:36ZFalse
MDU6SXNzdWU0MzkzNjc4MTE=License of the pretrained models2019-05-01T23:25:05Z2019-05-02T18:38:53ZTrue
MDU6SXNzdWU0Mzk0MDY2MDM=Memory consumption on running create_pretraining_data.py2019-05-02T02:36:18ZFalse
MDU6SXNzdWU0Mzk0MDkwMDg=Trainable BERT Using TPU2019-05-02T02:53:59ZFalse
MDU6SXNzdWU0Mzk0MjM1OTE=how to infer in python 2019-05-02T04:32:53Z2019-07-22T04:41:57ZTrue
MDU6SXNzdWU0Mzk1NDUyODI=BERT pre-training using only domain specific text2019-05-02T11:34:10ZFalse
MDU6SXNzdWU0Mzk5MTE4MDg=650M corpus was splited to 40 files pass to create_pretraining_data, but it takes too long time2019-05-03T06:55:00Z2019-05-04T01:02:28ZTrue
MDU6SXNzdWU0NDAwMzEwOTM=Access middle layers with tensorflow hub2019-05-03T12:50:00ZFalse
MDU6SXNzdWU0NDAwMzkzNzY=tensorflow.python.framework.errors_impl.InvalidArgumentError:2019-05-03T13:12:09Z2019-05-03T13:13:07ZTrue
MDU6SXNzdWU0NDAxMDcyMjI=Pretrained Chinese language model - single CJK character wordpiece in vocab file not necessary?2019-05-03T15:49:38ZFalse
MDU6SXNzdWU0NDAyNTkzOTk=Bert Context Based QA2019-05-03T23:41:04Z2019-05-17T17:47:41ZTrue
MDU6SXNzdWU0NDAyOTgzNTk=Fine Tuning + Extracting Features for Custom Dataset2019-05-04T08:14:43ZFalse
MDU6SXNzdWU0NDAzNjQ3NDk="How to use Tensorboard to plot loss on Colab ""TPU""(TPUEstimator) with this repo."2019-05-04T19:59:00ZFalse
MDU6SXNzdWU0NDA0MjU0MDA=error when running bert on GCP with tpu2019-05-05T09:52:38Z2019-05-08T11:46:46ZTrue
MDU6SXNzdWU0NDA3MzUxNDE=Pretraining a PyTorch model of BERT2019-05-06T14:44:12Z2019-05-06T15:04:11ZTrue
MDU6SXNzdWU0NDEwMjk4NDg=Can the use of [SEP] reduce the information extraction between the sentences?2019-05-07T05:08:59Z2019-05-20T00:06:32ZTrue
MDU6SXNzdWU0NDE0MzI4OTI=Bert with Cloud Dataflow2019-05-07T20:31:34ZFalse
MDU6SXNzdWU0NDE2Mjc2MjU=BUG: 'truncate_seq_pair' 2019-05-08T09:03:15ZFalse
MDU6SXNzdWU0NDE5ODI2NzI=Not able to run BERT-Large with either SQuAD 2.0/SQuAD 1.1 on GCP with TPU2019-05-08T23:14:09Z2019-05-17T15:13:34ZTrue
MDU6SXNzdWU0NDIwMjMyMTg=Really well commented code. thank you!2019-05-09T02:39:59Z2019-05-09T02:40:02ZTrue
MDU6SXNzdWU0NDIwMzAzNjc=word piece tokenization2019-05-09T03:16:21ZFalse
MDU6SXNzdWU0NDIwNTYxMDA=Train with bert_multi_cased OOM error, but works with bert_cased2019-05-09T05:30:30ZFalse
MDU6SXNzdWU0NDIxMDIxMTQ=How do I continue training from checkpoint?2019-05-09T08:01:25Z2019-05-10T06:00:36ZTrue
MDU6SXNzdWU0NDIxMTQxMjI=Is multilingual model cross-lingual?2019-05-09T08:30:12Z2019-06-04T08:04:10ZTrue
MDU6SXNzdWU0NDIyMDE1MzI="Is the ""Prediction from classifier"" run on GPU?"2019-05-09T12:04:50ZFalse
MDU6SXNzdWU0NDIzOTk0MzE=Padding sent1 hurts the performance of sentence pair tasks2019-05-09T19:38:48Z2019-05-10T09:41:34ZTrue
MDU6SXNzdWU0NDI4MzMzOTA=How often is the validation/evaluation performed? (fine-tuning using run_classifier.py)2019-05-10T18:01:21ZFalse
MDU6SXNzdWU0NDI5MDE4Njk=How to freeze layers of bert?2019-05-10T21:31:17ZFalse
MDU6SXNzdWU0NDMwNDczMDY=module 'tokenization' has no attribute 'FullTokenizer'2019-05-11T23:52:43Z2019-05-12T02:43:18ZTrue
MDU6SXNzdWU0NDMxMTU5Njk=Classification fine tuning for Q & A 2019-05-12T15:22:36ZFalse
MDU6SXNzdWU0NDMyMTUyMTY=How could BERT-Large fit into TPUs?2019-05-13T05:46:01Z2019-05-20T03:26:28ZTrue
MDU6SXNzdWU0NDM0ODgwOTQ=Language dependent vocabulary?2019-05-13T16:19:30ZFalse
MDU6SXNzdWU0NDM4NTI0Mjk=difference between bert and GPT on finetuning dataset STS-B2019-05-14T11:07:37ZFalse
MDU6SXNzdWU0NDM4ODAyMDg=Recommended GPU size when training BERT-base2019-05-14T12:13:42ZFalse
MDU6SXNzdWU0NDM5MTUzODA=How to handle labels when using the BERT wordpiece tokenizer2019-05-14T13:27:34ZFalse
MDU6SXNzdWU0NDQwODQ4NTA=taking 30 seconds to run on a 25k doc, how can I increase performance2019-05-14T19:26:47ZFalse
MDU6SXNzdWU0NDQyNjE0Nzg=how to use BERT for Siamese Model paraphrase identify2019-05-15T06:37:50ZFalse
MDU6SXNzdWU0NDQyNjMyODE=Learning Rate and Warmup Steps2019-05-15T06:43:24ZFalse
MDU6SXNzdWU0NDQ0OTk1NzQ=Using bert for Document Classification2019-05-15T15:19:20ZFalse
MDU6SXNzdWU0NDQ5MjIzNDY=Losing Knowledge for Language Model in Fine-Tuning2019-05-16T12:17:36ZFalse
MDU6SXNzdWU0NDUyMjk5MTE=Does label list need to be sorted?2019-05-17T01:58:01ZFalse
MDU6SXNzdWU0NDUyMzA5MzA=When will bert with tensorflow2.0 be updated?2019-05-17T02:02:58ZFalse
MDU6SXNzdWU0NDUyNDkzMjM=Reshape free BERT model?2019-05-17T03:32:58ZFalse
MDU6SXNzdWU0NDU5MTIxNTg=Unable to run Squad dataset on BERT -permission issues2019-05-20T03:53:32ZFalse
MDU6SXNzdWU0NDU5ODc5NjA=How is the number of BERT model parameters calculated?2019-05-20T08:33:13ZFalse
MDU6SXNzdWU0NDY0ODE5NDY=How to use run_squad.py to produce multiple answers for a question?2019-05-21T08:23:37ZFalse
MDU6SXNzdWU0NDY1NDEzMTU=run convert_examples_to_features on multiple cores2019-05-21T10:29:51ZFalse
MDU6SXNzdWU0NDY5MDQyMzA=very lower EM ,F1 score2019-05-22T02:31:28ZFalse
MDU6SXNzdWU0NDY5NjAxMTc=training process become slower after freezing layers2019-05-22T06:46:25ZFalse
MDU6SXNzdWU0NDcxNjUzMjA=how to close the acculmulation of Batch Normalization in the tf hub mode?2019-05-22T14:19:00ZFalse
MDU6SXNzdWU0NDc1MzM5Njc=Determining training steps2019-05-23T09:06:28ZFalse
MDU6SXNzdWU0NDc4Mjg1NTg=Tuned Bert Model on MRPC gives wrong predictions.2019-05-23T19:12:51ZFalse
MDU6SXNzdWU0NDg0Mzg0MzM=how does repeat help with parallel reading during training in run_classifier.py?2019-05-25T08:26:13ZFalse
MDU6SXNzdWU0NDg1Mzc2NDU=Why was use_one_hot_embeddings set to FLAG.use_tpu in line 855 in run_classifier.py ?2019-05-26T07:25:27ZFalse
MDU6SXNzdWU0NDkzNTAxNzI=BertForPreTraining predicts the masked token with ZERO accuracy.2019-05-28T15:55:52ZFalse
MDU6SXNzdWU0NTAyNzE2MzQ=Training BERT on v2-8 TPU Google Cloud - Allocation of 93763584 exceeds 10% of system memory.2019-05-30T11:59:48Z2019-05-31T15:00:54ZTrue
MDU6SXNzdWU0NTA4MDIwMzE=Bert for document similarity2019-05-31T13:34:08ZFalse
MDU6SXNzdWU0NTE0MzUwMDg=Inconsistency of output features from estimator.predict() in extract_features.py and sess.run(model.get_sequence_output()) 2019-06-03T11:39:10ZFalse
MDU6SXNzdWU0NTE1NTQwNTI=Bert with ner -> run_classifier2019-06-03T15:40:08Z2019-06-12T10:07:31ZTrue
MDU6SXNzdWU0NTE4MDM5NTU=How to add learning rate into tensorboard?2019-06-04T05:26:10ZFalse
MDU6SXNzdWU0NTE4MTAzNjg=Not compatible with tensorflow 2.02019-06-04T05:55:20Z2019-06-16T06:42:41ZTrue
MDU6SXNzdWU0NTIyMTMzNDc=Performance on cpu+gpu host for run_squad: only 1 CPU used for CPU part; only 1 GPU for GPU part2019-06-04T21:20:09Z2019-06-19T13:13:02ZTrue
MDU6SXNzdWU0NTIzNTk5NDE=Clarify whole word models for BERT-Base2019-06-05T07:50:31ZFalse
MDU6SXNzdWU0NTI2MzYyNzU=Easiest way to serve fine-tuned bert model?2019-06-05T17:53:23ZFalse
MDU6SXNzdWU0NTI3ODU3MzU=Tutorial: A Pipeline Of Pretraining Bert On Google TPU2019-06-06T01:16:00ZFalse
MDU6SXNzdWU0NTI4MTk0MTk=Can Bert be fine-tuned on unlabeled data?2019-06-06T03:54:28Z2019-06-06T08:24:37ZTrue
MDU6SXNzdWU0NTMwOTIwNTY=BERT Feature Extraction on TPU: ValueError: `train_batch_size` cannot be `None`2019-06-06T15:19:19ZFalse
MDU6SXNzdWU0NTMzODU4MTE=How to classify neutral sentiments using BERT.2019-06-07T07:57:25ZFalse
MDU6SXNzdWU0NTM0NTEzMTQ=Low F1 score on squad v1.1 even with low fine-tuning loss2019-06-07T10:46:00ZFalse
MDU6SXNzdWU0NTM3NjA3MzA=Cannot Find Synthetic Self-Training in this repository.(Reposted)2019-06-08T06:02:18ZFalse
MDU6SXNzdWU0NTM4ODcwNjc=Performance with TPU vs Pytorch( GPU P100)2019-06-09T11:06:26ZFalse
MDU6SXNzdWU0NTQxMzkxNTg=Getting same probability of labels in all the test set examples2019-06-10T12:09:47Z2019-06-12T13:32:13ZTrue
MDU6SXNzdWU0NTQ0NDQ3NzQ=Why not use a more powerful tokenizer here2019-06-11T01:57:36ZFalse
MDU6SXNzdWU0NTUxNjY5OTA=Very different testing result each time with everything unchanged 2019-06-12T11:47:41ZFalse
MDU6SXNzdWU0NTU1NDIzODA=Interpretation of fine tuning output2019-06-13T05:32:41Z2019-06-25T18:39:32ZTrue
MDU6SXNzdWU0NTU1ODEwMzk=12019-06-13T07:34:52Z2019-06-13T07:38:40ZTrue
MDU6SXNzdWU0NTU2NDIyMTg=End to End (Fine-tuning + Predicting) with Cloud TPU has issu2019-06-13T09:47:46ZFalse
MDU6SXNzdWU0NTU2NTIyMjE=Relevance of BERT for NMT2019-06-13T10:08:41ZFalse
MDU6SXNzdWU0NTY1MzA1MjE=(0) Not found: Key output_bias not found in checkpoint (Restoring a self pre-trained model)2019-06-15T11:55:48ZFalse
MDU6SXNzdWU0NTY2OTc4ODQ=Eval results 2019-06-17T00:19:21ZFalse
MDU6SXNzdWU0NTY3NzQwNDU=How to strip a finetune model to pretrain model?2019-06-17T07:01:21ZFalse
MDU6SXNzdWU0NTY4OTMxNjg=$BERT_DIR\bert_config.json could not be found2019-06-17T11:53:36Z2019-06-20T04:28:10ZTrue
MDU6SXNzdWU0NTc0MTY5NjM=ValueError: For training, each question should have exactly 1 answer.2019-06-18T11:29:20Z2019-06-20T04:25:47ZTrue
MDU6SXNzdWU0NTc0NzE0MTI=Assign requires shapes of both tensors to match. lhs shape= [3072] rhs shape= [4096]2019-06-18T13:07:36ZFalse
MDU6SXNzdWU0NTc2MTc3OTE=upload the new Whole Word Masking pretrained models to Tensorflow Hub?2019-06-18T17:56:34ZFalse
MDU6SXNzdWU0NTc3NDExNDg=Why reshape here?2019-06-18T23:35:20Z2019-07-03T15:12:21ZTrue
MDU6SXNzdWU0NTc4MjUwMDk=Couldn't train BERT with SQUAD 1.12019-06-19T06:13:50Z2019-06-20T04:27:15ZTrue
MDU6SXNzdWU0NTc5NjU0OTQ=Minor clarifications2019-06-19T11:46:16Z2019-06-20T12:10:08ZTrue
MDU6SXNzdWU0NTg2NzEyODE=bert_large is inaccurate compared to bert_base2019-06-20T13:51:07ZFalse
MDU6SXNzdWU0NTkwODQ2MDc=TPU Training tf_hub model crashes2019-06-21T08:46:15ZFalse
MDU6SXNzdWU0NTk0MjY1MzQ=Accuracy of fine-tuning BERT varied significantly based on epochs for intent classification task2019-06-22T03:17:34ZFalse
MDU6SXNzdWU0NTk0NjU3MjQ=Training on custom dataset2019-06-22T11:38:56ZFalse
MDU6SXNzdWU0NTk2ODY4MjY=how to fine tune bert for ner on custom data?2019-06-24T04:52:40ZFalse
MDU6SXNzdWU0NTk3MTc5NzA=handle empty string in sentence pairs2019-06-24T06:47:55ZFalse
MDU6SXNzdWU0NTk4NjcxOTE=BERT fine-tuned with SQUAD 2.0 takes long time to generate perdictions.json file in CPU?2019-06-24T12:37:17ZFalse
MDU6SXNzdWU0NjAxODEyMDU=How to run prediction on text classification task on GPU2019-06-25T02:46:52Z2019-07-10T01:09:05ZTrue
MDU6SXNzdWU0NjA3OTExMTE=" File ""run_classifier.py"", line 326, in _create_examples     text_b = tokenization.convert_to_unicode(line[4]) IndexError: list index out of range"2019-06-26T06:46:03ZFalse
MDU6SXNzdWU0NjA4MDM1NDU=Old multilingual model2019-06-26T07:21:02ZFalse
MDU6SXNzdWU0NjEwOTE2NDA=ValueError: Tensor not found in checkpoint2019-06-26T17:22:20Z2019-06-28T14:35:09ZTrue
MDU6SXNzdWU0NjEyNDUyMjQ=Expected train time on Cloud TPUv32019-06-27T00:42:02ZFalse
MDU6SXNzdWU0NjEyNjQ2OTQ=XNLI multilingual task2019-06-27T01:54:57ZFalse
MDU6SXNzdWU0NjEyNzc1NDk=Pretraining statistics2019-06-27T02:56:03ZFalse
MDU6SXNzdWU0NjEzNTM2OTI=Error when running run_classifier.py 2019-06-27T07:03:28Z2019-06-27T07:23:23ZTrue
MDU6SXNzdWU0NjEzNzc0NTk=how to view the prediction result of each sample？2019-06-27T08:01:21ZFalse
MDU6SXNzdWU0NjE1MDA1MTg=Cannot use trained BERT model from a trained checkpoint2019-06-27T12:29:11Z2019-07-08T11:15:43ZTrue
MDU6SXNzdWU0NjE4NDA4MDA=Can BERT be used for Natural Language Correction? If so, how?2019-06-28T03:42:35ZFalse
MDU6SXNzdWU0NjE5NTAxNTk=Is `drop_remainder=True` when evaluating ? the code may have a bug?2019-06-28T09:42:56ZFalse
MDU6SXNzdWU0NjIwMDMzNTM=How to GIT pull latest BERT code2019-06-28T12:07:54Z2019-06-30T18:32:35ZTrue
MDU6SXNzdWU0NjI0NzY1MzE=gpu_memory_fraction  config not work with predictor.from_estimator2019-07-01T01:56:10ZFalse
MDU6SXNzdWU0NjI2MTk2NzI=When I run run_classifier.py, is BERT fine-tuning the whole BERT model or it's just training the last output full-connected NN?2019-07-01T09:50:33ZFalse
MDU6SXNzdWU0NjI3NDQ5OTg=How BERT run_squad predictions and nbest_predictions are written?2019-07-01T14:25:11ZFalse
MDU6SXNzdWU0NjMxNTUxODQ=is there a way to add tensorflow layers API on the Bert embedding2019-07-02T10:41:54ZFalse
MDU6SXNzdWU0NjM1MjE0MzU=GPU vs CPU2019-07-03T03:07:27ZFalse
MDU6SXNzdWU0NjM2NjkzNjM= multi-gpu horovod2019-07-03T10:19:52ZFalse
MDU6SXNzdWU0NjM3NjQ0NTc=Two fields for sentence classification2019-07-03T13:49:22ZFalse
MDU6SXNzdWU0NjM4MDA0MTg=Mixing of Languages during Multilingual Pretraining2019-07-03T14:54:55ZFalse
MDU6SXNzdWU0NjM4MTQ0OTI=Bert pre-training loss convergence2019-07-03T15:21:04ZFalse
MDU6SXNzdWU0NjQwODE1NzI=Instructions for exporting TFHub Module2019-07-04T06:14:32ZFalse
MDU6SXNzdWU0NjQyMDI1NTU=Sentiment analysis on emoji data.2019-07-04T10:55:55ZFalse
MDU6SXNzdWU0NjQ4MTkzNjM=How much loss is optimum for good model and when to stop training2019-07-06T05:19:47ZFalse
MDU6SXNzdWU0NjQ4MjgyMTE=Creating training set from Wikipedia data?2019-07-06T07:36:38ZFalse
MDU6SXNzdWU0NjUwOTQyNTQ=Large amount of text (5MB) in context takes a lot of time for conversion when run_squad.py is executed2019-07-08T07:17:08ZFalse
MDU6SXNzdWU0NjUzMzM3ODE=tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Key: masked_lm_weights.  Can't parse serialized Example.2019-07-08T15:49:58ZFalse
MDU6SXNzdWU0NjU4NDc0MDM=CPU usage for prediction tasks2019-07-09T15:28:06ZFalse
MDU6SXNzdWU0NjU4NDgzNzQ=GPU usage for prediction tasks2019-07-09T15:29:48Z2019-08-22T14:58:23ZTrue
MDU6SXNzdWU0NjY1OTg3MDI=Serving fine-tuned Model - best solution2019-07-11T00:53:07ZFalse
MDU6SXNzdWU0NjY3MzYwNjE=The cache problem of BERT2019-07-11T08:16:40ZFalse
MDU6SXNzdWU0NjY4MDU3MDE=Errors with pre-training in BERT2019-07-11T10:26:28ZFalse
MDU6SXNzdWU0Njc1NTA4NzM=Exporting probabilities over the learned vocabulary2019-07-12T18:44:11Z2019-07-16T15:32:33ZTrue
MDU6SXNzdWU0Njc1NzQzNjI=Docs: Very wrong assertion that Wikipedia size correlates with number of speakers2019-07-12T19:49:04Z2019-07-16T01:40:26ZTrue
MDU6SXNzdWU0Njc2MzQ0OTM=How to use BERT for ranking with Pairwise loss function during Finetuining2019-07-12T23:24:05ZFalse
MDU6SXNzdWU0NjgzOTg4OTg=WordPiece Tokenizer Clarification2019-07-16T01:10:36ZFalse
MDU6SXNzdWU0Njg1Mzc3Njc=Negative Probabilities for sentiment classification2019-07-16T09:11:25Z2019-07-26T09:30:11ZTrue
MDU6SXNzdWU0Njg1Njc3OTA=How is the multilingual model being trained?2019-07-16T10:12:29ZFalse
MDU6SXNzdWU0Njg2NzEzNDE=Limit GPU usage to specific GPU device2019-07-16T13:58:28ZFalse
MDU6SXNzdWU0Njg4MzE1NzQ=Multiple Layer Representations using Tensorflow Hub2019-07-16T19:45:45ZFalse
MDU6SXNzdWU0Njg5Njk4ODE=using tf.estimator.train_and_evaluate, train on GPU while eval on CPU2019-07-17T03:42:25ZFalse
MDU6SXNzdWU0Njg5NzQ5ODE=How to use bert embeding in Java2019-07-17T04:07:23ZFalse
MDU6SXNzdWU0NjkwNzI3MTQ=change the position of text a and text b, get a different result in bert similarity2019-07-17T09:02:46ZFalse
MDU6SXNzdWU0NjkwODk1NjM=Use the pre-trained model for word prediction2019-07-17T09:37:16ZFalse
MDU6SXNzdWU0NjkyMDM3OTA=Whole word masking model on TFHub2019-07-17T13:47:09ZFalse
MDU6SXNzdWU0Njk0MzE5Nzg="Missing ""do_train"" and ""do_eval"" argument in run_classifier_with_tfhub.py"2019-07-17T20:35:56ZFalse
MDU6SXNzdWU0Njk1MDM1NTU=In ner task, do I need to add crf or just softmax in the end of the module?2019-07-17T23:54:33ZFalse
MDU6SXNzdWU0NzAyNzAxMzc=how to use tensorflow-serving to predict online with high performance2019-07-19T11:08:06ZFalse
MDU6SXNzdWU0NzA2NTYwOTI="Did Chinese-only model strip out the accent mark? I mean the mark like ""-"""2019-07-20T09:34:03ZFalse
MDU6SXNzdWU0NzA3MzQ1MTg=whole word mask is not support in chinese2019-07-21T02:32:16ZFalse
MDU6SXNzdWU0NzA3NTkwMzY=how to run multiple run_classifier.py programs at the same time2019-07-21T08:56:15ZFalse
MDU6SXNzdWU0NzE1MjU4MjQ="InvalidArgumentError (see above for traceback): Found Inf or NaN global norm. : Tensor had NaN values 	 [[{{node VerifyFinite/CheckNumerics}} = CheckNumerics[T=DT_FLOAT, message=""Found Inf or NaN global norm."", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](global_norm/global_norm)]]"2019-07-23T07:18:52ZFalse
MDU6SXNzdWU0NzE1NTk5OTk=Improve answer scoring on fine-tuned Bert with SQUAD2019-07-23T08:38:28ZFalse
MDU6SXNzdWU0NzIxMDcxMDk=create_pretraining_data.py kept killed..2019-07-24T06:42:44ZFalse
MDU6SXNzdWU0NzI4MjE0ODU=the list of the 102 languages2019-07-25T11:50:29ZFalse
MDU6SXNzdWU0NzMxOTYzNTU=the set of log_step_count_steps doesn't work in tf.contrib.tpu.RunConfig2019-07-26T06:19:14ZFalse
MDU6SXNzdWU0NzM2NjQ2NTM=Example for Machine Translation2019-07-27T18:24:48ZFalse
MDU6SXNzdWU0NzM4MjI3MzA=Null Return in model_predict function when BERT predicts on a single record2019-07-29T02:38:59Z2019-07-29T07:05:09ZTrue
MDU6SXNzdWU0NzU1NDA1MDM="how can ""Estimater.predict"" do a real-time prediction ? "2019-08-01T08:15:43ZFalse
MDU6SXNzdWU0NzU1NjY0MzM=Out of memory2019-08-01T09:11:55ZFalse
MDU6SXNzdWU0NzU2NTM1Mzk=freezing bert ckpt model to pb model named pb_model and quantizing pb model named pb_quantize_model, however , bert pb_quantize_model inference is not work while pb_model inference is work2019-08-01T12:26:25ZFalse
MDU6SXNzdWU0NzU3MTk2NDU=Option to output extract_features to one file per encoding2019-08-01T14:34:54ZFalse
MDU6SXNzdWU0NzYwODU0NTY=Issue with convert examples to features2019-08-02T09:26:15ZFalse
MDU6SXNzdWU0NzY0Nzc1OTE=Using BERT for predicting masked token2019-08-03T18:30:45ZFalse
MDU6SXNzdWU0NzgxMjkxNjE=run_classifier.py input_fn required edits for large datasets2019-08-07T20:39:48Z2019-09-19T19:52:56ZTrue
MDU6SXNzdWU0NzgzNTUxNDc="Using hidden states from BERT (Similar to using precomputed hidden states in GPT2 model ""past"" argument)"2019-08-08T09:31:36ZFalse
MDU6SXNzdWU0NzkxNzIxNjY=Similar word from phrase that exemplifies context2019-08-09T21:23:21ZFalse
MDU6SXNzdWU0Nzk0Njg4MzU=Why estimator.predict didn't really run inference graph?2019-08-12T05:04:04ZFalse
MDU6SXNzdWU0Nzk3MjMxMTI=Performance metrics of the classifier2019-08-12T15:54:02ZFalse
MDU6SXNzdWU0Nzk5MjMxODI=Intended Behaviour for Impossible (out-of-span) SQuAD 1.1 Features2019-08-13T01:55:15ZFalse
MDU6SXNzdWU0ODA0Mzg4NTc=Will BERT learn from XLnet? 2019-08-14T01:25:14ZFalse
MDU6SXNzdWU0ODA2MTgyNjM=BERT End to End (Fine-tuning + Predicting) in 5 minutes with Cloud TPU2019-08-14T11:08:00ZFalse
MDU6SXNzdWU0ODEwNDQwOTU=will using bert like w2v work if I skip proprocessing with CLS and SEP for NER tasks? My experiments results are very poor. Not sure if this is the problem.2019-08-15T08:15:35ZFalse
MDU6SXNzdWU0ODEzNDMxNjE=What kind of classifier or architecture of classifier that BERT uses?2019-08-15T21:17:31ZFalse
MDU6SXNzdWU0ODE1MDE1MDk=How to remove training nodes after continue pretraining?2019-08-16T08:28:16ZFalse
MDU6SXNzdWU0ODE1NDE3MjU=BERT-Base, Uncased (Whole Word Masking)2019-08-16T10:14:28ZFalse
MDU6SXNzdWU0ODE5NDQ5MTA=Experiment using RAdam optimizer2019-08-18T02:18:41ZFalse
MDU6SXNzdWU0ODE5NjQwMzE=Non deterministic results in movie review notebook2019-08-18T07:33:54Z2019-08-20T08:44:50ZTrue
MDU6SXNzdWU0ODIyOTA5OTM=Can BERT really handle misspelled words?2019-08-19T12:45:10ZFalse
MDU6SXNzdWU0ODI3MDkxOTI=why the result model.ckpt is such bigger than the pretrained bert model2019-08-20T08:10:33ZFalse
MDU6SXNzdWU0ODI5NTcyMDY=Experiment using state of the art activation functions2019-08-20T16:17:09ZFalse
MDU6SXNzdWU0ODMxNTA1MzQ=Will BERT learn from ERNIE 2.0?2019-08-21T01:11:40ZFalse
MDU6SXNzdWU0ODM2MTMzMDA=Experiment attention on attention for BERT2019-08-21T19:36:49ZFalse
MDU6SXNzdWU0ODM3NTY1MzA=tf.estimator2019-08-22T03:59:42ZFalse
MDU6SXNzdWU0ODQ5Mjk4NjM=When will the Chinese BERT-large pre-training model be released?2019-08-25T13:10:31ZFalse
MDU6SXNzdWU0ODUxNjc5MTg=How to add new classes to a self pretrained model ?2019-08-26T10:35:24ZFalse
MDU6SXNzdWU0ODUyMTA1MzU=Question about QA results2019-08-26T12:28:05ZFalse
MDU6SXNzdWU0ODYxMjIzNjU=How to do fine tuning on downstream tasks with multi GPUs2019-08-28T02:12:13ZFalse
MDU6SXNzdWU0ODYxNzY3NTg=Use cross entropy loss function in the classification task.2019-08-28T06:04:06ZFalse
MDU6SXNzdWU0ODY3MDI1NTU=the error Paddings must be non-negative happened when run  run_pretraining2019-08-29T02:36:12ZFalse
MDU6SXNzdWU0ODY5MDExOTI=Advice on pre-training for Chinese2019-08-29T11:28:05ZFalse
MDU6SXNzdWU0ODY5NzA4MzM=extract_features.py  is too slow2019-08-29T13:49:52ZFalse
MDU6SXNzdWU0ODcwNDkxODg=how to set to use four GPU2019-08-29T16:03:18ZFalse
MDU6SXNzdWU0ODcyODY5MDY=Loss keep going up and down2019-08-30T05:02:14ZFalse
MDU6SXNzdWU0ODcyOTc2MzY=Any advice on pre-training for Spanish?2019-08-30T05:45:16ZFalse
MDU6SXNzdWU0ODc0NDg2OTY=TRAINED_CLASSIFIER2019-08-30T12:07:42ZFalse
MDU6SXNzdWU0ODc4OTI1MjE=Exporting best model2019-09-01T14:28:35Z2020-05-05T13:19:51ZTrue
MDU6SXNzdWU0ODgyMzgwMDI=How to set warmup step and decaying step ?2019-09-02T15:18:18ZFalse
MDU6SXNzdWU0ODg0NDc4NzM=How to pre-train a Chinese and English multilingual model2019-09-03T07:53:26ZFalse
MDU6SXNzdWU0ODg5MTMxODU=many grammar in bert have been deprecated, please update the bert library for python2019-09-04T02:57:42ZFalse
MDU6SXNzdWU0ODg5NjM2NzM=Unexpected low similarity between similar token vectors2019-09-04T06:17:42ZFalse
MDU6SXNzdWU0ODkwMjM4OTU=how can I get a six layer bert?2019-09-04T08:44:40ZFalse
MDU6SXNzdWU0ODk0OTAzMzg=Windows fatal exception: access violation2019-09-05T02:14:55ZFalse
MDU6SXNzdWU0ODk1NTMxMTQ=Learning Word-pieces garble the predictions2019-09-05T06:29:28ZFalse
MDU6SXNzdWU0ODk1ODE3NDk=Training BERT WWM for Hindi from scratch2019-09-05T07:38:53ZFalse
MDU6SXNzdWU0OTAxOTE3MDU=How to fine tune bert on small labeled twitter dataset?2019-09-06T08:13:35Z2020-05-16T09:16:12ZTrue
MDU6SXNzdWU0OTAzNjIyNjI=Exporting bert model to a saved model format2019-09-06T14:35:53ZFalse
MDU6SXNzdWU0OTA1NDgxNTA=R Version2019-09-06T22:35:19ZFalse
MDU6SXNzdWU0OTA1NjUwOTg=How to set weight decay other than BERT layer?2019-09-07T00:05:21ZFalse
MDU6SXNzdWU0OTA3MTc0Mjc=Prediction out of Bound |  Condition x < y did not hold element-wise2019-09-08T06:40:36ZFalse
MDU6SXNzdWU0OTA3MjI1OTc=how to solve the error of passing the param?2019-09-08T07:45:51ZFalse
MDU6SXNzdWU0OTA4MDkxOTc=How to run bert classifier pb file 2019-09-08T21:34:56Z2019-10-03T09:24:47ZTrue
MDU6SXNzdWU0OTA4NzA1MTM=Problem: Large Document Classification with BERT2019-09-09T04:31:15Z2019-09-12T00:20:55ZTrue
MDU6SXNzdWU0OTIwNTE1Mzg=Using hub.Module() to import downloaded BERT in disk2019-09-11T06:53:01Z2019-09-11T07:21:56ZTrue
MDU6SXNzdWU0OTIxNTc1MDM=How to get masked word in BERT tensorflow (I have trained ckpt files)?2019-09-11T10:41:29ZFalse
MDU6SXNzdWU0OTI2MDc2Mzk=Has anyone tried to distill multi bert models into one bert model?2019-09-12T06:18:44ZFalse
MDU6SXNzdWU0OTM0ODE5NjI=Suspicious evaluation in Jupyter notebook for sentiment classification2019-09-13T19:25:42ZFalse
MDU6SXNzdWU0OTM3MjM0NjA=Repretrain bert but OOM2019-09-15T10:57:14ZFalse
MDU6SXNzdWU0OTM3NDI4Mjg=Accuracy not increasing with BERT Large model 2019-09-15T14:18:21ZFalse
MDU6SXNzdWU0OTM4NjE4OTI=What is the reason for this?2019-09-16T06:03:24ZFalse
MDU6SXNzdWU0OTM5OTI3NzQ=BERT returns different embedding for same sentence2019-09-16T11:29:43Z2019-09-16T17:10:34ZTrue
MDU6SXNzdWU0OTUwNjgzMTQ=when using c++ to do inference, tensorflow::session->Run error2019-09-18T08:26:54ZFalse
MDU6SXNzdWU0OTUyNjExMTU=tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[2968] = 30523 is not in [0, 30522)2019-09-18T14:25:09ZFalse
MDU6SXNzdWU0OTYxMTU0ODk=What is the best CPU inference acceleration solution for BERT now?2019-09-20T02:49:30ZFalse
MDU6SXNzdWU0OTY1MzQ1NTE=Error 2019-09-20T20:30:54ZFalse
MDU6SXNzdWU0OTY3MzM5ODU=My classification always get one same result.2019-09-22T05:00:32Z2019-09-22T08:03:54ZTrue
MDU6SXNzdWU0OTY3ODUzODQ=Obtain Bert's intermediate results2019-09-22T14:20:55ZFalse
MDU6SXNzdWU0OTg2MzMxMzk=how to use fine-tuned bert for another task2019-09-26T03:22:21ZFalse
MDU6SXNzdWU0OTg2OTQ3Mzk=How to get the origin word embedding in training for ditillation?2019-09-26T06:52:39Z2019-09-26T09:06:23ZTrue
MDU6SXNzdWU1MDAxODQzNjE=Inconsistent filesizes made by create_pretraining_data.py2019-09-30T10:19:27ZFalse
MDU6SXNzdWU1MDA0MTQwMDk=Albert Availability2019-09-30T17:27:24ZFalse
MDU6SXNzdWU1MDE3MDUwMDA=Multi Task Learning Clarification 2019-10-02T20:19:52Z2019-10-02T20:20:57ZTrue
MDU6SXNzdWU1MDI5MjcwOTk=Bert embedding  for topic modeling.2019-10-05T07:05:01ZFalse
MDU6SXNzdWU1MDM3NTc3NzY=Create a language model from scratch2019-10-08T00:24:07ZFalse
MDU6SXNzdWU1MDQwMzcyMDM=WWM for Multilingual2019-10-08T13:14:53ZFalse
MDU6SXNzdWU1MDUyODU4ODI= how to use GPU for create_pretraining_data.py2019-10-10T13:50:49ZFalse
MDU6SXNzdWU1MDU4MjE2MzA=how to implement gradient accumulation in tf estimator2019-10-11T12:25:52ZFalse
MDU6SXNzdWU1MDY0NjE4NDI=how process digits with bert model2019-10-14T06:00:36ZFalse
MDU6SXNzdWU1MDY3MzQ3OTM=how to realize the tokenization of BERT model in c++2019-10-14T15:45:49Z2019-11-22T08:29:58ZTrue
MDU6SXNzdWU1MDc0MDkwNDY=OOM error fine-tuning2019-10-15T18:26:30ZFalse
MDU6SXNzdWU1MDc1ODMxOTY=some questions about the script run_classifier_with_tfhub2019-10-16T03:00:12ZFalse
MDU6SXNzdWU1MDc4MTA3Mjc=Can not run Bert with Colab TPU2019-10-16T12:11:19Z2019-10-25T10:00:43ZTrue
MDU6SXNzdWU1MDg2MjY5MTI=how to reduce the size of a pretrain bert by delete the adam variable(train by tpu) 2019-10-17T17:46:50Z2019-10-25T13:28:35ZTrue
MDU6SXNzdWU1MDk4NDg3NzY=Same init_checkpoint for train and eval in the classification2019-10-21T09:40:32ZFalse
MDU6SXNzdWU1MTIzMTAyMzE="How many ""num_tpu_cores"" be set ? "2019-10-25T05:27:02Z2019-10-25T06:19:11ZTrue
MDU6SXNzdWU1MTIzOTY5NTU=accent character2019-10-25T09:09:17ZFalse
MDU6SXNzdWU1MTI0NDU4NDk=Can I run the ```run_classifier.py``` with multi-GPUs?2019-10-25T10:50:48ZFalse
MDU6SXNzdWU1MTI1MTYzMzY=how use the pretrain checkpoint to continue train on my own corpus?2019-10-25T13:27:04ZFalse
MDU6SXNzdWU1MTMzMDE3MjY="""model_fn should return an EstimatorSpec."" Error when running ""predicting_movie_reviews_with_bert_on_tf_hub.ipynb"" for fine-tuning BERT-Chinese Model"2019-10-28T13:25:56Z2019-10-29T18:46:20ZTrue
MDU6SXNzdWU1MTQwNTc4MDk=TF 2.X Colab Example2019-10-29T16:33:14ZFalse
MDU6SXNzdWU1MTQyODc3MDA=Vocabulary Token Frequencies2019-10-29T23:15:17ZFalse
MDU6SXNzdWU1MTQ1OTE2MzY=Wrap Up custom BERT as TF Hub module2019-10-30T11:28:07ZFalse
MDU6SXNzdWU1MTQ2ODIwNjQ=TF 2.0 compatible BERT2019-10-30T13:46:21ZFalse
MDU6SXNzdWU1MTU3NjcyOTY=seems like an infinite loop2019-10-31T21:45:12ZFalse
MDU6SXNzdWU1MTU5Nzk3MTU=add tokenize emoji for tokenization.BasicTokenizer 2019-11-01T08:36:44ZFalse
MDU6SXNzdWU1MTYxNDYwODU=export_saved_model output file does not exist2019-11-01T14:27:08ZFalse
MDU6SXNzdWU1MTc0MTAwMDg=Failing to pre-train Bert with TPU V2 8 Cores, Google Cloud Storage, 30 GB RAM and TF 1.11.02019-11-04T21:20:31ZFalse
MDU6SXNzdWU1MTc0NDUyMjA="run run_classifier on colab with TPU got ""^C"" after the first checkpoint. "2019-11-04T22:39:17ZFalse
MDU6SXNzdWU1MTc1ODYzMjY=Wrong number of params in mBERT README?2019-11-05T07:10:07ZFalse
MDU6SXNzdWU1MTgyMzg0NDI=Fine tuning BERT in SQuAD 1.1 stop in colab 2019-11-06T05:00:10ZFalse
MDU6SXNzdWU1MTgzNTY0MDg=run run_classifier.py UnicodeDecodeError2019-11-06T09:48:14ZFalse
MDU6SXNzdWU1MTg0OTc2ODc=Bert similarity score high for non semantic similar sentences .2019-11-06T14:11:59ZFalse
MDU6SXNzdWU1MTkzODQ5OTg="When I run modeling_test.py, I get the error ""Tensor.name is meaningless when eager execution is enabled."""2019-11-07T16:45:24ZFalse
MDU6SXNzdWU1MjA1NTc4MTA=Processing book corpus2019-11-10T05:44:07ZFalse
MDU6SXNzdWU1MjA1NjM5NTk=How do you get the training time on each epoch using TPUEstimator?2019-11-10T07:09:03ZFalse
MDU6SXNzdWU1MjA4NzQwOTk=BertForNextSentencePrediction is giving high score for non similar sentences 2019-11-11T10:37:18ZFalse
MDU6SXNzdWU1MjA4ODgzMTU=transformers vs  pytorch_pretrained_bert giving different scores for BertForNextSentencePrediction2019-11-11T11:03:47ZFalse
MDU6SXNzdWU1MjEzNjU0ODM=`Whole Word Masking` does not work in this code at 'create_pretraining_data.py'2019-11-12T06:58:34ZFalse
MDU6SXNzdWU1MjE0NTc3OTU=LM Finetuning is slow with GTX 1080  GPU 2019-11-12T10:20:55ZFalse
MDU6SXNzdWU1MjE0ODA2Mjc=How to do multi gpu prediction for a finetuned bert model?2019-11-12T11:02:43ZFalse
MDU6SXNzdWU1MjE5Mzg0NTc=computing self-attention for tokens in a sentence2019-11-13T03:36:44ZFalse
MDU6SXNzdWU1MjI1OTU3MTI=It seems that global step (tf.train.get_global_step) has not been increased2019-11-14T03:08:35ZFalse
MDU6SXNzdWU1MjI1OTg1Mzg=run_classifier with low GPU Util and low GPU Memory2019-11-14T03:19:01Z2019-11-14T08:31:22ZTrue
MDU6SXNzdWU1MjI2MDYyNDQ=Eval every 100 steps during training.2019-11-14T03:46:26ZFalse
MDU6SXNzdWU1MjI4MDM1MTY=What does output_fn at line 471 do in run_squad.py?2019-11-14T11:40:00ZFalse
MDU6SXNzdWU1MjI4NDc4Mjc=TF2 version of BERT multilingual on TF Hub2019-11-14T13:11:13ZFalse
MDU6SXNzdWU1MjMzMDA2NzM=How to print learning_rate?2019-11-15T07:21:51ZFalse
MDU6SXNzdWU1MjM0NDE0MzU=Original BERT-BASE / BERT-LARGE training loss across training steps2019-11-15T12:24:13ZFalse
MDU6SXNzdWU1MjM0OTgyMTc=[MEMORY] How to know memory consumption on GPU/TPU of a model?  2019-11-15T14:23:45ZFalse
MDU6SXNzdWU1MjM5MTA2MzE=Multiclassification Erorr Randomly - [predictions must be in [0, 1]]2019-11-16T23:39:00ZFalse
MDU6SXNzdWU1MjQ2OTMwODk=save all 12 layers outputs for each token2019-11-19T00:07:12ZFalse
MDU6SXNzdWU1MjQ3MTAzMjc=How to use tensorboard on colab to get the model statistics2019-11-19T01:06:10ZFalse
MDU6SXNzdWU1MjQ4ODM3MzI=BertForTokenClassification for NER . what is the conclusion of this output ?2019-11-19T09:32:39ZFalse
MDU6SXNzdWU1MjU2MDUzMzA=How to use SQuAD for chinese (Close-Domain)QA task2019-11-20T06:35:44ZFalse
MDU6SXNzdWU1MjU2MzI0MjQ=FileNotFoundError: [Errno 2] No such file or directory: 'pybert/output/checkpoints/bert'2019-11-20T07:48:28ZFalse
MDU6SXNzdWU1MjU3MjI1MDk=Update citation2019-11-20T10:46:07ZFalse
MDU6SXNzdWU1MjcwNTI5MTY=FullTokenizer not compatible with tf 2.02019-11-22T08:18:35ZFalse
MDU6SXNzdWU1MjcxMDcxOTQ=How to splice the other features needed into Bert and fine-tune them together?2019-11-22T10:15:07Z2019-12-27T10:10:48ZTrue
MDU6SXNzdWU1MjcxMjIyNTY=how to provide data to input_ids,input_mask,segment_ids?2019-11-22T10:45:30ZFalse
MDU6SXNzdWU1MjczMDk1Mzk=Too much Prediction Time2019-11-22T17:01:16ZFalse
MDU6SXNzdWU1Mjc2NTY5Mjk=module 'tensorflow_core._api.v2.train' has no attribute 'Optimizer'2019-11-24T06:33:20ZFalse
MDU6SXNzdWU1Mjc5MzcxOTY=Why restoring checkpoint is run on CPU not GPU?2019-11-25T08:51:03ZFalse
MDU6SXNzdWU1MjgxNDI5MDI=Pretraining - ValueError2019-11-25T15:00:25Z2019-12-08T20:04:32ZTrue
MDU6SXNzdWU1Mjg1MDIxMTM=Pre-training on TPU Pod2019-11-26T05:43:52ZFalse
MDU6SXNzdWU1Mjg1Mzk2NjU=Error while using bert as tfhub layer with tensorflow 2.02019-11-26T07:26:55ZFalse
MDU6SXNzdWU1Mjg1NTk2Njg=nan error:  tensorflow.python.framework.errors_impl.InvalidArgumentError: From /job:worker/replica:0/task:0: Gradient for bert/embeddings/LayerNorm/gamma:0 is NaN : Tensor had NaN values          [[node CheckNumerics_4 (defined at usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]2019-11-26T08:16:28ZFalse
MDU6SXNzdWU1Mjg1NjgwNTQ=Question about calculating word embeddings using pretrained model2019-11-26T08:34:48Z2019-12-12T11:25:35ZTrue
MDU6SXNzdWU1Mjg1NzE4MDc=how to optimize bert to be suitable for multi-pages documents to extract some infomation 2019-11-26T08:42:46ZFalse
MDU6SXNzdWU1MjkxNjA0MDk=Pre-Training BERT from scratch using Tokenized input file and custom vocabulary file for Khmer language2019-11-27T07:10:25ZFalse
MDU6SXNzdWU1Mjk3OTUxMDY=Training on specific task after a fine-tuning on the language model2019-11-28T09:33:44ZFalse
MDU6SXNzdWU1MzA2NzQyMjM=NotFoundError: ./dev.tsv2019-12-01T05:21:48ZFalse
MDU6SXNzdWU1MzI0NjgzNjY=When use the Bert model in other senarios, do we have a unittest method or guidline to test.2019-12-04T05:58:50ZFalse
MDU6SXNzdWU1MzI0ODgzOTY=When use bert model for classifier(run_classifier.py), can I separate the data handle process and classify precess2019-12-04T06:57:16ZFalse
MDU6SXNzdWU1MzI1OTU5OTk=Hi, why [CLS] can be used to classify?2019-12-04T10:38:55ZFalse
MDU6SXNzdWU1MzI2MTU2MjY=clearify2019-12-04T11:11:57ZFalse
MDU6SXNzdWU1MzI3MDQ0OTU=how to train BertForMaskedLM model with custom corpus?2019-12-04T14:02:08ZFalse
MDU6SXNzdWU1MzMxNTA5Njg=run_classifier.py MRPC result2019-12-05T06:24:58ZFalse
MDU6SXNzdWU1MzMxNzk1MDg=How to see masked_lm_loss & next_sentence_loss per iteration step during train?2019-12-05T07:41:37ZFalse
MDU6SXNzdWU1MzMzOTk3MTY=Unable to load the custom pretrained model . How to test after pretraining the bert model ?2019-12-05T14:50:36ZFalse
MDU6SXNzdWU1MzM4Mjc1Nzc=What sequence length should I use for GLUE fine-tuning?2019-12-06T08:52:14ZFalse
MDU6SXNzdWU1MzM4ODUwOTA=Help:! unable to load the pretrained model from local/colab directory2019-12-06T10:44:37ZFalse
MDU6SXNzdWU1MzM4OTkzMjI=[ERROR] TPUEstimator with BestExporter: ValueError: slice index 1 of dimension 0 out of bounds. 2019-12-06T11:11:51ZFalse
MDU6SXNzdWU1MzU2MDI3MjY=How does Google calculate a document embeddings using BERT in its new search?2019-12-10T09:31:51ZFalse
MDU6SXNzdWU1MzU3NDgzNjU=BERT for tabular data - e.g. wikitables2019-12-10T13:59:41ZFalse
MDU6SXNzdWU1MzU4Mjc2MTk=How to interprete results2019-12-10T16:05:48ZFalse
MDU6SXNzdWU1MzY0NDA5OTc=convert tf1 pretrained bert checkpoint to tf2 2019-12-11T15:22:40ZFalse
MDU6SXNzdWU1Mzk0ODI2Nzk=BERT论文里面有#task1和#task2，在训练模型时这两个task是先训练task1再训练task2，还是同时训练同时训练的话，怎么做的？训练语料是同一份吗？2019-12-18T06:41:51ZFalse
MDU6SXNzdWU1NDAwNDkwNzM=when we calculate loss, why we jsut calculate one token loss, rather than sum all token loss in one example2019-12-19T03:17:08ZFalse
MDU6SXNzdWU1NDIyMzgwNjY=How can I get the attention matrix output from the attention layer?2019-12-25T02:37:15ZFalse
MDU6SXNzdWU1NDIyNjkwNDE=BERT Multi-lingual: similarity score of two different languages?2019-12-25T06:33:20Z2019-12-27T06:02:38ZTrue
MDU6SXNzdWU1NDI0MjQ3NDU=is it possible to get less than 2.0 loss when pretraining from scratch on 20gb dataset on the first 30k steps?2019-12-26T04:02:51ZFalse
MDU6SXNzdWU1NDI0NDQ2OTM="How to understand the ""we pre-train the model with sequence length of 128 for 90% of the steps. Then, we train the rest 10% of the steps of sequence of 512 to learn the positional embeddings."" mentioned in the paper A.2 Pre-training Procedure ???"2019-12-26T06:03:00ZFalse
MDU6SXNzdWU1NDI2ODY2MzA=Load the model from a specific check point which generated minimum loss2019-12-26T22:40:56ZFalse
MDU6SXNzdWU1NDI4ODU2MTk=请问获得训练好的词向量的值？ How to get the pretrained embedding_table?2019-12-27T14:03:25Z2019-12-28T11:44:37ZTrue
MDU6SXNzdWU1NDI4OTcwOTk=Print accuracy during training via loggingHook --> InaccessibleTensorError2019-12-27T14:44:45ZFalse
MDU6SXNzdWU1NDMwOTI2NTM=Question about using function 'tf.squeeze' for selecting 'first_token_tensor'2019-12-28T08:08:42ZFalse
MDU6SXNzdWU1NDMxMzI2MjM=请问预训练时怎么划分训练集和测试集呢？How to split training data and test data during pretraining?2019-12-28T11:48:22ZFalse
MDU6SXNzdWU1NDMxOTMyOTY=Compared with CBOW, skip-gram and GloVe, what is the effect of embedding words with BERT?2019-12-28T14:43:33ZFalse
MDU6SXNzdWU1NDQzNDY4MDc=module 'tensorflow' has no attribute 'gfile'2020-01-01T11:31:58ZFalse
MDU6SXNzdWU1NDQ0ODE0MjQ=Can I run multi-gpu pretraining?2020-01-02T08:03:45ZFalse
MDU6SXNzdWU1NDQ1OTY0MzQ=can not down wikipedia pre-training dataset2020-01-02T14:17:57ZFalse
MDU6SXNzdWU1NDQ5MDE2MTY=Why the results of pytorch and TensorFlow are inconsistent2020-01-03T08:44:27Z2020-01-05T09:20:40ZTrue
MDU6SXNzdWU1NDQ5MTY5OTY="""intermediate"" hidden layer"2020-01-03T09:34:38ZFalse
MDU6SXNzdWU1NDQ5MzA5NTA=I'd like to find 10 most similar words to an input word. Is there a method in the BERT package that I can call?2020-01-03T10:14:36ZFalse
MDU6SXNzdWU1NDYzMDYzMjk=Códigos2020-01-07T14:13:50ZFalse
MDU6SXNzdWU1NDY2OTkxMDE=token_type_id has only two possible value， yes？2020-01-08T07:50:02ZFalse
MDU6SXNzdWU1NDc4ODQzMjI=Avoid loading graph for every call to BERT2020-01-10T06:06:09ZFalse
MDU6SXNzdWU1NDc4ODYxNjU=Service request to BERT using flask2020-01-10T06:12:09ZFalse
MDU6SXNzdWU1NDc4OTU5OTY=BERT-PRETRAINING AND VOCABULARY2020-01-10T06:43:41ZFalse
MDU6SXNzdWU1NDg0MDUyMjI="why bert ""only predict the masked words rather than reconstructing the entire input."" ?"2020-01-11T09:15:36ZFalse
MDU6SXNzdWU1NDg0NzIxMDY=bert run_classifier2020-01-11T19:47:11ZFalse
MDU6SXNzdWU1NDg3MTk5OTk=What does bert embedding of a single term signify?2020-01-13T05:53:13ZFalse
MDU6SXNzdWU1NTAwMzk5MzU=How much data need for pre-training the language models from pre-trained checkpoints2020-01-15T08:36:14ZFalse
MDU6SXNzdWU1NTMzNTQ3NjU=What is the effect of using small vocabulary size for training bert?2020-01-22T07:18:26ZFalse
MDU6SXNzdWU1NTQ0MzcwNzc=Averaging attention head weights2020-01-23T22:12:05ZFalse
MDU6SXNzdWU1NTUzMDc0MjU=Bucjet name is not defined?2020-01-26T23:56:27ZFalse
MDU6SXNzdWU1NTY5NTMzMzc=Reproduce Multilingual BERT results2020-01-29T15:53:47ZFalse
MDU6SXNzdWU1NTg0MDU3MDc=NotfoundError: Key bert/embeddings/LayerNorm/beta not found in checkpoint2020-01-31T22:24:33ZFalse
MDU6SXNzdWU1NTk0OTUyNjA=Regarding reducing the size of finetuned bert model in tf 2.x2020-02-04T05:23:08ZFalse
MDU6SXNzdWU1NjAzODI5MDA=how to handle tagging with Bert wordpiece2020-02-05T13:46:57ZFalse
MDU6SXNzdWU1NjI5OTIyMTM=bert run_classifier key error = '0'2020-02-11T05:51:45ZFalse
MDU6SXNzdWU1NjQxNTQ3NjM=BERT generating prediction in 120sec approx using squad 2.0 in prediction.json2020-02-12T17:32:29ZFalse
MDU6SXNzdWU1NjQzNjUwNDM=Distributed Training2020-02-13T00:32:23ZFalse
MDU6SXNzdWU1NjUyMTU1NTk=Multilingual model supported language codes in machine readable format2020-02-14T09:48:29ZFalse
MDU6SXNzdWU1NjU3NTE2MTE=bert ner fp16 model error2020-02-15T14:00:26ZFalse
MDU6SXNzdWU1NjU5OTgxNzI=Can you provide the evaluation for mean average prevision for classification task?2020-02-17T00:28:44Z2020-02-24T16:59:42ZTrue
MDU6SXNzdWU1NjkyODk3NDk=Generating vocabulary file for or after pretraining BERT from base2020-02-22T06:17:56ZFalse
MDU6SXNzdWU1NjkzOTE3Mzk=Is it possible feed BERT to seq2seq encoder for NMT (for low resource language)?2020-02-22T20:52:10ZFalse
MDU6SXNzdWU1Njk0Mjc1NTM=How many instances are used to train English bert-base? Is the dupe_factor set to 1 for creating the training instances?2020-02-23T02:53:31ZFalse
MDU6SXNzdWU1Njk2NTE4NTQ=Any future release of BERT for Tensorflow 2.x?2020-02-24T05:58:32ZFalse
MDU6SXNzdWU1NzAzMTYzODU=Finding results on STS Benchmark dataset2020-02-25T05:11:10ZFalse
MDU6SXNzdWU1NzAzNTM5MDM=Can we use bert on lower versions of tensorflow (<1.8)2020-02-25T06:58:30ZFalse
MDU6SXNzdWU1NzA4MDk5MjE=NotFoundError: [_Derived_]No gradient defined for op: Einsum on Tensorflow 1.152020-02-25T20:23:32ZFalse
MDU6SXNzdWU1NzExNzMzMzQ=Multilingual model broken for Japanese2020-02-26T09:01:31ZFalse
MDU6SXNzdWU1NzIwODYzODk=Regarding bert attention output 2020-02-27T13:32:08ZFalse
MDU6SXNzdWU1NzM2MTYwMzY=Exploding gradients in training BERT from scratch2020-03-01T21:10:20ZFalse
MDU6SXNzdWU1NzM3NTE3MzM=[ERROR] TypeError: Expected binary or unicode string, got 102020-03-02T06:37:34ZFalse
MDU6SXNzdWU1NzQyMDc2MTI=How to use gradient accumulate optimization in the fine-tune2020-03-02T19:51:31ZFalse
MDU6SXNzdWU1NzQyNDY1MTI=Explain the variables in the checkpoint2020-03-02T21:03:45ZFalse
MDU6SXNzdWU1NzU5NDY2NDA=BERT large training more unstabile than BERT base2020-03-05T02:17:50ZFalse
MDU6SXNzdWU1NzU5NDk5MDk=Fine-tuning  model.ckpt-0  problem2020-03-05T02:28:24ZFalse
MDU6SXNzdWU1NzYwMzkzODQ=DuplicateFlagError in run_classifier.py2020-03-05T07:10:56ZFalse
MDU6SXNzdWU1NzY4NjM1MjI=Fix Some Code to compat for tf 2.02020-03-06T11:13:09ZFalse
MDU6SXNzdWU1NzcwNjkxNjU=Does bert have this function ?2020-03-06T17:18:06ZFalse
MDU6SXNzdWU1NzczMzg5MTk=BERT pretraining num_train_steps questions2020-03-07T14:02:32ZFalse
MDU6SXNzdWU1Nzk4Mjc2MzQ=KeyError: 1000000000 write_predictions (run_squad.py)2020-03-12T10:10:03ZFalse
MDU6SXNzdWU1ODAwMzM2MzQ=Please add bert base scores to glue table2020-03-12T15:48:02ZFalse
MDU6SXNzdWU1ODAyMjg3MTQ=BERT Large , 512 sequence length - Allocation of X exceeds Y% of system memory.2020-03-12T21:16:16ZFalse
MDU6SXNzdWU1ODA4NTYyNTU=Train-dev-test splits2020-03-13T21:17:04ZFalse
MDU6SXNzdWU1ODEyNDUwMDM=BERT SavedModel  Feature Transformation using TF API inference timings2020-03-14T15:06:29ZFalse
MDU6SXNzdWU1ODIwMDM4NDg=Can I reproduce to train these 24 smaller models?2020-03-16T04:57:48ZFalse
MDU6SXNzdWU1ODM0NDE4ODI=m-dash missing in the mBERT vocabulary2020-03-18T03:41:08ZFalse
MDU6SXNzdWU1ODU3NTA2OTE=MRPC Produces Two Vastly Different Eval Accuracy2020-03-22T16:00:24Z2020-03-22T16:10:47ZTrue
MDU6SXNzdWU1ODU3NzgwOTU=BERT throws error with batch size = 1.2020-03-22T18:09:45ZFalse
MDU6SXNzdWU1ODYyMTc3MDI=Pre-trained models fail to infer with batch>12020-03-23T13:41:13ZFalse
MDU6SXNzdWU1ODc3MDkxNzA=Using my pre-trained model2020-03-25T13:47:58ZFalse
MDU6SXNzdWU1ODgzMTAyNzk=iterations_per_loop and train/eval split in pretraining2020-03-26T10:24:45ZFalse
MDU6SXNzdWU1ODg5NDcyMzk=how compress the fine-tune model to small?2020-03-27T07:42:33ZFalse
MDU6SXNzdWU1ODk2OTMxOTA=Tiny multilingual BERT?2020-03-29T01:18:15ZFalse
MDU6SXNzdWU1OTAzMzg4NDQ=max_eval_steps pretraining2020-03-30T14:30:56ZFalse
MDU6SXNzdWU1OTE2NDAxMzc=BERT Tiny/Mini/Small/Medium Cased models2020-04-01T05:38:32ZFalse
MDU6SXNzdWU1OTI5NzQxMjA=Tokenizer for BERT Pretrained models and punctuation2020-04-02T23:16:24ZFalse
MDU6SXNzdWU1OTM3NDA3MTg=For token embeddings, how do you get the shape 768 (Input format) from wordpiece integer ids?2020-04-04T04:14:23ZFalse
MDU6SXNzdWU1OTM3NDA5NjM=For BERT input embedding, how are the word piece tokens converted to a vector of size 7682020-04-04T04:15:53ZFalse
MDU6SXNzdWU1OTQzMTE3NjY=race-condition in optimizer.py2020-04-05T07:40:27ZFalse
MDU6SXNzdWU1OTU1NjI5NzQ=Got very bad classification perfromance using run_classifier.py on SQuAD data. Is the run_classifier.py designed for Sentence level classification only?2020-04-07T03:25:29ZFalse
MDU6SXNzdWU1OTgzNzQ5MTY=NotFoundError: $BERT_BASE_DIR/bert_config.json; No such file or directory2020-04-11T23:49:44ZFalse
MDU6SXNzdWU1OTkyMzgzNDg=multi-segment text input for BERT now.2020-04-14T01:47:04ZFalse
MDU6SXNzdWU1OTkyODUzNzE=is it necessary to drop stop words before training?2020-04-14T04:17:08ZFalse
MDU6SXNzdWU1OTk5ODI4NDY=How many epoch do we need when pretraining bert?2020-04-15T02:59:11ZFalse
MDU6SXNzdWU2MDA0Mzk4MjE= How to get the embedded tabel size after pre-training2020-04-15T16:43:58ZFalse
MDU6SXNzdWU2MDEwNjgyMTM="How is this counted? --> ""3.3 billion word corpus"""2020-04-16T13:46:26ZFalse
MDU6SXNzdWU2MDE2MzMxNjU="""logits must be 2-dimensional"" error on TF 1.9"2020-04-17T01:10:53ZFalse
MDU6SXNzdWU2MDIzMjkxNjg=what is the different between the model in gs and tensorflow.hub2020-04-18T00:30:13ZFalse
MDU6SXNzdWU2MDI1ODY2NzY=how to understand the segmention embeddings2020-04-19T00:45:12ZFalse
MDU6SXNzdWU2MDI2NjU0MjI=Why we get last 4 layers while residual connection transfer useful knowledge to the subsequent layers?2020-04-19T09:17:17ZFalse
MDU6SXNzdWU2MDMxMTI5NjU=What's the difference between use_one_hot_embeddings and tf.gather in embedding_lookup2020-04-20T10:07:12ZFalse
MDU6SXNzdWU2MDM0MTU4Njk=BERT-Tiny,BERT-Mini,BERT-Small,BERT-Medium - TF 2.0 checkpoints 2020-04-20T17:42:37ZFalse
MDU6SXNzdWU2MDQwNjc2OTQ=Pooled output is different from first vector of sequence output2020-04-21T15:00:08ZFalse
MDU6SXNzdWU2MDQxNzQ4NjY=Pretrain without Next Sentence Prediction Task2020-04-21T17:57:38ZFalse
MDU6SXNzdWU2MDQzMzk1MjU=pretraining BERT CASED model gives lower accuracy than UNCASED2020-04-21T23:07:16ZFalse
MDU6SXNzdWU2MDY5NTU5MjQ=Error extract features trained model2020-04-26T08:37:32ZFalse
MDU6SXNzdWU2MDc2NjczMjY=Are adam weights and variances necessary to continue pretraining?2020-04-27T16:04:10ZFalse
MDU6SXNzdWU2MDgzNTMwMTA=How much GPU memory shall I have if I want to fine-tuning BERT-large?2020-04-28T14:14:22ZFalse
MDU6SXNzdWU2MTEyMjQ5NTY=Do_predict does not make predictions for all instances in the test.tsv2020-05-02T16:25:30ZFalse
MDU6SXNzdWU2MTE0NzExMzE=deploy on serverless architecture2020-05-03T18:04:02ZFalse
MDU6SXNzdWU2MTE2NTAyMDY=BERT is capable to predict phrasel keyword in NER ?2020-05-04T07:09:00ZFalse
MDU6SXNzdWU2MTI0Mjk1Njk=How to choose num_train_step in run_pretraining.py ?2020-05-05T08:27:32ZFalse
MDU6SXNzdWU2MTUzNDE1OTA=how to used fine tuned model as initial checkpoint for another task?2020-05-10T08:16:13Z2020-05-11T21:33:55ZTrue
MDU6SXNzdWU2MTcxNzcwMzQ=Adding custom domain words and abbreviations to vocab.txt2020-05-13T06:24:30ZFalse
MDU6SXNzdWU2MTgzMTI5OTI=Sentence embeddings2020-05-14T15:14:04ZFalse
