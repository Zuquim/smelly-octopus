idtitlecreatedAtclosedAtclosed
MDU6SXNzdWUxMzIyMjg5NjA=need requirements.txt2016-02-08T19:00:00Z2016-02-08T23:44:27ZTrue
MDU6SXNzdWUxMzI3OTA2MTY=Shallow policy network2016-02-10T19:11:37Z2017-07-11T19:19:07ZTrue
MDU6SXNzdWUxMzI3OTEwMTg=Training in parallel2016-02-10T19:13:25Z2016-03-16T22:21:14ZTrue
MDU6SXNzdWUxMzQxMzA0NDI="Definining ""Ladder Capture"" and ""Ladder Escape"""2016-02-16T23:49:41Z2016-11-27T16:03:16ZTrue
MDU6SXNzdWUxMzQxMzE4OTk=handling 'atari' features2016-02-16T23:58:57Z2016-02-17T21:28:18ZTrue
MDU6SXNzdWUxMzQxMzIyNTE=write tests for new gamestate features2016-02-17T00:00:54Z2016-03-15T20:31:21ZTrue
MDU6SXNzdWUxMzQ2Nzk2ODc=tensor shape, converting from numpy2016-02-18T19:58:06Z2016-02-19T22:03:27ZTrue
MDU6SXNzdWUxMzk2MDQ0NjI=snapback2016-03-09T15:15:46Z2016-03-09T21:15:01ZTrue
MDU6SXNzdWUxMzk3MDQwNjc=reduce complexity of go.py2016-03-09T21:22:09Z2016-03-15T20:28:57ZTrue
MDU6SXNzdWUxMzk4MzI1MDM=http://mcts.ai/code/python.html 2016-03-10T09:28:46Z2016-03-10T14:32:56ZTrue
MDU6SXNzdWUxMzk5MTU3MTc=Possibly add install instructions2016-03-10T15:09:11Z2016-03-10T15:22:35ZTrue
MDU6SXNzdWUxNDAwNzk0MDM=A Bug in `deal_post_data`2016-03-11T04:02:52Z2016-03-13T19:01:00ZTrue
MDU6SXNzdWUxNDAyNjgzNjg=How do I contribute2016-03-11T19:22:35Z2016-05-16T13:13:18ZTrue
MDU6SXNzdWUxNDA0MDQzNjk=Library choice2016-03-12T18:10:03Z2016-03-12T21:33:02ZTrue
MDU6SXNzdWUxNDA0NDI2OTE=Very good!2016-03-13T03:42:24Z2016-03-13T18:59:48ZTrue
MDU6SXNzdWUxNDA0ODIzNjg=how to build AlphaGo to play chess?2016-03-13T12:47:20Z2016-03-13T18:59:43ZTrue
MDU6SXNzdWUxNDA0ODI2MjQ=How to use2016-03-13T12:53:37Z2016-03-13T18:59:37ZTrue
MDU6SXNzdWUxNDA1MjY2MTk=How to run the project?2016-03-13T20:36:22Z2016-03-14T00:14:39ZTrue
MDU6SXNzdWUxNDA4MzY1ODc=Opinion on PEP8 violations2016-03-15T00:37:48Z2016-05-16T13:13:38ZTrue
MDU6SXNzdWUxNDA4NDMyMTM=Misc thoughts and suggestions2016-03-15T01:23:57Z2016-05-16T13:12:56ZTrue
MDU6SXNzdWUxNDEwNDk4ODA=Detecting end of game2016-03-15T17:48:51Z2016-05-06T13:29:00ZTrue
MDU6SXNzdWUxNDEwNTI0MzU=Fast rollout features2016-03-15T17:58:30ZFalse
MDU6SXNzdWUxNDEwNzYwNjg=GPU training and scaling2016-03-15T19:30:13Z2016-05-16T13:12:16ZTrue
MDU6SXNzdWUxNDEwNzY2MTk=Other implementation2016-03-15T19:32:58Z2016-03-15T20:28:22ZTrue
MDU6SXNzdWUxNDEwNzg0OTk=Refactor SGF conversions?2016-03-15T19:41:41Z2016-03-20T21:42:47ZTrue
MDU6SXNzdWUxNDEwNzkxMDI=Go Text Protocol2016-03-15T19:44:00Z2016-04-26T11:47:41ZTrue
MDU6SXNzdWUxNDExMDE3NzA=consider switching to jtauber/sgf for sgf library2016-03-15T21:21:15Z2016-03-20T21:42:47ZTrue
MDU6SXNzdWUxNDEyMTIxMTk=This is interesting. Would you please develop what it is about ?2016-03-16T09:06:34Z2016-03-16T16:32:35ZTrue
MDU6SXNzdWUxNDEyMzc0NDU=run goServer.py Error,when upload a sgf file.2016-03-16T10:57:58Z2016-03-22T18:14:26ZTrue
MDU6SXNzdWUxNDEyOTIzMjM=How about coming to the BOINC platform?2016-03-16T14:32:27Z2016-03-16T16:27:57ZTrue
MDU6SXNzdWUxNDE0MjIxNjU=Supervised learning pipeline2016-03-16T22:33:10Z2016-03-21T00:02:51ZTrue
MDU6SXNzdWUxNDIwODI0MTQ=rewrite tests using parseboard2016-03-19T17:08:43ZFalse
MDU6SXNzdWUxNDIwOTA0NzI=Help!2016-03-19T18:49:40Z2016-03-19T18:53:15ZTrue
MDU6SXNzdWUxNDIxNDg4NjU=Reducing the size of the neural net - interesting paper2016-03-20T10:31:24ZFalse
MDU6SXNzdWUxNDIyMDk1NTM=Keras + theano on travis2016-03-20T21:44:30Z2016-03-21T13:43:08ZTrue
MDU6SXNzdWUxNDIyMjUzNTA=Managing our data2016-03-21T00:17:42Z2016-03-28T18:52:55ZTrue
MDU6SXNzdWUxNDIyMjU1ODM=Extra functionality for supervised_policy_trainer2016-03-21T00:18:39Z2016-03-28T18:52:55ZTrue
MDU6SXNzdWUxNDM1MTgzMTY=extract dataset statistics2016-03-25T15:01:40ZFalse
MDU6SXNzdWUxNDM4NDU0OTQ="Bot ""tournaments"" and statistics"2016-03-27T20:21:33ZFalse
MDU6SXNzdWUxNDQwNjY5MDk=NaN accuracy while training2016-03-28T19:52:56Z2016-03-29T21:06:20ZTrue
MDU6SXNzdWUxNDQwNjkyMzc=Concatenate datasets together2016-03-28T20:02:52Z2016-04-19T15:03:54ZTrue
MDU6SXNzdWUxNDQzOTA3NTY=Feature plane consistency with pyfuego2016-03-29T21:16:33ZFalse
MDU6SXNzdWUxNDUxNzA4NDY=How to run the AlphaGo project on our computer?How can I import sgf?2016-04-01T12:41:35Z2016-04-01T13:54:39ZTrue
MDU6SXNzdWUxNDUzNDU0NTE=How can I run Benchmarks?2016-04-02T07:08:03Z2016-04-02T13:06:25ZTrue
MDU6SXNzdWUxNDU1NDQyNDM=Fix CNNPolicy.eval_state2016-04-03T21:49:58Z2016-04-08T15:43:44ZTrue
MDU6SXNzdWUxNDU1Nzk1MjI=TypeError: Can't convert element 2 (19) to hsize_t2016-04-04T04:15:35Z2016-04-05T02:28:36ZTrue
MDU6SXNzdWUxNDU4MTAwMDQ=missing self-atari in game2016-04-04T21:29:31Z2016-04-19T17:06:41ZTrue
MDU6SXNzdWUxNDYxMTYxNzI=training saves only loss and not accuracy2016-04-05T21:56:38Z2016-04-06T00:05:16ZTrue
MDU6SXNzdWUxNDYxMTgxMDQ=get rid of transpose in feature preprocessing2016-04-05T22:06:59Z2016-04-19T17:06:41ZTrue
MDU6SXNzdWUxNDYzNjYzNzQ=flatten neural net output2016-04-06T16:31:04Z2016-04-08T18:02:16ZTrue
MDU6SXNzdWUxNDcxMzU0MTY=How to use this program2016-04-09T14:59:13Z2016-04-10T17:15:59ZTrue
MDU6SXNzdWUxNDcyMDM0NjI=how to get sgf2016-04-10T07:40:13Z2016-04-10T17:17:36ZTrue
MDU6SXNzdWUxNDc0MDE0OTU=Python, multithreading and lock free MCTS...?2016-04-11T11:40:41Z2016-04-12T07:14:17ZTrue
MDU6SXNzdWUxNDc0MzgzNzU=is_legal and do_move(..., color) are inconsistent2016-04-11T13:59:09Z2016-04-29T15:58:22ZTrue
MDU6SXNzdWUxNDg2NTkxMDE=validation metrics in supervised learning2016-04-15T13:19:24ZFalse
MDU6SXNzdWUxNDkxNjQxMzE=full pipeline script2016-04-18T14:17:35ZFalse
MDU6SXNzdWUxNDk3ODQyNDE=`policy.save_model` should save class too2016-04-20T14:29:10Z2016-05-14T23:32:20ZTrue
MDU6SXNzdWUxNTQyNjE1MTU=policy nets are missing individual biases for each position2016-05-11T14:44:23Z2016-05-14T23:32:26ZTrue
MDU6SXNzdWUxNTQ3MjgzNTQ=Allow validation in a separate process2016-05-13T14:44:05Z2017-07-11T19:12:25ZTrue
MDU6SXNzdWUxNTU2NzQxMDU=Architecture of valuenet2016-05-19T07:50:49Z2016-09-22T00:07:18ZTrue
MDU6SXNzdWUxNTU5ODM5MDI=reinforcement policy training benchmarking2016-05-20T15:04:07Z2016-09-22T00:06:19ZTrue
MDU6SXNzdWUxNTgwMzc2OTc=JSON serializable problem2016-06-02T00:47:17Z2016-08-03T13:53:59ZTrue
MDU6SXNzdWUxNTg1OTgwOTg=Development haitus2016-06-06T04:17:28Z2016-08-30T12:28:13ZTrue
MDU6SXNzdWUxNTk0NTAyODQ=follow2016-06-09T16:21:04Z2016-06-13T16:21:02ZTrue
MDU6SXNzdWUxNjA4MTAzNTc=when i run the AlphaGo.training.supervised_policy_trainer  find a ValueError2016-06-17T04:34:08Z2016-09-22T00:05:18ZTrue
MDU6SXNzdWUxNjQ0NTQ0ODA=Mapping RocAlphaGo to Stock Trading ? any idea 2016-07-08T03:54:21Z2016-07-12T14:56:01ZTrue
MDU6SXNzdWUxNjQ5Mzc0MTc=Possible model checkpointing error with Keras 1.0.02016-07-11T21:21:49Z2016-07-19T15:45:47ZTrue
MDU6SXNzdWUxNjQ5ODIyODM=gtp library has bug with pass move2016-07-12T02:41:42Z2016-07-12T14:52:32ZTrue
MDU6SXNzdWUxNjUyNjk1MjE=The project is out of updating?2016-07-13T08:52:09Z2016-07-13T15:40:52ZTrue
MDU6SXNzdWUxNjU3MDA0MDQ=Rollout function only performs 1 rollout2016-07-15T02:45:58Z2016-07-19T06:20:29ZTrue
MDU6SXNzdWUxNjU3MDIxMTk=Create a player class that uses MCTS2016-07-15T03:04:11Z2016-07-29T04:34:43ZTrue
MDU6SXNzdWUxNjU5NTY4ODE=GameState.copy() doesn't create copy of history2016-07-17T02:26:44Z2016-07-18T14:36:03ZTrue
MDU6SXNzdWUxNjYyNTc5Mzg=Create utility classes to aid in printing the board/data2016-07-19T06:32:40ZFalse
MDU6SXNzdWUxNjcxOTQ2ODc=Possible memory leak during RL training2016-07-23T17:39:20Z2016-07-25T07:04:12ZTrue
MDU6SXNzdWUxNjcyNDM3NjA=Python3 compatibility2016-07-24T17:27:53ZFalse
MDU6SXNzdWUxNjcyNzgyNTk=More memory-efficient implementation of RL2016-07-25T04:09:32Z2016-09-19T17:34:43ZTrue
MDU6SXNzdWUxNjcyNzg0ODg=Rework the RL trainer script to handle restarting differently2016-07-25T04:12:47ZFalse
MDU6SXNzdWUxNjkwNDYxNjY=rewrite gamestate to sgf converter to use sgf library2016-08-03T04:37:46ZFalse
MDU6SXNzdWUxNzQwMDcxNjM=SL Training Schedule2016-08-30T12:34:30Z2017-07-11T19:19:58ZTrue
MDU6SXNzdWUxNzQwMDc4OTU=SL restart overwrites weights2016-08-30T12:38:11Z2017-07-11T19:25:33ZTrue
MDU6SXNzdWUxNzQwMDk0ODM=Create tests for player classes2016-08-30T12:46:09ZFalse
MDU6SXNzdWUxNzQxNjk4NzA=Apply board symmetries during inference2016-08-31T02:25:36ZFalse
MDU6SXNzdWUxNzQ1ODc4NjM=Check superko2016-09-01T18:03:17Z2016-09-22T00:03:31ZTrue
MDU6SXNzdWUxNzQ2NjkwNzM=apply temperature in log space for ProbabilisticPolicyPlayer2016-09-02T02:45:05Z2016-10-29T13:48:49ZTrue
MDU6SXNzdWUxNzYwNTA0NjM=Get player rank from SGF, put it in HDF5 dataset for each move2016-09-09T16:23:02ZFalse
MDU6SXNzdWUxNzc1ODU3ODU=tensorflow compatibility2016-09-17T15:42:09Z2017-07-11T18:54:26ZTrue
MDU6SXNzdWUxNzgwODk3ODM=Add cache to preprocessing2016-09-20T15:14:58ZFalse
MDU6SXNzdWUxNzg0ODkyNzE=win_ratio is always zero in RL policy trainer2016-09-21T23:46:21Z2016-09-21T23:55:30ZTrue
MDU6SXNzdWUxNzg4ODM1MDY=Incorrect loss function in RL2016-09-23T13:53:00Z2016-09-25T12:18:32ZTrue
MDU6SXNzdWUxNzg4ODQzNjk=Current RL optimizer does not support batch updates2016-09-23T13:56:43Z2017-01-07T16:03:58ZTrue
MDU6SXNzdWUxNzkwMTU5OTg=gtp_wrapper has a couple issues2016-09-24T07:06:13ZFalse
MDU6SXNzdWUxNzkzODU0OTM=How to start the program？thank you.2016-09-27T02:51:32Z2016-09-27T02:59:08ZTrue
MDU6SXNzdWUxODkyNjUwMTM=RuntimeError: maximum recursion depth exceeded2016-11-15T00:23:26Z2016-11-27T16:03:37ZTrue
MDU6SXNzdWUxOTE5ODQyMzU=Reward is applied late.2016-11-28T11:39:30Z2017-07-11T19:11:38ZTrue
MDU6SXNzdWUxOTI1ODc4ODU=Infinite loop, is_ladder_capture2016-11-30T15:01:30Z2017-07-11T18:54:45ZTrue
MDU6SXNzdWUxOTQwMjIwMDc=AlphaChess version2016-12-07T11:13:36Z2017-07-11T18:56:39ZTrue
MDU6SXNzdWUxOTUwMTYyMjg=Fix SL epoch number on restart2016-12-12T16:16:51Z2017-07-11T18:55:08ZTrue
MDU6SXNzdWUxOTUwOTg5NTQ=Include all symmetries during training2016-12-12T22:04:41ZFalse
MDU6SXNzdWUxOTgxODA5NDY=Value training2016-12-30T18:41:18ZFalse
MDU6SXNzdWUxOTg5ODE2MTE=DeepMind AlphaGo recent update2017-01-05T15:26:15Z2017-07-11T18:56:44ZTrue
MDU6SXNzdWUyMDAxMzExNzg=Issue about the get_winner function in the GameState class2017-01-11T15:55:16Z2017-01-15T21:40:07ZTrue
MDU6SXNzdWUyMDE0OTQ2MDQ=What accuracy did you get for your SL policy network?2017-01-18T06:59:54Z2017-01-26T14:10:17ZTrue
MDU6SXNzdWUyMDUwMjk4NTM=Who can tell me how to start this game?2017-02-02T23:34:30Z2017-02-04T16:02:48ZTrue
MDU6SXNzdWUyMDU0NTU1OTY=Faster go.py2017-02-05T21:24:18Z2017-07-11T18:55:38ZTrue
MDU6SXNzdWUyMDU0NTYwMTM=Faster feature computation2017-02-05T21:30:37Z2017-07-11T18:56:26ZTrue
MDU6SXNzdWUyMDU1ODE0NTM=is there any evaluation on the difficulty of RocAolphaGo to human ?2017-02-06T13:21:05Z2017-07-11T18:56:49ZTrue
MDU6SXNzdWUyMTUxOTkyMjg=How to solve the unknown layer: Bias mistake?2017-03-18T14:56:47Z2017-03-19T12:08:46ZTrue
MDU6SXNzdWUyNDAwMzM4ODI=test-case about ladder search is probably wrong2017-07-02T20:55:39Z2017-07-03T21:22:16ZTrue
MDU6SXNzdWUyNDc2NDg2MTA=Something wrong with the installation2017-08-03T09:38:10Z2017-08-07T06:27:50ZTrue
MDU6SXNzdWUyNDc5MjM4Nzk=Something wrong with the tests2017-08-04T07:22:25Z2017-08-14T07:10:40ZTrue
MDU6SXNzdWUyNDg5ODk1MjI=How to use the GoGui2017-08-09T10:43:06Z2017-08-29T07:57:43ZTrue
MDU6SXNzdWUyNTI4MDAyNjI=How to train the value network and the reinforcement value network?  2017-08-25T05:12:00Z2017-08-29T07:58:15ZTrue
MDU6SXNzdWUyNTMxNDcwMTU=How to create *model.json for value?2017-08-27T07:32:43ZFalse
MDU6SXNzdWUyNjg4MTUxNjE=Review `cython-optimization` branch and merge into main branch2017-10-26T15:51:12ZFalse
MDU6SXNzdWUyNjg4MTU0ODI=Create combined policy+value resnet model2017-10-26T15:52:07ZFalse
MDU6SXNzdWUyNjg4MTYyNjY=Implement Zero's Monte-Carlo Tree Search2017-10-26T15:54:19ZFalse
MDU6SXNzdWUyNjg4MTY0ODg=Combine cython preprocessing into a single file2017-10-26T15:54:58ZFalse
MDU6SXNzdWUyNjg4MjAwMDI="Create ""last n board states"" feature as used in AlphaGo Zero"2017-10-26T16:04:50ZFalse
MDU6SXNzdWUyNjg4MjAyNTc=Implement RL training using MCTS policy-iteration2017-10-26T16:05:41ZFalse
MDU6SXNzdWUyNjg4MjA5ODQ="Implement a simple SL ""pre-training"" for a policy+value model"2017-10-26T16:07:54ZFalse
MDU6SXNzdWUyNjg4MzAwNTQ=Benchmark Zero's MCTS2017-10-26T16:35:23ZFalse
MDU6SXNzdWUzMjg0OTE2MTQ=Ask for permission.2018-06-01T11:56:11Z2018-06-01T14:14:17ZTrue
MDU6SXNzdWUzMzA3MDc0MDI=Some problems in go engine2018-06-08T15:38:01Z2018-06-11T12:50:12ZTrue
MDU6SXNzdWUzMzA3Mjg2NDI=Can we only use value network, and not use policy network?2018-06-08T16:44:37Z2018-06-08T17:23:41ZTrue
