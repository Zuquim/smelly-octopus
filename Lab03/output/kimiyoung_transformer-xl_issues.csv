idtitlecreatedAtclosedAtclosed
MDU6SXNzdWUzOTc3MzcxODM=PyTorch: pretrained models2019-01-10T09:18:04ZFalse
MDU6SXNzdWUzOTgxOTkyNjU=License for the released code?2019-01-11T09:20:07Z2019-01-11T16:26:52ZTrue
MDU6SXNzdWUzOTg0MzA2Mzk=PyTorch multiGPU training2019-01-11T19:57:21Z2019-01-12T02:17:32ZTrue
MDU6SXNzdWUzOTg3OTAyNDY=relative attention score2019-01-14T08:38:21Z2019-01-15T03:18:56ZTrue
MDU6SXNzdWUzOTkyNjUwMzU=Tensor2Tensor compatibility 2019-01-15T09:51:32ZFalse
MDU6SXNzdWUzOTkzNTQ4NDE=Some questions about pytorch code and details.2019-01-15T13:53:33ZFalse
MDU6SXNzdWUzOTk1NjQwNzc=Usage of the additional parameter ext_len2019-01-15T22:29:00Z2019-01-17T08:58:15ZTrue
MDU6SXNzdWUzOTk5MTE4Njg=Tensorflow version is 0.1.12? Why we find this version? Can you offer the link?2019-01-16T17:16:24Z2019-01-17T18:31:31ZTrue
MDU6SXNzdWU0MDAxMTU1MTM=Quick question on comparison against BERT2019-01-17T05:25:03Z2019-01-18T19:27:02ZTrue
MDU6SXNzdWU0MDA1ODk0NzA=tf code question?2019-01-18T06:26:47ZFalse
MDU6SXNzdWU0MDE1OTQ0NjA=Unable to replicate experiment results2019-01-22T04:24:33Z2019-01-28T02:20:41ZTrue
MDU6SXNzdWU0MDE3MjQ5ODE=How to train models with attn_type=2 on wiki103 training set?2019-01-22T11:41:25ZFalse
MDU6SXNzdWU0MDI0NzE2MDM=Architecture for word-level Penn Treebank dataset2019-01-23T23:12:58ZFalse
MDU6SXNzdWU0MDMwNTc4NjY=trouble loading pytorch model2019-01-25T08:45:45ZFalse
MDU6SXNzdWU0MDMyMjE2MDA=TPU settings2019-01-25T16:08:25Z2019-01-25T22:51:56ZTrue
MDU6SXNzdWU0MDM1MzQ4MzM=ZeroDivisionError: integer division or modulo by zero2019-01-27T10:08:08Z2019-01-29T03:19:13ZTrue
MDU6SXNzdWU0MDQxMzY2ODA=why pplx was so high as 1000 when I was training on wt103 dataset2019-01-29T06:08:57ZFalse
MDU6SXNzdWU0MDQ2MDc0ODY=Are there any special tuning skills? Why is my pplx always very high2019-01-30T05:25:09ZFalse
MDU6SXNzdWU0MDYxODA4NDc=Transfer Learning for Sentence Classification2019-02-04T04:50:05ZFalse
MDU6SXNzdWU0MDYzNDQzNTE=get perplexity of new sentence2019-02-04T14:05:12Z2019-02-05T14:47:01ZTrue
MDU6SXNzdWU0MDczMzQ4NDg=Sensitivity to initial weights causing NANs?2019-02-06T17:00:36ZFalse
MDU6SXNzdWU0MDc2NTE0NTA=Different ppl values for same inputs2019-02-07T11:21:24ZFalse
MDU6SXNzdWU0MDgxNTE5Mzg="Does the ""Beyond Fixed-Length"" solution make the new architecture compatible with incomplete-sentence tasks (e.g. text generation)?"2019-02-08T13:26:49ZFalse
MDU6SXNzdWU0MDkzNTIxMzU=Is transformer-xl like a seq2seq model or a word-embedding model?2019-02-12T15:19:16Z2019-02-25T18:27:02ZTrue
MDU6SXNzdWU0MTAyNTM3MjA=Some problems when training2019-02-14T11:25:31ZFalse
MDU6SXNzdWU0MTA2Njg3Nzc=Can not understand this sentence in the paper. Thank you!2019-02-15T09:05:18Z2019-02-16T08:50:29ZTrue
MDU6SXNzdWU0MTA2NzYzNDU=Finetune with transformer-xl pretrained models2019-02-15T09:26:32ZFalse
MDU6SXNzdWU0MTEyNTk0NjQ=Have you eval the speed of 512 len and 256 len? Thank you!!2019-02-18T00:50:50Z2019-02-19T01:09:06ZTrue
MDU6SXNzdWU0MTE3MDI5MzU=Release models that support more languages?2019-02-19T01:17:52Z2019-02-22T05:52:13ZTrue
MDU6SXNzdWU0MTIwMjk0NzA=Penn Treebank and WikiText-2 architectures2019-02-19T17:04:11ZFalse
MDU6SXNzdWU0MTIyMzA5MjI=Could you please summarize the reason of the inference speedup?2019-02-20T03:43:31Z2019-02-27T03:33:30ZTrue
MDU6SXNzdWU0MTI1MDE5MzA=Train a new corpus !2019-02-20T16:01:32Z2019-04-16T11:32:44ZTrue
MDU6SXNzdWU0MTI3NDI1NTY=It seems the eval speed of transformer-xl is not faster than bert-base-uncased.2019-02-21T04:22:37Z2019-02-27T03:30:52ZTrue
MDU6SXNzdWU0MTI4ODE3ODc=Problem with run sota/lm1b.sh.2019-02-21T11:38:29ZFalse
MDU6SXNzdWU0MTMyMzAxNTE=speedup due to state reuse, compared by 2 32seq_len+state-reuse vs 1 64seq_len+no-state-reuse?2019-02-22T03:46:20Z2019-02-27T03:27:03ZTrue
MDU6SXNzdWU0MTY0ODgxNjQ=Any plan to release the pretrained models?2019-03-03T08:05:27ZFalse
MDU6SXNzdWU0MTY2MTYwNTg=problem when run sota/enwik8.sh2019-03-04T03:40:09Z2019-03-04T07:10:29ZTrue
MDU6SXNzdWU0MTg2OTEyMzk=problem in tf code2019-03-08T08:52:16ZFalse
MDU6SXNzdWU0MTkyNjE2NTU=run pytorch’s run_wt103_large.sh print 285170506 parameters, but the paper is 128M, and OOM.2019-03-11T01:37:53ZFalse
MDU6SXNzdWU0MTk3MDAyMzc=Generation script2019-03-11T21:50:18ZFalse
MDU6SXNzdWU0MjA4NjgxOTQ=Does anyone have a Python3 friendly version code2019-03-14T07:28:51ZFalse
MDU6SXNzdWU0MjA4Njk5Mjg=parameters in tf code2019-03-14T07:34:36ZFalse
MDU6SXNzdWU0MjMxMDg4NTE=OOM issue when training 1 billion corpus2019-03-20T07:39:45Z2019-05-03T09:02:52ZTrue
MDU6SXNzdWU0MjQwMjQ5NDI=Google one-billion experiments2019-03-22T02:54:29ZFalse
MDU6SXNzdWU0MjU4ODMyMjY=How to use the model for predicting next word.2019-03-27T10:39:46ZFalse
MDU6SXNzdWU0MjYzNjgzNDY=Finetuning2019-03-28T08:49:33ZFalse
MDU6SXNzdWU0MzE3MjkxMDI=Issues with wt103_large_tpu.sh2019-04-10T21:36:02ZFalse
MDU6SXNzdWU0MzI0MzIzODY=Using this model to get sentence level log probability2019-04-12T07:47:44ZFalse
MDU6SXNzdWU0MzI4NTE3Mzg=is this a bug in pytorch code on invocation of `_update_mems`?2019-04-13T14:13:40ZFalse
MDU6SXNzdWU0MzI4NzUyODE=sparse updates with multi-GPU2019-04-13T17:26:39ZFalse
MDU6SXNzdWU0MzM3MzQ4MTU=Questions For Configuring a new Corpus2019-04-16T11:44:37ZFalse
MDU6SXNzdWU0MzM5NDA2NjA=tf not working in the 1st try2019-04-16T19:09:55ZFalse
MDU6SXNzdWU0MzQ5ODgzODc=Cuda out of memory2019-04-18T22:48:49ZFalse
MDU6SXNzdWU0MzU0NjUyNTE=Out of Memory When Using GPU2019-04-21T01:48:33ZFalse
MDU6SXNzdWU0MzU0NjU1NDU=Is There an Encoder Process?2019-04-21T01:52:14ZFalse
MDU6SXNzdWU0MzU5MjQ4MTA=DistributedDataParallel works better on NVlink2019-04-22T22:52:30ZFalse
MDU6SXNzdWU0MzY3NzIzMTk=Apparent logical error in GPU loss2019-04-24T15:45:08Z2019-04-25T09:34:58ZTrue
MDU6SXNzdWU0MzcyMzgwMjg=Expected Results for PyTorch run_lm1b_base.sh2019-04-25T14:41:53ZFalse
MDU6SXNzdWU0MzgzMDg5ODk=Extension to a Summarization task2019-04-29T13:13:25ZFalse
MDU6SXNzdWU0MzgzNDYyNDA=about the visualizing tool2019-04-29T14:31:48Z2019-05-13T13:18:45ZTrue
MDU6SXNzdWU0NDAxMDI1MzQ=Training with wordpiece/bpe vocab2019-05-03T15:37:56ZFalse
MDU6SXNzdWU0NDA5NDQ4NTE=--attn_type 2 throwing size mismatch error with pytorch code ( -attn_type 0/1/3 work fine)2019-05-06T23:26:04ZFalse
MDU6SXNzdWU0NDIwODEzOTg=Can't calculate ppl for sentences of different lengths.2019-05-09T07:05:22ZFalse
MDU6SXNzdWU0NDMwMTE2MjU=class AdaptiveEmbedding, advice for understanding 2019-05-11T16:24:36ZFalse
MDU6SXNzdWU0NDM2NzIxMzc=Train/evaluate model on word-level ptb2019-05-14T01:45:01ZFalse
MDU6SXNzdWU0NDQ4Njk4MDI={BUG} Model and para_model Semantic error !2019-05-16T10:12:05ZFalse
MDU6SXNzdWU0NDc0NDA4NjE=Adaptive Softmax2019-05-23T04:04:05Z2019-05-23T16:07:18ZTrue
MDU6SXNzdWU0NDgzMTIwNzQ=character level representation2019-05-24T18:57:47ZFalse
MDU6SXNzdWU0NDk1MzAwOTk=batch shape does not include ext_len 2019-05-29T00:11:47ZFalse
MDU6SXNzdWU0NTE0MjcxODM=Improving Perplexity with Smarter Vocabularies2019-06-03T11:19:02ZFalse
MDU6SXNzdWU0NTIzMTU1Mjk=Is there a pre-training model in Chinese2019-06-05T05:00:25ZFalse
MDU6SXNzdWU0NTU5NDMzMDk=Training with own data2019-06-13T20:41:52ZFalse
MDU6SXNzdWU0NTY2MjEzODI=why use enwiki8 as the test set for wikitext 103?2019-06-16T09:26:58ZFalse
MDU6SXNzdWU0NTk1NzU3ODY=help about the mask created when same_length is true2019-06-23T13:22:54Z2019-06-27T23:38:01ZTrue
MDU6SXNzdWU0NjE5OTk5MzM=Inference time compared to LSTM based LMs 2019-06-28T11:58:02ZFalse
MDU6SXNzdWU0NjIwMjg1NjQ=How to retrieve the output word predicted by the LM?2019-06-28T13:12:56ZFalse
MDU6SXNzdWU0NjMwODY3NDQ=i got the logit to be all Nan, last_hidden, new_mems = self.transformer(input_ids, mems), and the last_hidden tensor all Nan. Could anybody help me with this?2019-07-02T08:16:08Z2019-07-03T02:15:29ZTrue
MDU6SXNzdWU0NjQzODUxMDk=Short question about position embeddings2019-07-04T20:14:13ZFalse
MDU6SXNzdWU0NjU5NTUyNTQ=parameter cutoff in the function single_core_graph2019-07-09T19:48:45ZFalse
MDU6SXNzdWU0Njg1MDMxMDA=Loss jumping to 8.28 and not going down2019-07-16T07:54:14ZFalse
MDU6SXNzdWU0Njk1ODUwMjk=what is the use of 'valid.txt'?2019-07-18T06:04:33ZFalse
MDU6SXNzdWU0NzIzMjc0NTU=where is the decoder in tf implementation?2019-07-24T14:48:17ZFalse
MDU6SXNzdWU0NzMxNTk3NDI=Short question for the critical idea in transformer-xl2019-07-26T03:28:57Z2019-09-06T15:58:52ZTrue
MDU6SXNzdWU0Nzg0NDUxNTA=Possible bug in a call?2019-08-08T12:38:18ZFalse
MDU6SXNzdWU0Nzk0NjUyNTE=How to speed up the inference2019-08-12T04:42:11Z2019-08-13T01:30:15ZTrue
MDU6SXNzdWU0ODM1NzUxMjM=Computing just logits/log prob without getting loss from Adaptive Softmax2019-08-21T18:15:14ZFalse
MDU6SXNzdWU0ODg0MDI2MDI=Result of wt103_base2019-09-03T05:43:11ZFalse
MDU6SXNzdWU1MDA4NzQxMTc=Extending the model for sentiment analysis2019-10-01T12:50:11ZFalse
MDU6SXNzdWU1MDgwNDUxODU=Clarify why evaluation will be much faster?2019-10-16T19:13:32ZFalse
MDU6SXNzdWU1MTI5MzUxMTc=How mem_len affects 1-billion lm experiment result2019-10-27T08:14:18ZFalse
MDU6SXNzdWU1NTA3NjY1NTA=what if mems is None?2020-01-16T12:07:33ZFalse
MDU6SXNzdWU1NTI2OTA2NTc=qkv computation2020-01-21T08:14:20ZFalse
MDU6SXNzdWU1NjA5NDMyNzU=Best settings to train Transformer-XL from scratch2020-02-06T11:13:08Z2020-02-09T16:26:31ZTrue
MDU6SXNzdWU1NzkzNTQ3NjE=question on TRAIN_BSZ used in tf/scripts/text8_large_tpu.sh2020-03-11T15:35:35ZFalse
MDU6SXNzdWU1ODQxMTcyMzU=论文中的figure1有些看不懂，有大神可以解答一下吗？2020-03-19T02:21:35Z2020-03-19T03:13:55ZTrue
MDU6SXNzdWU1OTI5ODI2Nzg=Bounty: PTB Transformer-xl2020-04-02T23:40:14Z2020-04-03T04:02:18ZTrue
MDU6SXNzdWU1OTMxOTMyMzI=PositionalEmbedding error2020-04-03T07:57:44Z2020-04-16T06:35:11ZTrue
MDU6SXNzdWU2MDYxOTQ1OTU=Why pos_seq is in descending order as the input of positional embedding? 2020-04-24T10:01:18ZFalse
MDU6SXNzdWU2MDcyOTA1OTg=can not reproduce sota wikitext103 results2020-04-27T07:00:04ZFalse
MDU6SXNzdWU2MTEzNTUyNDQ=Perplexity not changes with tgt_len2020-05-03T07:45:04ZFalse
MDU6SXNzdWU2MTU0NzE2NjA=Different training steps in tf and pytorch2020-05-10T20:38:45ZFalse
